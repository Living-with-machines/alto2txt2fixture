var __index = {"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"alto2txt2fixture","text":"<p><code>alto2txt2fixture</code> is a standalone tool to convert <code>alto2txt</code> <code>XML</code> output and other related datasets into <code>JSON</code> (and where feasible <code>CSV</code>) data with corresponding relational IDs to ease general use and ingestion into a relational database.</p> <p>We target the the <code>JSON</code> produced for importing into <code>lwmdb</code>: a database built using the <code>Django</code> <code>python</code> webframework database <code>fixture</code> structure.</p>"},{"location":"index.html#installation-and-simple-use","title":"Installation and simple use","text":"<p>We provide a command line interface to process <code>alto2txt</code> <code>XML</code> files stored locally (or mounted via <code>azure</code> <code>blobfuse</code>), and for additional public data we automate a means of downloading those automatically.</p>"},{"location":"index.html#installation","title":"Installation","text":"<p>We recommend downloading a copy of the reposity or using <code>git clone</code>. From a local copy use <code>poetry</code> to install dependencies:</p> <pre><code>$ cd alto2txt2fixture\n$ poetry install\n</code></pre> <p>If you would like to test, render documentation and/or contribute to the code included <code>dev</code> dependencies in a local install:</p> <pre><code>$ poetry install --with dev\n</code></pre>"},{"location":"index.html#simple-use","title":"Simple use","text":"<p>To processing newspaper metadata with a local copy of <code>alto2txt</code> <code>XML</code> results, it's easiest to have that data in the same folder as your <code>alto2txt2fixture</code> checkout and <code>poetry</code> installed folder. One arranged, you should be able to begin the <code>JSON</code> converstion with</p> <pre><code>$ poetry run a2t2f-news\n</code></pre> <p>To generate related data in <code>JSON</code> and <code>CSV</code> form, assuming you have an internet collection and access to a <code>living-with-machines</code> <code>azure</code> account, the following will download related data into <code>JSON</code> and <code>CSV</code> files. The <code>JSON</code> results should be consistent with <code>lwmdb</code> tables for ease of import.</p> <pre><code>$ poetry run a2t2f-adj\n</code></pre>"},{"location":"running.html","title":"Running the Program","text":""},{"location":"running.html#using-poetry-to-run","title":"Using <code>poetry</code> to run","text":"<p>The program should run automatically with the following command:</p> <pre><code>$ poetry run a2t2f-news\n</code></pre> <p>Alternatively, if you want to add optional parameters and don\u2019t want to use the standard <code>poetry</code> script to run, you can use the (somewhat convoluted) <code>poetry run alto2txt2fixture/run.py</code> and provide any optional parameters. You can see a list of all the \u201cOptional parameters\u201d below. For example, if you want to only include the <code>hmd</code> collection:</p> <pre><code>$ poetry run alto2txt2fixture/run.py --collections hmd\n</code></pre>"},{"location":"running.html#alternative-run-the-script-without-poetry","title":"Alternative: Run the script without poetry","text":"<p>If you find yourself in trouble with <code>poetry</code>, the program should run perfectly fine on its own, assuming the dependencies are installed. The same command, then, would be:</p> <pre><code>$ python alto2txt2fixture/run.py --collections hmd\n</code></pre> <p>Note</p> <p>See the list under <code>[tool.poetry.dependencies]</code> in <code>pyproject.toml</code> for a list of dependencies that would need to be installed for <code>alto2txt2fixture</code> to work outside a python <code>poetry</code> environment.</p>"},{"location":"running.html#optional-parameters","title":"Optional parameters","text":"<p>The program has a number of optional parameters that you can choose to include or not. The table below describes each parameter, how to pass it to the program, and what its defaults are.</p> Flag Description Default value <code>-c</code>, <code>--collections</code> Which collections to process in the mounted alto2txt directory <code>hmd</code>, <code>lwm</code>, <code>jisc</code>, <code>bna</code> <code>-o</code>, <code>--output</code> Into which directory should the processed files be put? <code>./output/fixtures/</code> <code>-m</code>, <code>--mountpoint</code> Where is the alto2txt directories mounted? <code>./input/alto2txt/</code> <code>-t</code>, <code>--test-config</code> Print the config table but do not run <code>False</code>"},{"location":"running.html#successfully-running-the-program-an-example","title":"Successfully running the program: An example","text":""},{"location":"understanding-results.html","title":"Understanding the Results","text":""},{"location":"understanding-results.html#the-resulting-file-structure","title":"The resulting file structure","text":"<p>The examples below follow standard settings</p> <p>If you choose other settings for when you run the program, your output directory may look different from the information on this page.</p>"},{"location":"understanding-results.html#reports","title":"Reports","text":"<p>Reports are automatically generated with a unique hash as the overarching folder structure. Inside the <code>reports</code> directory, you\u2019ll find a JSON file for each <code>alto2txt</code> directory (organised by NLP identifier).</p> <p>The report structure, thus, looks like this:</p> <p></p> <p>The JSON file has some good troubleshooting information. You\u2019ll find that the contents are structured as a Python <code>dictionary</code> (or JavaScript <code>Object</code>). Here is an example:</p> <p></p> <p>Here is an explanation of each of the keys in the dictionary:</p> Key Explanation Data type <code>path</code> The input path for the zip file that is being converted. <code>string</code> <code>bytes</code> The size of the input zip file represented in bytes. <code>integer</code> <code>size</code> The size of the input zip file represented in a human-readable string. <code>string</code> <code>contents</code> #TODO #3 <code>integer</code> <code>start</code> Date and time when processing started (see also <code>end</code> below). <code>datestring</code> <code>newspaper_paths</code> #TODO #3 <code>list</code> (<code>string</code>) <code>publication_codes</code> A list of the NLPs that are contained in the input zip file. <code>list</code> (<code>string</code>) <code>issue_paths</code> A list of all the issue paths that are contained in the cache directory. <code>list</code> (<code>string</code>) <code>item_paths</code> A list of all the item paths that are contained in the cache directory. <code>list</code> (<code>string</code>) <code>end</code> Date and time when processing ended (see also <code>start</code> above). <code>datestring</code> <code>seconds</code> Seconds that the script spent interpreting the zip file (should be added to the <code>microseconds</code> below). <code>integer</code> <code>microseconds</code> Microseconds that the script spent interpreting the zip file (should be added to the <code>seconds</code> above). <code>integer</code>"},{"location":"understanding-results.html#fixtures","title":"Fixtures","text":"<p>The most important output of the script is contained in the <code>fixtures</code> directory. This directory contains JSON files for all the different columns in the corresponding Django metadata database (i.e. <code>DataProvider</code>, <code>Digitisation</code>, <code>Ingest</code>, <code>Issue</code>, <code>Newspaper</code>, and <code>Item</code>). The numbering at the end of each file indicates the order of the files as they are divided into a maximum of <code>2e6</code> elements*:</p> <p></p> <p>Each JSON file contains a Python-like <code>list</code> (JavaScript <code>Array</code>) of <code>dictionaries</code> (JavaScript <code>Objects</code>), which have a primary key (<code>pk</code>), the related database model (in the example below the Django <code>newspapers</code> app\u2019s <code>newspaper</code> table), and a nested <code>dictionary</code>/<code>Object</code> which contains all the values for the database\u2019s table entry:</p> <p></p> <p>* The maximum elements per file can be adjusted in the <code>settings.py</code> file\u2019s <code>settings</code> object\u2019s <code>MAX_ELEMENTS_PER_FILE</code> value.</p>"},{"location":"reference/SUMMARY.html","title":"SUMMARY","text":"<ul> <li>alto2txt2fixture<ul> <li>__main__</li> <li>cli</li> <li>create_adjacent_tables</li> <li>jisc</li> <li>log</li> <li>parser</li> <li>patterns</li> <li>plaintext</li> <li>router</li> <li>settings</li> <li>types</li> <li>utils</li> </ul> </li> </ul>"},{"location":"reference/alto2txt2fixture/index.html","title":"alto2txt2fixture","text":""},{"location":"reference/alto2txt2fixture/__main__.html","title":"__main__","text":"<p>Entry point for <code>alto2txt2fixture.parse</code> to convert <code>alto2txt</code> <code>XML</code> -&gt; <code>JSON</code>.</p> <p>This module defines the run function which is the main driver for the entire process.</p> <p>It imports various functions from other modules and uses them to route and parse <code>XML</code> data generated by <code>alto2txt</code>.</p> <p>The following steps are performed in the run function:</p> <ol> <li>Parses command line arguments using the parse_args function. If no     arguments are provided, the default values are taken from the settings     module.</li> <li>Prints a setup report to the console, showing the values of the relevant     parameters.</li> <li>Calls the route function to route <code>alto2txt</code> data into subdirectories with     structured files.</li> <li>Calls the parse function to parse the resulting <code>JSON</code> files.</li> <li>Calls the clear_cache function to clear the cache.</li> </ol> <p>If the script is run as a <code>main</code> program (i.e. if the name of the script is <code>__main__</code>), the <code>run()</code> function is executed.</p> <p>Note: at present this does not include any functunality in <code>create_adjacent_tables.py</code></p>"},{"location":"reference/alto2txt2fixture/__main__.html#alto2txt2fixture.__main__.parse_args","title":"parse_args","text":"<pre><code>parse_args(argv: list[str] | None = None) -&gt; Namespace\n</code></pre> <p>Manage command line arguments for <code>run()</code></p> <p>This constructs an <code>ArgumentParser</code> instance to manage configurating calls of <code>run()</code> to manage <code>newspaper</code> <code>XML</code> to <code>JSON</code> converstion.</p> <p>Parameters:</p> Name Type Description Default <code>argv</code> <code>list[str] | None</code> <p>If <code>None</code> treat as equivalent of ['--help<code>], if a</code>list<code>of</code>str<code>pass those options to</code>ArgumentParser`</p> <code>None</code> <p>Returns:</p> Type Description <code>Namespace</code> <p>A <code>Namespace</code> <code>dict</code>-like configuration for <code>run()</code></p> Source code in <code>alto2txt2fixture/__main__.py</code> <pre><code>def parse_args(argv: list[str] | None = None) -&gt; Namespace:\n    \"\"\"Manage command line arguments for `run()`\n\n    This constructs an `ArgumentParser` instance to manage\n    configurating calls of `run()` to manage `newspaper`\n    `XML` to `JSON` converstion.\n\n    Arguments:\n        argv:\n            If `None` treat as equivalent of ['--help`],\n            if a `list` of `str` pass those options to `ArgumentParser`\n\n    Returns:\n        A `Namespace` `dict`-like configuration for `run()`\n    \"\"\"\n    argv = None if not argv else argv\n    parser = ArgumentParser(\n        prog=\"a2t2f-news\",\n        description=\"Process alto2txt XML into and Django JSON Fixture files\",\n        epilog=(\n            \"Note: this is still in beta mode and contributions welcome\\n\\n\" + __doc__\n        ),\n        formatter_class=RawTextHelpFormatter,\n    )\n    parser.add_argument(\n        \"-c\",\n        \"--collections\",\n        nargs=\"+\",\n        help=\"&lt;Optional&gt; Set collections\",\n        required=False,\n    )\n    parser.add_argument(\n        \"-m\",\n        \"--mountpoint\",\n        type=str,\n        help=\"&lt;Optional&gt; Mountpoint\",\n        required=False,\n    )\n    parser.add_argument(\n        \"-o\",\n        \"--output\",\n        type=str,\n        help=\"&lt;Optional&gt; Set an output directory\",\n        required=False,\n    )\n    parser.add_argument(\n        \"-t\",\n        \"--test-config\",\n        default=False,\n        help=\"Only print the configuration\",\n        action=BooleanOptionalAction,\n    )\n    parser.add_argument(\n        \"-f\",\n        \"--show-fixture-tables\",\n        default=True,\n        help=\"Print included fixture table configurations\",\n        action=BooleanOptionalAction,\n    )\n    parser.add_argument(\n        \"--export-fixture-tables\",\n        default=True,\n        help=\"Experimental: export fixture tables prior to data processing\",\n        action=BooleanOptionalAction,\n    )\n    parser.add_argument(\n        \"--data-provider-field\",\n        type=str,\n        default=DATA_PROVIDER_INDEX,\n        help=\"Key for indexing DataProvider records\",\n    )\n    return parser.parse_args(argv)\n</code></pre>"},{"location":"reference/alto2txt2fixture/__main__.html#alto2txt2fixture.__main__.run","title":"run","text":"<pre><code>run(local_args: list[str] | None = None) -&gt; None\n</code></pre> <p>Manage running newspaper <code>XML</code> to <code>JSON</code> conversion.</p> <p>First <code>parse_args</code> is called for command line arguments including:</p> <ul> <li><code>collections</code></li> <li><code>output</code></li> <li><code>mountpoint</code></li> </ul> <p>If any of these arguments are specified, they will be used, otherwise they will default to the values in the <code>settings</code> module.</p> <p>The <code>show_setup</code> function is then called to display the configurations being used.</p> <p>The <code>route</code> function is then called to route the alto2txt files into subdirectories with structured files.</p> <p>The <code>parse</code> function is then called to parse the resulting JSON files.</p> <p>Finally, the <code>clear_cache</code> function is called to clear the cache (pending the user's confirmation).</p> <p>Parameters:</p> Name Type Description Default <code>local_args</code> <code>list[str] | None</code> <p>Options passed to <code>parse_args()</code></p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alto2txt2fixture/__main__.py</code> <pre><code>def run(local_args: list[str] | None = None) -&gt; None:\n    \"\"\"Manage running newspaper `XML` to `JSON` conversion.\n\n    First `parse_args` is called for command line arguments including:\n\n    - `collections`\n    - `output`\n    - `mountpoint`\n\n    If any of these arguments are specified, they will be used, otherwise they\n    will default to the values in the `settings` module.\n\n    The `show_setup` function is then called to display the configurations\n    being used.\n\n    The `route` function is then called to route the alto2txt files into\n    subdirectories with structured files.\n\n    The `parse` function is then called to parse the resulting JSON files.\n\n    Finally, the `clear_cache` function is called to clear the cache\n    (pending the user's confirmation).\n\n    Arguments:\n        local_args: Options passed to `parse_args()`\n\n    Returns:\n        None\n    \"\"\"\n    args: Namespace = parse_args(argv=local_args)\n\n    if args.collections:\n        COLLECTIONS = [x.lower() for x in args.collections]\n    else:\n        COLLECTIONS = settings.COLLECTIONS\n\n    if args.output:\n        OUTPUT = args.output.rstrip(\"/\")\n    else:\n        OUTPUT = settings.OUTPUT\n\n    if args.mountpoint:\n        MOUNTPOINT = args.mountpoint.rstrip(\"/\")\n    else:\n        MOUNTPOINT = settings.MOUNTPOINT\n\n    show_setup(\n        COLLECTIONS=COLLECTIONS,\n        OUTPUT=OUTPUT,\n        CACHE_HOME=settings.CACHE_HOME,\n        MOUNTPOINT=MOUNTPOINT,\n        JISC_PAPERS_CSV=settings.JISC_PAPERS_CSV,\n        REPORT_DIR=settings.REPORT_DIR,\n        MAX_ELEMENTS_PER_FILE=settings.MAX_ELEMENTS_PER_FILE,\n    )\n\n    if args.show_fixture_tables:\n        # Show a table of fixtures used, defaults to DataProvider Table\n        show_fixture_tables(settings, data_provider_index=args.data_provider_field)\n\n    if args.export_fixture_tables:\n        export_fixtures(\n            fixture_tables=settings.FIXTURE_TABLES,\n            path=OUTPUT,\n            formats=settings.FIXTURE_TABLES_FORMATS,\n        )\n\n    if not args.test_config:\n        # Routing alto2txt into subdirectories with structured files\n        route(\n            COLLECTIONS,\n            settings.CACHE_HOME,\n            MOUNTPOINT,\n            settings.JISC_PAPERS_CSV,\n            settings.REPORT_DIR,\n        )\n\n        # Parsing the resulting JSON files\n        parse(\n            COLLECTIONS,\n            settings.CACHE_HOME,\n            OUTPUT,\n            settings.MAX_ELEMENTS_PER_FILE,\n        )\n\n        clear_cache(settings.CACHE_HOME)\n</code></pre>"},{"location":"reference/alto2txt2fixture/cli.html","title":"cli","text":""},{"location":"reference/alto2txt2fixture/cli.html#alto2txt2fixture.cli.adj_metadata","title":"adj_metadata","text":"<pre><code>adj_metadata(\n    over_write: Annotated[\n        bool, Option(--over - write, -f, help=\"Overwrite local data files\")\n    ] = False,\n    output_path: Annotated[\n        Path, Option(--output, -o, help=\"Set output directory\")\n    ] = Path(create_adj.OUTPUT),\n) -&gt; list[PathLike]\n</code></pre> <p>Download, process, link and export <code>Mitchells</code> and <code>Gazetteer</code> fixtures.</p> Note <p>This will require access to <code>https://zooniversedata.blob.core.windows.net/downloads/</code>.</p> Source code in <code>alto2txt2fixture/cli.py</code> <pre><code>@cli.command()\ndef adj_metadata(\n    over_write: Annotated[\n        bool, typer.Option(\"--over-write\", \"-f\", help=\"Overwrite local data files\")\n    ] = False,\n    output_path: Annotated[\n        Path, typer.Option(\"--output\", \"-o\", help=\"Set output directory\")\n    ] = Path(create_adj.OUTPUT),\n) -&gt; list[os.PathLike]:\n    \"\"\"Download, process, link and export `Mitchells` and `Gazetteer` fixtures.\n\n    Note:\n        This will require access to `https://zooniversedata.blob.core.windows.net/downloads/`.\n    \"\"\"\n    return create_adj.run(\n        files_dict={},\n        files_to_download_overwrite=over_write,\n        saved=create_adj.SAVED,\n        output_path=output_path,\n    )\n</code></pre>"},{"location":"reference/alto2txt2fixture/cli.html#alto2txt2fixture.cli.file_rename_table","title":"file_rename_table","text":"<pre><code>file_rename_table(\n    paths_dict: dict[PathLike, PathLike],\n    compress_format: ArchiveFormatEnum = COMPRESSION_TYPE_DEFAULT,\n    title: str = FILE_RENAME_TABLE_TITLE_DEFAULT,\n    prefix: str = \"\",\n    renumber: bool = True,\n) -&gt; Table\n</code></pre> <p>Create a <code>rich.Table</code> of rename configuration.</p> <p>Parameters:</p> Name Type Description Default <code>paths_dict</code> <code>dict[PathLike, PathLike]</code> <p>dict[os.PathLike, os.PathLike], Original and renumbered <code>paths</code> <code>dict</code></p> required <code>compress_format</code> <code>ArchiveFormatEnum</code> <p>Which <code>ArchiveFormatEnum</code> for compression</p> <code>COMPRESSION_TYPE_DEFAULT</code> <code>title</code> <code>str</code> <p>Title of returned <code>Table</code></p> <code>FILE_RENAME_TABLE_TITLE_DEFAULT</code> <code>prefix</code> <code>str</code> <p><code>str</code> to add in front of every new path</p> <code>''</code> <code>renumber</code> <code>bool</code> <p>Whether an <code>int</code> in each path will be renumbered.</p> <code>True</code> Source code in <code>alto2txt2fixture/cli.py</code> <pre><code>def file_rename_table(\n    paths_dict: dict[os.PathLike, os.PathLike],\n    compress_format: ArchiveFormatEnum = COMPRESSION_TYPE_DEFAULT,\n    title: str = FILE_RENAME_TABLE_TITLE_DEFAULT,\n    prefix: str = \"\",\n    renumber: bool = True,\n) -&gt; Table:\n    \"\"\"Create a `rich.Table` of rename configuration.\n\n    Args:\n        paths_dict: dict[os.PathLike, os.PathLike],\n            Original and renumbered `paths` `dict`\n        compress_format:\n            Which `ArchiveFormatEnum` for compression\n        title:\n            Title of returned `Table`\n        prefix:\n            `str` to add in front of every new path\n        renumber:\n            Whether an `int` in each path will be renumbered.\n\n    \"\"\"\n    table: Table = Table(title=title)\n    table.add_column(\"Current File Name\", justify=\"right\", style=\"cyan\")\n    table.add_column(\"New File Name\", style=\"magenta\")\n\n    def final_file_name(name: os.PathLike) -&gt; str:\n        return (\n            prefix\n            + str(Path(name).name)\n            + (f\".{compress_format}\" if compress_format else \"\")\n        )\n\n    for old_path, new_path in paths_dict.items():\n        name: str = final_file_name(new_path if renumber else old_path)\n        table.add_row(Path(old_path).name, name)\n    return table\n</code></pre>"},{"location":"reference/alto2txt2fixture/cli.html#alto2txt2fixture.cli.func_table","title":"func_table","text":"<pre><code>func_table(\n    func: Callable,\n    values: dict,\n    title: str = \"\",\n    extra_dict: dict[str, Any] = {},\n) -&gt; Table\n</code></pre> <p>Geneate <code>rich</code> <code>Table</code> from <code>func</code> signature and <code>help</code> attr.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable</code> <p>Function whose <code>args</code> and <code>type</code> hints will be converted to a table.</p> required <code>values</code> <code>dict</code> <p><code>dict</code> of variables covered in <code>func</code> signature. <code>local()</code> often suffices.</p> required <code>title</code> <code>str</code> <p><code>str</code> for table title.</p> <code>''</code> <code>extra_dict</code> <code>dict[str, Any]</code> <p>A <code>dict</code> of additional rows to add to the table. For each <code>key</code>, <code>value</code> pair: if the <code>value</code> is a <code>tuple</code>, it will be expanded to match the <code>Type</code>, <code>Value</code>, and <code>Notes</code> columns; else the <code>Type</code> will be inferred and <code>Notes</code> left blank.</p> <code>{}</code> Example <pre><code>&gt;&gt;&gt; def test_func(\n...     var_a: Annotated[str, typer.Option(help=\"Example\")] = \"Default\"\n... ) -&gt; None:\n...     test_func_table: Table = func_table(test_func, values=vars())\n...     console.print(test_func_table)\n&gt;&gt;&gt; if is_platform_win:\n...     pytest.skip('fails on certain Windows root paths: issue #56')\n&gt;&gt;&gt; test_func()\n           test_func config\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Variable \u2503 Type \u2503 Value   \u2503 Notes   \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502    var_a \u2502 str  \u2502 Default \u2502 Example \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Source code in <code>alto2txt2fixture/cli.py</code> <pre><code>def func_table(\n    func: Callable, values: dict, title: str = \"\", extra_dict: dict[str, Any] = {}\n) -&gt; Table:\n    \"\"\"Geneate `rich` `Table` from `func` signature and `help` attr.\n\n    Args:\n        func:\n            Function whose `args` and `type` hints will be converted\n            to a table.\n\n        values:\n            `dict` of variables covered in `func` signature.\n            `local()` often suffices.\n\n        title:\n            `str` for table title.\n\n        extra_dict:\n            A `dict` of additional rows to add to the table. For each\n            `key`, `value` pair: if the `value` is a `tuple`, it will\n            be expanded to match the `Type`, `Value`, and `Notes`\n            columns; else the `Type` will be inferred and `Notes`\n            left blank.\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; def test_func(\n        ...     var_a: Annotated[str, typer.Option(help=\"Example\")] = \"Default\"\n        ... ) -&gt; None:\n        ...     test_func_table: Table = func_table(test_func, values=vars())\n        ...     console.print(test_func_table)\n        &gt;&gt;&gt; if is_platform_win:\n        ...     pytest.skip('fails on certain Windows root paths: issue #56')\n        &gt;&gt;&gt; test_func()\n                   test_func config\n        \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n        \u2503 Variable \u2503 Type \u2503 Value   \u2503 Notes   \u2503\n        \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n        \u2502    var_a \u2502 str  \u2502 Default \u2502 Example \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n        ```\n    \"\"\"\n    title = title if title else f\"{func.__name__} config\"\n    func_signature: dict = get_type_hints(func, include_extras=True)\n    table: Table = Table(title=title)\n    table.add_column(\"Variable\", justify=\"right\", style=\"cyan\")\n    table.add_column(\"Type\", style=\"yellow\")\n    table.add_column(\"Value\", style=\"magenta\")\n    table.add_column(\"Notes\")\n    for var, info in func_signature.items():\n        try:\n            var_type, annotation = get_args(info)\n            value: Any = values[var]\n            if value in (\"\", \"\"):\n                value = \"''\"\n            table.add_row(str(var), var_type.__name__, str(value), annotation.help)\n        except ValueError:\n            continue\n    for key, val in extra_dict.items():\n        if isinstance(val, tuple):\n            table.add_row(key, *val)\n        else:\n            table.add_row(key, type(val).__name__, str(val))\n    return table\n</code></pre>"},{"location":"reference/alto2txt2fixture/cli.html#alto2txt2fixture.cli.metadata","title":"metadata","text":"<pre><code>metadata(\n    collections: Annotated[\n        list[str], Option(--collections, -c, help=\"Set collections\")\n    ] = settings.COLLECTIONS,\n    mountpoint: Annotated[\n        Path, Option(--mountpoint, -m, help=\"Mountpoint of xml files\")\n    ] = Path(settings.MOUNTPOINT),\n    output: Annotated[\n        Path, Option(--output, -o, help=\"Set an output directory\")\n    ] = Path(settings.OUTPUT),\n    run: Annotated[\n        bool, Option(--run / --dry - run, help=\"Whether to execute\")\n    ] = False,\n    print_fixture_tables: Annotated[\n        bool,\n        Option(\n            --show - fixture - tables,\n            -f,\n            help=\"Print included fixture table configurations\",\n        ),\n    ] = True,\n    export_fixture_tables: Annotated[\n        bool,\n        Option(\n            --export - fixture - tables,\n            help=\"Export fixture tables prior to data processing\",\n        ),\n    ] = True,\n    use_legacy_codes: Annotated[\n        bool,\n        Option(\n            help=\"Whether to legacy (backwards compatibler) data provider codes\"\n        ),\n    ] = True,\n) -&gt; None\n</code></pre> <p>Manage running newspaper <code>XML</code> to <code>JSON</code> conversion.</p> <p>The core opitions for <code>XML</code> processing are:</p> <ul> <li><code>collections</code></li> <li><code>output</code></li> <li><code>mountpoint</code></li> </ul> <p>If any of these arguments are specified, they will be used, otherwise they will default to the values in the <code>settings</code> module.</p> <p>The <code>show_setup</code> function is then called to display the configurations being used.</p> <p>The <code>route</code> function is then called to route the alto2txt files into subdirectories with structured files.</p> <p>The <code>parse</code> function is then called to parse the resulting JSON files.</p> <p>Finally, the <code>clear_cache</code> function is called to clear the cache (pending the user's confirmation).</p> <p>Parameters:</p> Name Type Description Default <code>collections</code> <code>Annotated[list[str], Option(--collections, -c, help='Set collections')]</code> <p>Which of the pre-configured <code>XML</code> collections to process.</p> <code>COLLECTIONS</code> <code>output</code> <code>Annotated[Path, Option(--output, -o, help='Set an output directory')]</code> <p>Which folder to save <code>JSON</code> fixtures to</p> <code>Path(OUTPUT)</code> <code>mountpoint</code> <code>Annotated[Path, Option(--mountpoint, -m, help='Mountpoint of xml files')]</code> <p>Path to <code>XML</code> files to process</p> <code>Path(MOUNTPOINT)</code> <code>print_fixture_tables</code> <code>Annotated[bool, Option(--show - fixture - tables, -f, help='Print included fixture table configurations')]</code> <p>Show a table of fixtures used, defaults to <code>DataProvider</code></p> <code>True</code> <code>export_fixture_tables</code> <code>Annotated[bool, Option(--export - fixture - tables, help='Export fixture tables prior to data processing')]</code> <p>Whether to export fixture tables prior to processing.</p> <code>True</code> <code>use_legacy_codes</code> <code>Annotated[bool, Option(help='Whether to legacy (backwards compatibler) data provider codes')]</code> <p>Allow using legacy code spec</p> <code>True</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alto2txt2fixture/cli.py</code> <pre><code>@cli.command()\ndef metadata(\n    collections: Annotated[\n        list[str], typer.Option(\"--collections\", \"-c\", help=\"Set collections\")\n    ] = settings.COLLECTIONS,\n    mountpoint: Annotated[\n        Path, typer.Option(\"--mountpoint\", \"-m\", help=\"Mountpoint of xml files\")\n    ] = Path(settings.MOUNTPOINT),\n    output: Annotated[\n        Path, typer.Option(\"--output\", \"-o\", help=\"Set an output directory\")\n    ] = Path(settings.OUTPUT),\n    run: Annotated[\n        bool,\n        typer.Option(\"--run/--dry-run\", help=\"Whether to execute\"),\n    ] = False,\n    print_fixture_tables: Annotated[\n        bool,\n        typer.Option(\n            \"--show-fixture-tables\",\n            \"-f\",\n            help=\"Print included fixture table configurations\",\n        ),\n    ] = True,\n    export_fixture_tables: Annotated[\n        bool,\n        typer.Option(\n            \"--export-fixture-tables\",\n            help=\"Export fixture tables prior to data processing\",\n        ),\n    ] = True,\n    # data_provider_index: Annotated[str, typer.Option(\"--data-provider-field\", help=\"Key for indexing DataProvider records\")] = DATA_PROVIDER_INDEX,\n    # legacy_codes: Annotated[\n    #     bool, typer.Option(help=\"Whether to legacy (backwards compatibler) data provider codes\")\n    #     ] = True,\n    use_legacy_codes: Annotated[\n        bool,\n        typer.Option(\n            help=\"Whether to legacy (backwards compatibler) data provider codes\"\n        ),\n    ] = True,\n) -&gt; None:\n    \"\"\"Manage running newspaper `XML` to `JSON` conversion.\n\n    The core opitions for `XML` processing are:\n\n    - `collections`\n    - `output`\n    - `mountpoint`\n\n    If any of these arguments are specified, they will be used, otherwise they\n    will default to the values in the `settings` module.\n\n    The `show_setup` function is then called to display the configurations\n    being used.\n\n    The `route` function is then called to route the alto2txt files into\n    subdirectories with structured files.\n\n    The `parse` function is then called to parse the resulting JSON files.\n\n    Finally, the `clear_cache` function is called to clear the cache\n    (pending the user's confirmation).\n\n    Arguments:\n        collections: Which of the pre-configured `XML` collections to process.\n        output: Which folder to save `JSON` fixtures to\n        mountpoint: Path to `XML` files to process\n        print_fixture_tables: Show a table of fixtures used, defaults to `DataProvider`\n        export_fixture_tables: Whether to export fixture tables prior to processing.\n        use_legacy_codes: Allow using legacy code spec\n\n    Returns:\n        None\n    \"\"\"\n    if use_legacy_codes:\n        collections = [\n            NEWSPAPER_DATA_PROVIDER_CODE_DICT[collection][\"fields\"][\"legacy_code\"]\n            for collection in collections\n        ]\n    show_setup(\n        COLLECTIONS=collections,\n        OUTPUT=output,\n        CACHE_HOME=settings.CACHE_HOME,\n        MOUNTPOINT=mountpoint,\n        JISC_PAPERS_CSV=settings.JISC_PAPERS_CSV,\n        REPORT_DIR=settings.REPORT_DIR,\n        MAX_ELEMENTS_PER_FILE=settings.MAX_ELEMENTS_PER_FILE,\n    )\n\n    # if print_fixture_tables:\n    #     # Show a table of fixtures used, defaults to DataProvider Table\n    #     show_fixture_tables(settings, data_provider_index=data_provider_index)\n\n    if export_fixture_tables:\n        export_fixtures(\n            fixture_tables=settings.FIXTURE_TABLES,\n            path=output,\n            formats=settings.FIXTURE_TABLES_FORMATS,\n        )\n\n    if run:\n        # Routing alto2txt into subdirectories with structured files\n        route(\n            collections=collections,\n            cache_home=str(settings.CACHE_HOME),\n            mountpoint=str(mountpoint),\n            jisc_papers_path=str(settings.JISC_PAPERS_CSV),\n            report_dir=str(settings.REPORT_DIR),\n        )\n\n        # Parsing the resulting JSON files\n        parse(\n            collections=collections,\n            cache_home=str(settings.CACHE_HOME),\n            output=str(output),\n            max_elements_per_file=int(settings.MAX_ELEMENTS_PER_FILE),\n        )\n\n        clear_cache(dir=str(settings.CACHE_HOME))\n</code></pre>"},{"location":"reference/alto2txt2fixture/cli.html#alto2txt2fixture.cli.plaintext","title":"plaintext","text":"<pre><code>plaintext(\n    path: Annotated[Path, Argument(help=\"Path to raw plaintext files\")],\n    run: Annotated[\n        bool, Option(--run / --dry - run, help=\"Whether to execute\")\n    ] = False,\n    save_path: Annotated[\n        Path, Option(help=\"Path to save json export files\")\n    ] = Path(DEFAULT_PLAINTEXT_FIXTURE_OUTPUT),\n    data_provider_code: Annotated[\n        str, Option(help=\"Data provider code use existing config\")\n    ] = \"\",\n    extract_path: Annotated[\n        Path, Option(help=\"Folder to extract compressed raw plaintext to\")\n    ] = Path(DEFAULT_EXTRACTED_SUBDIR),\n    clear_extract_path: Annotated[\n        bool, Option(help=\"Delete any existing files in extract_path\")\n    ] = False,\n    skip_extract: Annotated[\n        bool, Option(help=\"Skip extracting files if extract_path is not empty\")\n    ] = False,\n    initial_pk: Annotated[\n        int, Option(help=\"First primary key to increment json export from\")\n    ] = DEFAULT_INITIAL_PK,\n    records_per_json: Annotated[\n        int, Option(help=\"Max records per json fixture\")\n    ] = DEFAULT_MAX_PLAINTEXT_PER_FIXTURE_FILE,\n    is_canonical: Annotated[\n        bool, Option(help=\"Whether to mark records as canonical\")\n    ] = False,\n    digit_padding: Annotated[\n        int, Option(help=\"Padding '0's for indexing json fixture filenames\")\n    ] = FILE_NAME_0_PADDING_DEFAULT,\n    compress: Annotated[bool, Option(help=\"Compress json fixtures\")] = False,\n    compress_path: Annotated[\n        Path, Option(help=\"Folder to compress json fixtures to\")\n    ] = Path(COMPRESSED_PATH_DEFAULT),\n    compress_format: Annotated[\n        ArchiveFormatEnum,\n        Option(case_sensitive=False, help=\"Compression format\"),\n    ] = COMPRESSION_TYPE_DEFAULT,\n    fixture_info: Annotated[\n        str, Option(help=\"Info string to include in export records\")\n    ] = \"\",\n    include_fixture_paths: Annotated[\n        bool, Option(help=\"Whether to include json_fixture_paths\")\n    ] = True,\n    log_level: Annotated[\n        int, Option(help=\"Set logging level for debugging\")\n    ] = WARNING,\n) -&gt; None\n</code></pre> <p>Create a PlainTextFixture and save to <code>save_path</code>.</p> Source code in <code>alto2txt2fixture/cli.py</code> <pre><code>@cli.command()\ndef plaintext(\n    path: Annotated[Path, typer.Argument(help=\"Path to raw plaintext files\")],\n    run: Annotated[\n        bool,\n        typer.Option(\"--run/--dry-run\", help=\"Whether to execute\"),\n    ] = False,\n    save_path: Annotated[\n        Path, typer.Option(help=\"Path to save json export files\")\n    ] = Path(DEFAULT_PLAINTEXT_FIXTURE_OUTPUT),\n    data_provider_code: Annotated[\n        str, typer.Option(help=\"Data provider code use existing config\")\n    ] = \"\",\n    extract_path: Annotated[\n        Path, typer.Option(help=\"Folder to extract compressed raw plaintext to\")\n    ] = Path(DEFAULT_EXTRACTED_SUBDIR),\n    clear_extract_path: Annotated[\n        bool, typer.Option(help=\"Delete any existing files in extract_path\")\n    ] = False,\n    skip_extract: Annotated[\n        bool, typer.Option(help=\"Skip extracting files if extract_path is not empty\")\n    ] = False,\n    initial_pk: Annotated[\n        int, typer.Option(help=\"First primary key to increment json export from\")\n    ] = DEFAULT_INITIAL_PK,\n    records_per_json: Annotated[\n        int, typer.Option(help=\"Max records per json fixture\")\n    ] = DEFAULT_MAX_PLAINTEXT_PER_FIXTURE_FILE,\n    is_canonical: Annotated[\n        bool, typer.Option(help=\"Whether to mark records as canonical\")\n    ] = False,\n    digit_padding: Annotated[\n        int, typer.Option(help=\"Padding '0's for indexing json fixture filenames\")\n    ] = FILE_NAME_0_PADDING_DEFAULT,\n    compress: Annotated[bool, typer.Option(help=\"Compress json fixtures\")] = False,\n    compress_path: Annotated[\n        Path, typer.Option(help=\"Folder to compress json fixtures to\")\n    ] = Path(COMPRESSED_PATH_DEFAULT),\n    compress_format: Annotated[\n        ArchiveFormatEnum,\n        typer.Option(case_sensitive=False, help=\"Compression format\"),\n    ] = COMPRESSION_TYPE_DEFAULT,\n    fixture_info: Annotated[\n        str, typer.Option(help=\"Info string to include in export records\")\n    ] = \"\",\n    include_fixture_paths: Annotated[\n        bool, typer.Option(help=\"Whether to include json_fixture_paths\")\n    ] = True,\n    log_level: Annotated[\n        int, typer.Option(help=\"Set logging level for debugging\")\n    ] = WARNING,\n    # legacy_codes: Annotated[\n    #     bool, typer.Option(help=\"Whether to legacy (backwards compatibler) data provider codes\")\n    #     ] = True,\n) -&gt; None:\n    \"\"\"Create a PlainTextFixture and save to `save_path`.\"\"\"\n    logger.level = log_level\n    # if legacy_codes and data_provider_code in settings.NEWSPAPER_DATA_PROVIDER_CODE_DICT:\n    #     data_provider_code = settings.NEWSPAPER_COLLECTION_METADATA[data_provider_code]['legacy_code']\n\n    plaintext_fixture = PlainTextFixture(\n        path=path,\n        data_provider_code=data_provider_code,\n        extract_subdir=extract_path,\n        export_directory=save_path,\n        initial_pk=initial_pk,\n        max_plaintext_per_fixture_file=records_per_json,\n        json_0_file_name_padding=digit_padding,\n        json_export_compression_format=compress_format,\n        json_export_compression_subdir=compress_path,\n        fixture_info=fixture_info,\n        is_canonical=is_canonical,\n        include_text_fixture_paths=include_fixture_paths,\n    )\n    plaintext_fixture.info()\n    while (\n        not plaintext_fixture.compressed_files\n        and not plaintext_fixture.plaintext_provided_uncompressed\n    ):\n        try_another_compressed_txt_source: bool = Confirm.ask(\n            f\"No .txt files available from extract path: \"\n            f\"{plaintext_fixture.trunc_extract_path_str}\\n\"\n            f\"Would you like to extract fixtures from a different path?\",\n            default=\"n\",\n        )\n        if try_another_compressed_txt_source:\n            new_extract_path: str = Prompt.ask(\"Please enter a new extract path\")\n            plaintext_fixture.path = Path(new_extract_path)\n        else:\n            return\n        plaintext_fixture.info()\n    if not run:\n        raise typer.Exit()\n    plaintext_fixture.extract_compressed(\n        overwite_extracts=clear_extract_path,\n        use_saved_if_exists=skip_extract,\n    )\n    plaintext_fixture.export_to_json_fixtures()\n    console.print(f\"Exports to 'json' fixtures finished at {datetime.now()}\")\n    console.print(f\"'json' exports saved to: '{save_path.absolute()}\")\n    if compress:\n        console.print(\n            f\"Compressing 'json' fixtures to {compress_format} at {compress_path.absolute()}\"\n        )\n        json_exports: tuple[Path, ...] = tuple(\n            plaintext_fixture.compress_json_exports()\n        )\n        export_count: int = len(json_exports)\n        console.print(f\"{export_count} 'json' fixtures compressed at {datetime.now()}\")\n        if export_count &gt; 10:\n            for compressed_path in json_exports[:3]:\n                console.print(compressed_path)\n            console.print(\"...\")\n            for compressed_path in json_exports[-3:]:\n                console.print(compressed_path)\n        else:\n            for compressed_path in json_exports:\n                console.print(compressed_path)\n</code></pre>"},{"location":"reference/alto2txt2fixture/cli.html#alto2txt2fixture.cli.rename","title":"rename","text":"<pre><code>rename(\n    path: Annotated[Path, Argument(help=\"Path to files to manage\")],\n    folder: Annotated[\n        Path, Option(help=\"Path under `path` for new files\")\n    ] = Path(),\n    renumber: Annotated[\n        bool, Option(help=\"Show changes without applying\")\n    ] = False,\n    regex: Annotated[str, Option(help=\"Regex to filter files\")] = \"*.txt\",\n    padding: Annotated[\n        int, Option(help=\"Digits to pad file name\")\n    ] = FILE_NAME_0_PADDING_DEFAULT,\n    prefix: Annotated[str, Option(help=\"Prefix for new file names\")] = \"\",\n    run: Annotated[\n        bool, Option(--run / --dry - run, help=\"Whether to apply changes\")\n    ] = False,\n    compress: Annotated[bool, Option(help=\"Whether to compress files\")] = False,\n    compress_format: Annotated[\n        ArchiveFormatEnum,\n        Option(case_sensitive=False, help=\"Compression format\"),\n    ] = COMPRESSION_TYPE_DEFAULT,\n    compress_suffix: Annotated[\n        str, Option(help=\"Compressed file name suffix\")\n    ] = \"\",\n    compress_folder: Annotated[\n        Path, Option(help=\"Optional folder to differ from renaming\")\n    ] = COMPRESSED_PATH_DEFAULT,\n    delete_uncompressed: Annotated[\n        bool, Option(help=\"Delete unneeded files after compression\")\n    ] = False,\n    log_level: Annotated[\n        int, Option(help=\"Set logging level for debugging\")\n    ] = WARNING,\n    force: Annotated[\n        bool, Option(--force, help=\"Force run without prompt\")\n    ] = False,\n) -&gt; None\n</code></pre> <p>Manage file names and compression.</p> Source code in <code>alto2txt2fixture/cli.py</code> <pre><code>@cli.command()\ndef rename(\n    path: Annotated[Path, typer.Argument(help=\"Path to files to manage\")],\n    folder: Annotated[\n        Path, typer.Option(help=\"Path under `path` for new files\")\n    ] = Path(),\n    renumber: Annotated[\n        bool, typer.Option(help=\"Show changes without applying\")\n    ] = False,\n    regex: Annotated[str, typer.Option(help=\"Regex to filter files\")] = \"*.txt\",\n    padding: Annotated[\n        int, typer.Option(help=\"Digits to pad file name\")\n    ] = FILE_NAME_0_PADDING_DEFAULT,\n    prefix: Annotated[str, typer.Option(help=\"Prefix for new file names\")] = \"\",\n    run: Annotated[\n        bool, typer.Option(\"--run/--dry-run\", help=\"Whether to apply changes\")\n    ] = False,\n    compress: Annotated[bool, typer.Option(help=\"Whether to compress files\")] = False,\n    compress_format: Annotated[\n        ArchiveFormatEnum,\n        typer.Option(case_sensitive=False, help=\"Compression format\"),\n    ] = COMPRESSION_TYPE_DEFAULT,\n    compress_suffix: Annotated[\n        str, typer.Option(help=\"Compressed file name suffix\")\n    ] = \"\",\n    compress_folder: Annotated[\n        Path, typer.Option(help=\"Optional folder to differ from renaming\")\n    ] = COMPRESSED_PATH_DEFAULT,\n    delete_uncompressed: Annotated[\n        bool, typer.Option(help=\"Delete unneeded files after compression\")\n    ] = False,\n    log_level: Annotated[\n        int, typer.Option(help=\"Set logging level for debugging\")\n    ] = WARNING,\n    force: Annotated[\n        bool, typer.Option(\"--force\", help=\"Force run without prompt\")\n    ] = False,\n) -&gt; None:\n    \"\"\"Manage file names and compression.\"\"\"\n    logger.level = log_level\n    folder_path: Path = Path(path) / folder\n    compress_path: Path = Path(path) / compress_folder\n\n    try:\n        paths_dict: dict[os.PathLike, os.PathLike] = glob_path_rename_by_0_padding(\n            path=path,\n            output_path=folder,\n            glob_regex_str=regex,\n            padding=padding,\n        )\n        assert paths_dict\n    except (ValueError, AssertionError, IndexError) as err:\n        console.print(f\"Error: '{err}'\\nTried reading from path: '{path}'\")\n        raise typer.Abort()\n    files_count: int = len(paths_dict)\n\n    if not compress and not force:\n        compress = Confirm.ask(\n            f\"Compress all ({files_count}) output file(s)?\",\n            default=\"n\",\n        )\n    if compress and not force:\n        compress_format = Prompt.ask(\n            \"Compression format\",\n            choices=list(str(format) for format in ArchiveFormatEnum),\n            default=compress_format,\n        )\n    extra_info_dict: dict[str, int | os.PathLike] = {\n        \"rename_path\": folder_path,\n        \"compress_path\": compress_path,\n        \"HD Space (GB)\": int(free_hd_space_in_GB()),\n    }\n    config_table: Table = func_table(\n        rename,\n        values=locals(),\n        extra_dict=extra_info_dict,\n    )\n    console.print(config_table)\n\n    file_names_table: Table = file_rename_table(\n        paths_dict,\n        compress_format=compress_format,\n        title=FILE_RENAME_TABLE_TITLE_DEFAULT,\n        prefix=prefix,\n        renumber=renumber,\n    )\n    console.print(file_names_table)\n\n    if not run:\n        if not force:\n            renumber = Confirm.ask(\n                f\"Copy {'and compress ' if compress else ''}\"\n                f\"{files_count} files \"\n                f\"from:\\n\\t'{path}'\\nto:\\n\\t'{folder_path}'\\n\"\n            )\n            if not delete_uncompressed:\n                delete_uncompressed = Confirm.ask(\n                    f\"Delete all uncompressed, renamed files \"\n                    f\"in:\\n'{folder_path}'\\n\"\n                    f\"after compression to '{compress_format}' format in:\"\n                    f\"\\n'{compress_path}'\\n\",\n                    default=\"n\",\n                )\n        else:\n            typer.Exit()\n    if renumber:\n        copy_dict_paths(paths_dict)\n    if compress:\n        for old_path, new_path in paths_dict.items():\n            file_path: Path = Path(new_path) if renumber else Path(old_path)\n            compress_fixture(\n                file_path,\n                output_path=compress_path,\n                suffix=compress_suffix,\n                format=compress_format,\n            )\n            if delete_uncompressed and renumber:\n                console.print(f\"Deleting {new_path}\")\n                Path(new_path).unlink()\n</code></pre>"},{"location":"reference/alto2txt2fixture/cli.html#alto2txt2fixture.cli.show_fixture_tables","title":"show_fixture_tables","text":"<pre><code>show_fixture_tables(\n    run_settings: dotdict = settings,\n    print_in_call: bool = True,\n    data_provider_index: str = DATA_PROVIDER_INDEX,\n) -&gt; list[Table]\n</code></pre> <p>Print fixture tables specified in <code>settings.fixture_tables</code> in <code>rich.Table</code> format.</p> <p>Parameters:</p> Name Type Description Default <code>run_settings</code> <code>dotdict</code> <p><code>alto2txt2fixture</code> run configuration</p> <code>settings</code> <code>print_in_call</code> <code>bool</code> <p>whether to print to console (will use <code>console</code> variable if so)</p> <code>True</code> <code>data_provider_index</code> <code>str</code> <p>key to index <code>dataprovider</code> from <code>NEWSPAPER_COLLECTION_METADATA</code></p> <code>DATA_PROVIDER_INDEX</code> <p>Returns:</p> Type Description <code>list[Table]</code> <p>A <code>list</code> of <code>rich.Table</code> renders from configurations in <code>run_settings.FIXTURE_TABLES</code></p> Example <pre><code>&gt;&gt;&gt; fixture_tables: list[Table] = show_fixture_tables(\n...     settings,\n...     print_in_call=False)\n&gt;&gt;&gt; len(fixture_tables)\n1\n&gt;&gt;&gt; fixture_tables[0].title\n'dataprovider'\n&gt;&gt;&gt; [column.header for column in fixture_tables[0].columns]\n['pk', 'name', 'code', 'legacy_code', 'collection', 'source_note']\n&gt;&gt;&gt; fixture_tables = show_fixture_tables(settings)\n&lt;BLANKLINE&gt;\n...dataprovider...Heritage...\u2502 bl-hmd...\u2502 hmd...\n</code></pre> Note <p>It is possible for the example test to fail in different screen sizes. Try increasing the window or screen width of terminal used to check before raising an issue.</p> Source code in <code>alto2txt2fixture/cli.py</code> <pre><code>def show_fixture_tables(\n    run_settings: dotdict = settings,\n    print_in_call: bool = True,\n    data_provider_index: str = DATA_PROVIDER_INDEX,\n) -&gt; list[Table]:\n    \"\"\"Print fixture tables specified in ``settings.fixture_tables`` in `rich.Table` format.\n\n    Arguments:\n        run_settings: `alto2txt2fixture` run configuration\n        print_in_call: whether to print to console (will use ``console`` variable if so)\n        data_provider_index: key to index `dataprovider` from ``NEWSPAPER_COLLECTION_METADATA``\n\n    Returns:\n        A `list` of `rich.Table` renders from configurations in ``run_settings.FIXTURE_TABLES``\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; fixture_tables: list[Table] = show_fixture_tables(\n        ...     settings,\n        ...     print_in_call=False)\n        &gt;&gt;&gt; len(fixture_tables)\n        1\n        &gt;&gt;&gt; fixture_tables[0].title\n        'dataprovider'\n        &gt;&gt;&gt; [column.header for column in fixture_tables[0].columns]\n        ['pk', 'name', 'code', 'legacy_code', 'collection', 'source_note']\n        &gt;&gt;&gt; fixture_tables = show_fixture_tables(settings)\n        &lt;BLANKLINE&gt;\n        ...dataprovider...Heritage...\u2502 bl-hmd...\u2502 hmd...\n\n        ```\n\n    Note:\n        It is possible for the example test to fail in different screen sizes. Try\n        increasing the window or screen width of terminal used to check before\n        raising an issue.\n    \"\"\"\n    if run_settings.FIXTURE_TABLES:\n        if \"dataprovider\" in run_settings.FIXTURE_TABLES:\n            check_newspaper_collection_configuration(\n                run_settings.COLLECTIONS,\n                run_settings.FIXTURE_TABLES[\"dataprovider\"],\n                data_provider_index=data_provider_index,\n            )\n        console_tables: list[Table] = list(\n            gen_fixture_tables(run_settings.FIXTURE_TABLES)\n        )\n        if print_in_call:\n            for console_table in console_tables:\n                console.print(console_table)\n        return console_tables\n    else:\n        return []\n</code></pre>"},{"location":"reference/alto2txt2fixture/cli.html#alto2txt2fixture.cli.show_setup","title":"show_setup","text":"<pre><code>show_setup(clear: bool = True, title: str = SETUP_TITLE, **kwargs) -&gt; None\n</code></pre> <p>Generate a <code>rich.table.Table</code> for printing configuration to console.</p> Source code in <code>alto2txt2fixture/cli.py</code> <pre><code>def show_setup(clear: bool = True, title: str = SETUP_TITLE, **kwargs) -&gt; None:\n    \"\"\"Generate a `rich.table.Table` for printing configuration to console.\"\"\"\n    if clear and os.name == \"posix\":\n        os.system(\"clear\")\n    elif clear:\n        os.system(\"cls\")\n\n    table = Table(title=title)\n\n    table.add_column(\"Setting\", justify=\"right\", style=\"cyan\", no_wrap=True)\n    table.add_column(\"Value\", style=\"magenta\")\n\n    for key, value in kwargs.items():\n        table.add_row(str(key), str(value))\n\n    console.print(table)\n    return\n</code></pre>"},{"location":"reference/alto2txt2fixture/create_adjacent_tables.html","title":"create_adjacent_tables","text":""},{"location":"reference/alto2txt2fixture/create_adjacent_tables.html#alto2txt2fixture.create_adjacent_tables.correct_dict","title":"correct_dict","text":"<pre><code>correct_dict(o: dict) -&gt; list\n</code></pre> <p>Returns a list with corrected data from a provided dictionary.</p> Source code in <code>alto2txt2fixture/create_adjacent_tables.py</code> <pre><code>def correct_dict(o: dict) -&gt; list:\n    \"\"\"Returns a list with corrected data from a provided dictionary.\"\"\"\n    return [(k, v[0], v[1]) for k, v in o.items() if not v[0].startswith(\"Q\")] + [\n        (k, v[1], v[0]) for k, v in o.items() if v[0].startswith(\"Q\")\n    ]\n</code></pre>"},{"location":"reference/alto2txt2fixture/create_adjacent_tables.html#alto2txt2fixture.create_adjacent_tables.csv2json_list","title":"csv2json_list","text":"<pre><code>csv2json_list(\n    csv_path: PathLike,\n    output_path: Path = OUTPUT,\n    saved: list[Path] | None = None,\n    indent: int = JSON_INDENT,\n) -&gt; list\n</code></pre> <p>Save <code>csv_path</code> as a <code>json</code> file and return as a <code>list</code>.</p> Note <p>Managing <code>Pandas</code> <code>DataFrame</code> <code>nan</code> values via suggestion: https://stackoverflow.com/a/62691803/678486</p> Source code in <code>alto2txt2fixture/create_adjacent_tables.py</code> <pre><code>def csv2json_list(\n    csv_path: PathLike,\n    output_path: Path = OUTPUT,\n    saved: list[Path] | None = None,\n    indent: int = JSON_INDENT,\n) -&gt; list:\n    \"\"\"Save `csv_path` as a `json` file and return as a `list`.\n\n    Note:\n        Managing `Pandas` `DataFrame` `nan` values via suggestion:\n        https://stackoverflow.com/a/62691803/678486\n\n    \"\"\"\n    json_data: list[dict[str, Any]] = []\n    df: pd.DataFame = (\n        pd.read_csv(csv_path, index_col=0).fillna(np.nan).replace([np.nan], [None])\n    )\n\n    if \"political_leanings\" in df.columns:\n        df[\"political_leanings\"] = df[\"political_leanings\"].apply(json.loads)\n    if \"prices\" in df.columns:\n        df[\"prices\"] = df[\"prices\"].apply(json.loads)\n\n    model: str = Path(csv_path).stem.lower()\n\n    for pk, row in df.iterrows():\n        fields: dict[str, Any] = row.to_dict()\n        json_data.append({\"pk\": pk, \"model\": model, \"fields\": fields})\n\n    json_path: Path = Path(output_path) / f\"{Path(csv_path).stem}.json\"\n    json_path.parent.mkdir(parents=True, exist_ok=True)\n    json_path.write_text(json.dumps(json_data, indent=indent))\n    if saved and isinstance(saved, list):\n        saved.append(json_path)\n    return json_data\n</code></pre>"},{"location":"reference/alto2txt2fixture/create_adjacent_tables.html#alto2txt2fixture.create_adjacent_tables.download_data","title":"download_data","text":"<pre><code>download_data(\n    files_dict: RemoteDataFilesType = {},\n    overwrite: bool = OVERWRITE,\n    exclude: list[str] = [],\n) -&gt; None\n</code></pre> <p>Download files in <code>files_dict</code>, overwrite if specified.</p> <p>Parameters:</p> Name Type Description Default <code>files_dict</code> <code>RemoteDataFilesType</code> <p><code>dict</code> of related files to download</p> <code>{}</code> <code>overwrite</code> <code>bool</code> <p><code>bool</code> to overwrite <code>LOCAL_CACHE</code> files or not</p> <code>OVERWRITE</code> <code>exclude</code> <code>list[str]</code> <p><code>list</code> of files to exclude from <code>files_dict</code></p> <code>[]</code> Example <pre><code>&gt;&gt;&gt; from os import chdir\n&gt;&gt;&gt; tmp_path: Path = getfixture('tmp_path')\n&gt;&gt;&gt; set_path: Path = chdir(tmp_path)\n&gt;&gt;&gt; download_data(exclude=[\"mitchells\", \"Newspaper-1\", \"linking\"])\nExcluding mitchells...\nExcluding Newspaper-1...\nExcluding linking...\nDownloading cache...dict_admin_counties.json\n100% ... 37/37 bytes\nDownloading cache...dict_countries.json\n100% ... 33.2/33.2 kB\nDownloading cache...dict_historic_counties.json\n100% ... 41.4/41.4 kB\nDownloading cache...nlp_loc_wikidata_concat.csv\n100% ... 59.8/59.8 kB\nDownloading cache...wikidata_gazetteer_selected_columns.csv\n100% ... 47.8/47.8 MB\n</code></pre> Source code in <code>alto2txt2fixture/create_adjacent_tables.py</code> <pre><code>def download_data(\n    files_dict: RemoteDataFilesType = {},\n    overwrite: bool = OVERWRITE,\n    exclude: list[str] = [],\n) -&gt; None:\n    \"\"\"Download files in ``files_dict``, overwrite if specified.\n\n    Args:\n        files_dict: `dict` of related files to download\n        overwrite: `bool` to overwrite ``LOCAL_CACHE`` files or not\n        exclude: `list` of files to exclude from ``files_dict``\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; from os import chdir\n        &gt;&gt;&gt; tmp_path: Path = getfixture('tmp_path')\n        &gt;&gt;&gt; set_path: Path = chdir(tmp_path)\n        &gt;&gt;&gt; download_data(exclude=[\"mitchells\", \"Newspaper-1\", \"linking\"])\n        Excluding mitchells...\n        Excluding Newspaper-1...\n        Excluding linking...\n        Downloading cache...dict_admin_counties.json\n        100% ... 37/37 bytes\n        Downloading cache...dict_countries.json\n        100% ... 33.2/33.2 kB\n        Downloading cache...dict_historic_counties.json\n        100% ... 41.4/41.4 kB\n        Downloading cache...nlp_loc_wikidata_concat.csv\n        100% ... 59.8/59.8 kB\n        Downloading cache...wikidata_gazetteer_selected_columns.csv\n        100% ... 47.8/47.8 MB\n\n        ```\n    \"\"\"\n    if not files_dict:\n        files_dict = deepcopy(FILES)\n    for data_source in exclude:\n        if data_source in files_dict:\n            print(f\"Excluding {data_source}...\")\n            files_dict.pop(data_source, 0)\n        else:\n            logger.warning(\n                f'\"{data_source}\" not an option to exclude from {files_dict}'\n            )\n\n    # Describe whether local file exists\n    for k in files_dict.keys():\n        files_dict[k][\"exists\"] = files_dict[k][\"local\"].exists()\n\n    files_to_download = [\n        (v[\"remote\"], v[\"local\"], v[\"exists\"])\n        for v in files_dict.values()\n        if \"exists\" in v and not v[\"exists\"] or overwrite\n    ]\n    for url, out, exists in files_to_download:\n        rmtree(Path(out), ignore_errors=True) if exists else None\n        print(f\"Downloading {out}\")\n        Path(out).parent.mkdir(parents=True, exist_ok=True)\n        assert isinstance(url, str)\n        with urlopen(url) as response, open(out, \"wb\") as out_file:\n            total: int = int(response.info()[\"Content-length\"])\n            with Progress(\n                \"[progress.percentage]{task.percentage:&gt;3.0f}%\",\n                BarColumn(),  # removed bar_width=None to avoid too long when resized\n                DownloadColumn(),\n            ) as progress:\n                download_task = progress.add_task(\"Download\", total=total)\n                for chunk in response:\n                    out_file.write(chunk)\n                    progress.update(download_task, advance=len(chunk))\n</code></pre>"},{"location":"reference/alto2txt2fixture/create_adjacent_tables.html#alto2txt2fixture.create_adjacent_tables.get_list","title":"get_list","text":"<pre><code>get_list(x)\n</code></pre> <p>Get a list from a string, which contains  as separator. If no string is encountered, the function returns an empty list. Source code in <code>alto2txt2fixture/create_adjacent_tables.py</code> <pre><code>def get_list(x):\n    \"\"\"Get a list from a string, which contains &lt;SEP&gt; as separator. If no\n    string is encountered, the function returns an empty list.\"\"\"\n    return x.split(\"&lt;SEP&gt;\") if isinstance(x, str) else []\n</code></pre>"},{"location":"reference/alto2txt2fixture/create_adjacent_tables.html#alto2txt2fixture.create_adjacent_tables.get_outpaths_dict","title":"get_outpaths_dict","text":"<pre><code>get_outpaths_dict(\n    names: Sequence[str], module_name: str\n) -&gt; TableOutputConfigType\n</code></pre> <p>Return a <code>dict</code> of <code>csv</code> and <code>json</code> paths for each <code>module_name</code> table.</p> <p>The <code>csv</code> and <code>json</code> paths</p> <p>Parameters:</p> Name Type Description Default <code>names</code> <code>Sequence[str]</code> <p>iterable of names of each <code>module_name</code>'s component. Main target is <code>csv</code> and <code>json</code> table names</p> required <code>module_name</code> <code>str</code> <p>name of module each name is part of, that is added as a prefix</p> required <p>Returns:</p> Type Description <code>TableOutputConfigType</code> <p>A <code>TableOutputConfigType</code>: a <code>dict</code> of table <code>names</code> and output <code>csv</code> and <code>json</code> filenames.</p> Example <pre><code>&gt;&gt;&gt; pprint(get_outpaths_dict(MITCHELLS_TABELS, \"mitchells\"))\n{'Entry': {'csv': 'mitchells.Entry.csv', 'json': 'mitchells.Entry.json'},\n 'Issue': {'csv': 'mitchells.Issue.csv', 'json': 'mitchells.Issue.json'},\n 'PoliticalLeaning': {'csv': 'mitchells.PoliticalLeaning.csv',\n                      'json': 'mitchells.PoliticalLeaning.json'},\n 'Price': {'csv': 'mitchells.Price.csv', 'json': 'mitchells.Price.json'}}\n</code></pre> Source code in <code>alto2txt2fixture/create_adjacent_tables.py</code> <pre><code>def get_outpaths_dict(names: Sequence[str], module_name: str) -&gt; TableOutputConfigType:\n    \"\"\"Return a `dict` of `csv` and `json` paths for each `module_name` table.\n\n    The `csv` and `json` paths\n\n    Args:\n        names: iterable of names of each `module_name`'s component. Main target is `csv` and `json` table names\n        module_name: name of module each name is part of, that is added as a prefix\n\n    Returns:\n        A ``TableOutputConfigType``: a `dict` of table ``names`` and output\n            `csv` and `json` filenames.\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; pprint(get_outpaths_dict(MITCHELLS_TABELS, \"mitchells\"))\n        {'Entry': {'csv': 'mitchells.Entry.csv', 'json': 'mitchells.Entry.json'},\n         'Issue': {'csv': 'mitchells.Issue.csv', 'json': 'mitchells.Issue.json'},\n         'PoliticalLeaning': {'csv': 'mitchells.PoliticalLeaning.csv',\n                              'json': 'mitchells.PoliticalLeaning.json'},\n         'Price': {'csv': 'mitchells.Price.csv', 'json': 'mitchells.Price.json'}}\n\n        ```\n    \"\"\"\n    return {\n        name: OutputPathDict(\n            csv=f\"{module_name}.{name}.csv\",\n            json=f\"{module_name}.{name}.json\",\n        )\n        for name in names\n    }\n</code></pre>"},{"location":"reference/alto2txt2fixture/create_adjacent_tables.html#alto2txt2fixture.create_adjacent_tables.run","title":"run","text":"<pre><code>run(\n    files_dict: dict = {},\n    files_to_download_overwrite: bool = OVERWRITE,\n    saved: list[PathLike] = SAVED,\n    time_stamp: str = \"\",\n    output_path: Path = OUTPUT,\n) -&gt; list[PathLike]\n</code></pre> <p>Download, process and link <code>files_dict</code> to <code>json</code> and <code>csv</code>.</p> Note <p>This will require access to <code>https://zooniversedata.blob.core.windows.net/downloads/</code>.</p> Source code in <code>alto2txt2fixture/create_adjacent_tables.py</code> <pre><code>def run(\n    files_dict: dict = {},\n    files_to_download_overwrite: bool = OVERWRITE,\n    saved: list[PathLike] = SAVED,\n    time_stamp: str = \"\",\n    output_path: Path = OUTPUT,\n) -&gt; list[PathLike]:\n    \"\"\"Download, process and link ``files_dict`` to `json` and `csv`.\n\n    Note:\n        This will require access to `https://zooniversedata.blob.core.windows.net/downloads/`.\n    \"\"\"\n\n    # Ensure time_stamp from the point of calling `run`\n    if not time_stamp:\n        time_stamp = get_now(as_str=False).strftime(TIME_FORMAT)\n\n    # Ensure an independent deepcopy of FILES to avoid modifying subsequent runs\n    if not files_dict:\n        files_dict = deepcopy(FILES)\n\n    # Download non-existing files\n    download_data(files_dict=files_dict, overwrite=files_to_download_overwrite)\n\n    # Create the output directory (defined in output_path)\n    output_path.mkdir(exist_ok=True, parents=True)\n\n    # Read all the Wikidata Q values from Mitchells\n    assert \"local\" in files_dict[\"mitchells\"]\n    mitchells_df = pd.read_csv(files_dict[\"mitchells\"][\"local\"], index_col=0)\n    mitchell_wikidata_mentions = sorted(\n        list(mitchells_df.PLACE_PUB_WIKI.unique()),\n        key=lambda x: int(x.replace(\"Q\", \"\")),\n    )\n\n    # Set up wikidata_gazetteer\n    gaz_cols = [\"wikidata_id\", \"english_label\", \"latitude\", \"longitude\", \"geonamesIDs\"]\n    assert \"local\" in files_dict[\"wikidata_gazetteer_selected_columns\"]\n    wikidata_gazetteer = pd.read_csv(\n        files_dict[\"wikidata_gazetteer_selected_columns\"][\"local\"], usecols=gaz_cols\n    )\n    wikidata_gazetteer.rename(\n        {\n            \"wikidata_id\": \"place_wikidata_id\",\n            \"english_label\": \"place_label\",\n            \"geonamesIDs\": \"geonames_ids\",\n        },\n        axis=1,\n        inplace=True,\n    )\n\n    # Read in + fix all dictionaries\n    dict_historic_counties = json.loads(\n        Path(files_dict[\"dict_historic_counties\"][\"local\"]).read_text()\n    )\n    dict_admin_counties = json.loads(\n        Path(files_dict[\"dict_admin_counties\"][\"local\"]).read_text()\n    )\n    dict_countries = json.loads(Path(files_dict[\"dict_countries\"][\"local\"]).read_text())\n    dict_historic_counties = correct_dict(dict_historic_counties)\n    dict_admin_counties = correct_dict(dict_admin_counties)\n    dict_countries = correct_dict(dict_countries)\n\n    # Create assisting frames\n    historical_counties_df = pd.DataFrame(\n        dict_historic_counties,\n        columns=[\"place_wikidata_id\", \"hcounty_label\", \"hcounty_wikidata_id\"],\n    )\n    admin_county_df = pd.DataFrame(\n        dict_admin_counties,\n        columns=[\n            \"place_wikidata_id\",\n            \"admin_county_label\",\n            \"admin_county_wikidata_id\",\n        ],\n    )\n    countries_df = pd.DataFrame(\n        dict_countries,\n        columns=[\"place_wikidata_id\", \"country_label\", \"country_wikidata_id\"],\n    )\n\n    wikidata_gazetteer = wikidata_gazetteer[\n        wikidata_gazetteer.place_wikidata_id.isin(mitchell_wikidata_mentions)\n    ].sort_values(\"place_wikidata_id\")\n    wikidata_gazetteer[\"place_pk\"] = np.arange(1, len(wikidata_gazetteer) + 1)\n    wikidata_gazetteer = wikidata_gazetteer[\n        [\"place_pk\"] + [x for x in wikidata_gazetteer.columns if not x == \"place_pk\"]\n    ]\n\n    # Merge wikidata_gazetteer with all the assisting frames (and rename the\n    # resulting columns)\n    wikidata_gazetteer = pd.merge(\n        wikidata_gazetteer, historical_counties_df, on=\"place_wikidata_id\", how=\"left\"\n    )\n    wikidata_gazetteer = pd.merge(\n        wikidata_gazetteer, admin_county_df, on=\"place_wikidata_id\", how=\"left\"\n    )\n    wikidata_gazetteer = pd.merge(\n        wikidata_gazetteer, countries_df, on=\"place_wikidata_id\", how=\"left\"\n    )\n\n    wikidata_gazetteer.rename(\n        {\n            \"admin_county_label\": \"admin_county__label\",\n            \"admin_county_wikidata_id\": \"admin_county__wikidata_id\",\n            \"hcounty_label\": \"historic_county__label\",\n            \"hcounty_wikidata_id\": \"historic_county__wikidata_id\",\n            \"country_label\": \"country__label\",\n            \"country_wikidata_id\": \"country__wikidata_id\",\n        },\n        axis=1,\n        inplace=True,\n    )\n\n    # Split back up into dataframes specific for the tables\n    historic_county_table = (\n        wikidata_gazetteer[[\"historic_county__label\", \"historic_county__wikidata_id\"]]\n        .drop_duplicates()\n        .copy()\n    )\n    historic_county_table = historic_county_table.replace({\"\": np.nan}).dropna()\n    historic_county_table[\"historic_county__pk\"] = np.arange(\n        1, len(historic_county_table) + 1\n    )\n\n    admin_county_table = (\n        wikidata_gazetteer[[\"admin_county__label\", \"admin_county__wikidata_id\"]]\n        .drop_duplicates()\n        .copy()\n    )\n    admin_county_table = admin_county_table.replace({\"\": np.nan}).dropna()\n    admin_county_table[\"admin_county__pk\"] = np.arange(1, len(admin_county_table) + 1)\n\n    country_table = (\n        wikidata_gazetteer[[\"country__label\", \"country__wikidata_id\"]]\n        .drop_duplicates()\n        .copy()\n    )\n    country_table = country_table.replace({\"\": np.nan}).dropna()\n    country_table[\"country__pk\"] = np.arange(1, len(country_table) + 1)\n\n    # Set up place_table from wikidata_gazetteer\n    place_table = wikidata_gazetteer.copy()\n\n    place_table = (\n        pd.merge(\n            place_table,\n            historic_county_table,\n            on=[\"historic_county__label\", \"historic_county__wikidata_id\"],\n            how=\"left\",\n        )\n        .drop([\"historic_county__label\", \"historic_county__wikidata_id\"], axis=1)\n        .rename({\"historic_county__pk\": \"historic_county_id\"}, axis=1)\n    )\n\n    place_table = (\n        pd.merge(\n            place_table,\n            admin_county_table,\n            on=[\"admin_county__label\", \"admin_county__wikidata_id\"],\n            how=\"left\",\n        )\n        .drop([\"admin_county__label\", \"admin_county__wikidata_id\"], axis=1)\n        .rename({\"admin_county__pk\": \"admin_county_id\"}, axis=1)\n    )\n\n    place_table = (\n        pd.merge(\n            place_table,\n            country_table,\n            on=[\"country__label\", \"country__wikidata_id\"],\n            how=\"left\",\n        )\n        .drop([\"country__label\", \"country__wikidata_id\"], axis=1)\n        .rename({\"country__pk\": \"country_id\"}, axis=1)\n    )\n\n    place_table.fillna(\"\", inplace=True)\n    place_table.set_index(\"place_pk\", inplace=True)\n    place_table.rename(\n        {\"place_label\": \"label\", \"place_wikidata_id\": \"wikidata_id\"},\n        axis=1,\n        inplace=True,\n    )\n    place_table[\"historic_county_id\"] = (\n        place_table[\"historic_county_id\"]\n        .replace(r\"^\\s*$\", 0, regex=True)\n        .astype(int)\n        .replace(0, \"\")\n    )\n    place_table[\"admin_county_id\"] = (\n        place_table[\"admin_county_id\"]\n        .replace(r\"^\\s*$\", 0, regex=True)\n        .astype(int)\n        .replace(0, \"\")\n    )\n    place_table[\"country_id\"] = (\n        place_table[\"country_id\"]\n        .replace(r\"^\\s*$\", 0, regex=True)\n        .astype(int)\n        .replace(0, \"\")\n    )\n    place_table.index.rename(\"pk\", inplace=True)\n    place_table.rename(\n        {\n            \"historic_county_id\": \"historic_county\",\n            \"admin_county_id\": \"admin_county\",\n            \"country_id\": \"country\",\n        },\n        axis=1,\n        inplace=True,\n    )\n\n    historic_county_table.set_index(\"historic_county__pk\", inplace=True)\n    historic_county_table.rename(\n        {x: x.split(\"__\")[1] for x in historic_county_table.columns},\n        axis=1,\n        inplace=True,\n    )\n    historic_county_table.index.rename(\"pk\", inplace=True)\n\n    admin_county_table.set_index(\"admin_county__pk\", inplace=True)\n    admin_county_table.rename(\n        {x: x.split(\"__\")[1] for x in admin_county_table.columns}, axis=1, inplace=True\n    )\n    admin_county_table.index.rename(\"pk\", inplace=True)\n\n    country_table.set_index(\"country__pk\", inplace=True)\n    country_table.rename(\n        {x: x.split(\"__\")[1] for x in country_table.columns}, axis=1, inplace=True\n    )\n    country_table.index.rename(\"pk\", inplace=True)\n\n    # Adding created_at, updated_at to all the gazetteer tables\n    place_table[\"created_at\"] = time_stamp\n    place_table[\"updated_at\"] = time_stamp\n    admin_county_table[\"created_at\"] = time_stamp\n    admin_county_table[\"updated_at\"] = time_stamp\n    historic_county_table[\"created_at\"] = time_stamp\n    historic_county_table[\"updated_at\"] = time_stamp\n    country_table[\"created_at\"] = time_stamp\n    country_table[\"updated_at\"] = time_stamp\n\n    # Save CSV files for gazetteer tables\n    place_table.to_csv(output_path / GAZETTEER_OUT_FILENAMES[PLACE][\"csv\"])\n    admin_county_table.to_csv(\n        output_path / GAZETTEER_OUT_FILENAMES[ADMIN_COUNTY][\"csv\"]\n    )\n    historic_county_table.to_csv(\n        output_path / GAZETTEER_OUT_FILENAMES[HISTORIC_COUNTY][\"csv\"]\n    )\n    country_table.to_csv(output_path / GAZETTEER_OUT_FILENAMES[COUNTRY][\"csv\"])\n    saved.extend(\n        [\n            output_path / GAZETTEER_OUT_FILENAMES[PLACE][\"csv\"],\n            output_path / GAZETTEER_OUT_FILENAMES[ADMIN_COUNTY][\"csv\"],\n            output_path / GAZETTEER_OUT_FILENAMES[HISTORIC_COUNTY][\"csv\"],\n            output_path / GAZETTEER_OUT_FILENAMES[COUNTRY][\"csv\"],\n        ]\n    )\n\n    # Fix up Mitchells (already loaded)\n    mitchells_df[\"politics\"] = mitchells_df.POLITICS.apply(get_list)\n    mitchells_df[\"persons\"] = mitchells_df.PERSONS.apply(get_list)\n    mitchells_df[\"organisations\"] = mitchells_df.ORGANIZATIONS.apply(get_list)\n    mitchells_df[\"price\"] = mitchells_df.PRICE.apply(get_list)\n\n    mitchells_df.rename(\n        {\n            \"ID\": \"mpd_id\",\n            \"TITLE\": \"title\",\n            \"politics\": \"political_leaning_raw\",\n            \"price\": \"price_raw\",\n            \"YEAR\": \"year\",\n            \"PLACE_PUB_WIKI\": \"place_of_publication_id\",\n            \"ESTABLISHED_DATE\": \"date_established_raw\",\n            \"PUBLISED_DATE\": \"day_of_publication_raw\",\n        },\n        axis=1,\n        inplace=True,\n    )\n\n    drop_cols = [\n        \"CHAIN_ID\",\n        \"POLITICS\",\n        \"PERSONS\",\n        \"ORGANIZATIONS\",\n        \"PRICE\",\n        \"PLACE_PUB\",\n        \"PLACE_PUB_COORD\",\n        \"PLACES\",\n        \"PLACES_TRES\",\n        \"TEXT\",\n    ]\n    mitchells_df.drop(columns=drop_cols, inplace=True)\n\n    # Create derivative tables (from Mitchells) = political_leanings, prices,\n    # issues\n    political_leanings = sorted(\n        list(set([y.strip() for x in mitchells_df.political_leaning_raw for y in x]))\n    )\n    political_leanings_table = pd.DataFrame()\n    political_leanings_table[\"political_leaning__pk\"] = np.arange(\n        1, len(political_leanings) + 1\n    )\n    political_leanings_table[\"political_leaning__label\"] = political_leanings\n    export = political_leanings_table.copy()\n    export[\"created_at\"] = time_stamp\n    export[\"updated_at\"] = time_stamp\n    export.set_index(\"political_leaning__pk\", inplace=True)\n    export.index.rename(\"pk\", inplace=True)\n    export.rename(\n        {x: x.split(\"__\")[1] if len(x.split(\"__\")) &gt; 1 else x for x in export.columns},\n        axis=1,\n        inplace=True,\n    )\n    export.to_csv(output_path / MITCHELLS_OUT_FILENAMES[POLITICAL_LEANING][\"csv\"])\n    saved.append(output_path / MITCHELLS_OUT_FILENAMES[POLITICAL_LEANING][\"csv\"])\n\n    prices = sorted(list(set([y.strip() for x in mitchells_df.price_raw for y in x])))\n    prices_table = pd.DataFrame()\n    prices_table[\"price__pk\"] = np.arange(1, len(prices) + 1)\n    prices_table[\"price__label\"] = prices\n    export = prices_table.copy()\n    export[\"created_at\"] = time_stamp\n    export[\"updated_at\"] = time_stamp\n    export.set_index(\"price__pk\", inplace=True)\n    export.index.rename(\"pk\", inplace=True)\n    export.rename(\n        {x: x.split(\"__\")[1] if len(x.split(\"__\")) &gt; 1 else x for x in export.columns},\n        axis=1,\n        inplace=True,\n    )\n    export.to_csv(output_path / MITCHELLS_OUT_FILENAMES[PRICE][\"csv\"])\n    saved.append(output_path / MITCHELLS_OUT_FILENAMES[PRICE][\"csv\"])\n\n    issues = sorted(list(mitchells_df.year.unique()))\n    issues_table = pd.DataFrame()\n    issues_table[\"issue__pk\"] = np.arange(1, len(issues) + 1)\n    issues_table[\"issue__year\"] = issues\n    export = issues_table.copy()\n    export[\"created_at\"] = time_stamp\n    export[\"updated_at\"] = time_stamp\n    export.set_index(\"issue__pk\", inplace=True)\n    export.index.rename(\"pk\", inplace=True)\n    export.rename(\n        {x: x.split(\"__\")[1] if len(x.split(\"__\")) &gt; 1 else x for x in export.columns},\n        axis=1,\n        inplace=True,\n    )\n    export.to_csv(output_path / MITCHELLS_OUT_FILENAMES[ISSUE][\"csv\"])\n    saved.append(output_path / MITCHELLS_OUT_FILENAMES[ISSUE][\"csv\"])\n\n    # Set up linking on Mitchells dataframe\n    linking_df = pd.read_csv(\n        files_dict[\"linking\"][\"local\"],\n        index_col=0,\n        dtype={\"NLP\": str},\n        usecols=[\n            \"NLP\",\n            \"Title\",\n            \"AcquiredYears\",\n            \"Editions\",\n            \"EditionTitles\",\n            \"City\",\n            \"Publisher\",\n            \"UnavailableYears\",\n            \"Collection\",\n            \"UK\",\n            \"Complete\",\n            \"Notes\",\n            \"County\",\n            \"HistoricCounty\",\n            \"First date held\",\n            \"Publication title\",\n            \"link_to_mpd\",\n        ],\n    )\n    linking_df[\"NLP\"] = linking_df.index\n\n    linking_df.rename(\n        {\"link_to_mpd\": \"mpd_id\", \"NLP\": \"newspaper\"}, axis=1, inplace=True\n    )\n\n    # Link Mitchells with all the other data\n    mitchells_df = pd.merge(mitchells_df, linking_df, on=\"mpd_id\", how=\"inner\")\n\n    # Create entry_table\n    entry_table = mitchells_df.copy()\n    entry_table[\"place_of_circulation_raw\"] = \"\"\n    entry_table[\"publication_district_raw\"] = \"\"\n    entry_table[\"publication_county_raw\"] = \"\"\n    # TODO: What happened to the three columns above? (Check w Kaspar?)\n\n    # Only keep relevant columns\n    entry_table = entry_table[\n        [\n            \"title\",\n            \"political_leaning_raw\",\n            \"price_raw\",\n            \"year\",\n            \"date_established_raw\",\n            \"day_of_publication_raw\",\n            \"place_of_circulation_raw\",\n            \"publication_district_raw\",\n            \"publication_county_raw\",\n            \"organisations\",\n            \"persons\",\n            \"place_of_publication_id\",\n            \"newspaper\",\n        ]\n    ]\n\n    # Fix refs to political_leanings_table\n    rev = political_leanings_table.set_index(\"political_leaning__label\")\n    entry_table[\"political_leanings\"] = entry_table.political_leaning_raw.apply(\n        lambda x: [rev.at[y, \"political_leaning__pk\"] for y in x]\n    )\n\n    # Fix refs to prices_table\n    rev = prices_table.set_index(\"price__label\")\n    entry_table[\"prices\"] = entry_table.price_raw.apply(\n        lambda x: [rev.at[y.strip(), \"price__pk\"] for y in x]\n    )\n\n    # Fix refs to issues_table\n    rev = issues_table.set_index(\"issue__year\")\n    entry_table[\"issue\"] = entry_table.year.apply(lambda x: rev.at[x, \"issue__pk\"])\n\n    # Fix refs to place_table\n    rev = place_table.copy()\n    rev[\"place__pk\"] = rev.index\n    rev.set_index(\"wikidata_id\", inplace=True)\n    entry_table[\"place_of_publication\"] = entry_table.place_of_publication_id.apply(\n        test_place, rev=rev\n    )\n    entry_table.drop(columns=[\"place_of_publication_id\"], inplace=True)\n\n    # Set up ref to newspapers\n    rev = json.loads(files_dict[\"Newspaper-1\"][\"local\"].read_text())\n    rev = [dict(pk=v[\"pk\"], **v[\"fields\"]) for v in rev]\n    rev = pd.DataFrame(rev)\n    rev.set_index(\"publication_code\", inplace=True)\n    entry_table[\"newspaper\"] = entry_table.newspaper.str.zfill(7)\n    entry_table[\"newspaper\"] = entry_table.newspaper.apply(test_paper, rev=rev)\n\n    # Create PK for entries\n    entry_table[\"pk\"] = np.arange(1, len(entry_table) + 1)\n\n    # Sort columns in entries file\n    entry_table = entry_table[\n        [\"pk\"] + [col for col in entry_table.columns if not col == \"pk\"]\n    ]\n\n    # Add created_at, modified_at to entry_table\n    entry_table[\"created_at\"] = time_stamp\n    entry_table[\"updated_at\"] = time_stamp\n\n    # Export entry_table\n    entry_table.set_index(\"pk\").to_csv(\n        output_path / MITCHELLS_OUT_FILENAMES[ENTRY][\"csv\"]\n    )\n    saved.append(output_path / MITCHELLS_OUT_FILENAMES[ENTRY][\"csv\"])\n\n    # ######\u00a0NOW WE CAN EASILY CREATE JSON files_dict\n    for csv_file_path in output_path.glob(\"*.csv\"):\n        csv2json_list(csv_file_path, output_path=output_path)\n\n    print(\"Finished - saved files:\")\n    print(\"- \" + \"\\n- \".join([str(x) for x in saved]))\n    return saved\n</code></pre>"},{"location":"reference/alto2txt2fixture/jisc.html","title":"jisc","text":""},{"location":"reference/alto2txt2fixture/jisc.html#alto2txt2fixture.jisc.get_jisc_title","title":"get_jisc_title","text":"<pre><code>get_jisc_title(\n    title: str,\n    issue_date: str,\n    jisc_papers: DataFrame,\n    input_sub_path: str,\n    publication_code: str,\n    abbr: str | None = None,\n) -&gt; str\n</code></pre> <p>Match a newspaper <code>title</code> with <code>jisc_papers</code> records.</p> <p>Takes an <code>input_sub_path</code>, a <code>publication_code</code>, and an (optional) abbreviation for any newspaper to locate the <code>title</code> in the <code>jisc_papers</code> <code>DataFrame</code>. <code>jisc_papers</code> is usually loaded via the <code>setup_jisc_papers</code> function.</p> <p>Parameters:</p> Name Type Description Default <code>title</code> <code>str</code> <p>target newspaper title</p> required <code>issue_date</code> <code>str</code> <p>target newspaper issue_date</p> required <code>jisc_papers</code> <code>DataFrame</code> <p><code>DataFrame</code> of <code>jisc_papers</code> to match</p> required <code>input_sub_path</code> <code>str</code> <p>path of files to narrow down query input_sub_path</p> required <code>publication_code</code> <code>str</code> <p>unique codes to match newspaper records</p> required <code>abbr</code> <code>str | None</code> <p>an optional abbreviation of the newspaper title</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>Matched <code>title</code> <code>str</code> or <code>abbr</code>.</p> <p>Returns:</p> Type Description <code>str</code> <p>A string estimating the JISC equivalent newspaper title</p> Source code in <code>alto2txt2fixture/jisc.py</code> <pre><code>def get_jisc_title(\n    title: str,\n    issue_date: str,\n    jisc_papers: pd.DataFrame,\n    input_sub_path: str,\n    publication_code: str,\n    abbr: str | None = None,\n) -&gt; str:\n    \"\"\"\n    Match a newspaper ``title`` with ``jisc_papers`` records.\n\n    Takes an ``input_sub_path``, a ``publication_code``, and an (optional)\n    abbreviation for any newspaper to locate the ``title`` in the\n    ``jisc_papers`` `DataFrame`. ``jisc_papers`` is usually loaded via the\n    ``setup_jisc_papers`` function.\n\n    Args:\n        title: target newspaper title\n        issue_date: target newspaper issue_date\n        jisc_papers: `DataFrame` of `jisc_papers` to match\n        input_sub_path: path of files to narrow down query input_sub_path\n        publication_code: unique codes to match newspaper records\n        abbr: an optional abbreviation of the newspaper title\n\n    Returns:\n        Matched ``title`` `str` or ``abbr``.\n\n\n    Returns:\n        A string estimating the JISC equivalent newspaper title\n    \"\"\"\n\n    # First option, search the input_sub_path for a valid-looking publication_code\n    g = PUBLICATION_CODE.findall(input_sub_path)\n\n    if len(g) == 1:\n        publication_code = g[0]\n        # Let's see if we can find title:\n        title = (\n            jisc_papers[\n                jisc_papers.publication_code == publication_code\n            ].title.to_list()[0]\n            if jisc_papers[\n                jisc_papers.publication_code == publication_code\n            ].title.count()\n            == 1\n            else title\n        )\n        return title\n\n    # Second option, look through JISC papers for best match (on publication_code if we have it, but abbr more importantly if we have it)\n    if abbr:\n        _publication_code = publication_code\n        publication_code = abbr\n\n    if jisc_papers.abbr[jisc_papers.abbr == publication_code].count():\n        date = datetime.strptime(issue_date, \"%Y-%m-%d\")\n        mask = (\n            (jisc_papers.abbr == publication_code)\n            &amp; (date &gt;= jisc_papers.start_date)\n            &amp; (date &lt;= jisc_papers.end_date)\n        )\n        filtered = jisc_papers.loc[mask]\n        if filtered.publication_code.count() == 1:\n            publication_code = filtered.publication_code.to_list()[0]\n            title = filtered.title.to_list()[0]\n            return title\n\n    # Last option: let's find all the possible titles in the jisc_papers for the abbreviation, and if it's just one unique title, let's pick it!\n    if abbr:\n        test = list({x for x in jisc_papers[jisc_papers.abbr == abbr].title})\n        if len(test) == 1:\n            return test[0]\n        else:\n            mask1 = (jisc_papers.abbr == publication_code) &amp; (\n                jisc_papers.publication_code == _publication_code\n            )\n            test1 = jisc_papers.loc[mask1]\n            test1 = list({x for x in jisc_papers[jisc_papers.abbr == abbr].title})\n            if len(test) == 1:\n                return test1[0]\n\n    # Fallback: if abbreviation is set, we'll return that:\n    if abbr:\n        # For these exceptions, see issue comment:\n        # https://github.com/alan-turing-institute/Living-with-Machines/issues/2453#issuecomment-1050652587\n        if abbr == \"IPJL\":\n            return \"Ipswich Journal\"\n        elif abbr == \"BHCH\":\n            return \"Bath Chronicle\"\n        elif abbr == \"LSIR\":\n            return \"Leeds Intelligencer\"\n        elif abbr == \"AGER\":\n            return \"Lancaster Gazetter, And General Advertiser For Lancashire West\"\n\n        return abbr\n\n    raise RuntimeError(f\"Title {title} could not be found.\")\n</code></pre>"},{"location":"reference/alto2txt2fixture/jisc.html#alto2txt2fixture.jisc.setup_jisc_papers","title":"setup_jisc_papers","text":"<pre><code>setup_jisc_papers(path: str = settings.JISC_PAPERS_CSV) -&gt; DataFrame\n</code></pre> <p>Create a <code>DataFrame</code> with information in <code>JISC_PAPERS_CSV</code> in settings.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p><code>DataFrame</code> with all JISC titles.</p> Source code in <code>alto2txt2fixture/jisc.py</code> <pre><code>def setup_jisc_papers(path: str = settings.JISC_PAPERS_CSV) -&gt; pd.DataFrame:\n    \"\"\"\n    Create a `DataFrame` with information in `JISC_PAPERS_CSV` in settings.\n\n    Returns:\n        `DataFrame` with all JISC titles.\n    \"\"\"\n\n    if not Path(path).exists():\n        raise RuntimeError(\n            f\"Could not find required JISC papers file. Put {Path(path).name} in {Path(path).parent} or correct the settings with a different path.\"\n        )\n\n    months = {\n        \"Jan\": 1,\n        \"Feb\": 2,\n        \"Mar\": 3,\n        \"Apr\": 4,\n        \"May\": 5,\n        \"Jun\": 6,\n        \"June\": 6,\n        \"Jul\": 7,\n        \"July\": 7,\n        \"Aug\": 8,\n        \"Sep\": 9,\n        \"Sept\": 9,\n        \"Oct\": 10,\n        \"Nov\": 11,\n        \"Dec\": 12,\n        \"Dec.\": 12,\n    }\n\n    jisc_papers = pd.read_csv(\n        path,\n        usecols=[\n            \"Newspaper Title\",\n            \"NLP\",\n            \"Abbr\",\n            \"StartD\",\n            \"StartM\",\n            \"StartY\",\n            \"EndD\",\n            \"EndM\",\n            \"EndY\",\n        ],\n    )\n    jisc_papers[\"start_date\"] = jisc_papers.apply(\n        lambda x: datetime(\n            year=int(x.StartY),\n            month=months[x.StartM.strip(\".\").strip()],\n            day=int(x.StartD),\n        ),\n        axis=1,\n    )\n    jisc_papers[\"end_date\"] = jisc_papers.apply(\n        lambda x: datetime(\n            year=int(x.EndY), month=months[x.EndM.strip(\".\").strip()], day=int(x.EndD)\n        ),\n        axis=1,\n    )\n    jisc_papers.drop(\n        [\"StartD\", \"StartM\", \"StartY\", \"EndD\", \"EndM\", \"EndY\"],\n        axis=\"columns\",\n        inplace=True,\n    )\n    jisc_papers.rename(\n        {\"Newspaper Title\": \"title\", \"NLP\": \"publication_code\", \"Abbr\": \"abbr\"},\n        axis=1,\n        inplace=True,\n    )\n    jisc_papers[\"title\"] = jisc_papers[\"title\"].apply(\n        lambda x: \"The \" + x[:-5] if x.strip()[-5:].lower() == \", the\" else x\n    )\n    jisc_papers[\"publication_code\"] = jisc_papers[\"publication_code\"].apply(\n        lambda x: str(x).zfill(7)\n    )\n\n    return jisc_papers\n</code></pre>"},{"location":"reference/alto2txt2fixture/log.html","title":"log","text":""},{"location":"reference/alto2txt2fixture/log.html#alto2txt2fixture.log.error","title":"error","text":"<pre><code>error(msg: str, crash: bool = True, silent: bool = True) -&gt; None\n</code></pre> <p>Print <code>msg</code> in <code>colorama</code> <code>Force.RED</code> and <code>exit()</code></p> <p>If <code>silent</code> <code>exit()</code> after call, else <code>raise</code> <code>RuntimeError</code> if <code>crash=True</code>.</p> Source code in <code>alto2txt2fixture/log.py</code> <pre><code>def error(msg: str, crash: bool = True, silent: bool = True) -&gt; None:\n    \"\"\"Print ``msg`` in `colorama` `Force.RED` and `exit()`\n\n    If `silent` `exit()` after call, else `raise` `RuntimeError` if ``crash=True``.\"\"\"\n    if crash and silent:\n        print(f\"{Fore.RED}{msg}{Style.RESET_ALL}\")\n        exit()\n    elif crash:\n        raise RuntimeError(msg) from None\n    print(f\"{Fore.RED}{msg}{Style.RESET_ALL}\")\n\n    return\n</code></pre>"},{"location":"reference/alto2txt2fixture/log.html#alto2txt2fixture.log.info","title":"info","text":"<pre><code>info(msg: str) -&gt; None\n</code></pre> <p>Print <code>msg</code> in <code>colorama</code> <code>Force.CYAN</code> colour.</p> Source code in <code>alto2txt2fixture/log.py</code> <pre><code>def info(msg: str) -&gt; None:\n    \"\"\"Print ``msg`` in `colorama` `Force.CYAN` colour.\"\"\"\n    print(f\"{Fore.CYAN}{msg}{Style.RESET_ALL}\")\n    return\n</code></pre>"},{"location":"reference/alto2txt2fixture/log.html#alto2txt2fixture.log.success","title":"success","text":"<pre><code>success(msg: str) -&gt; None\n</code></pre> <p>Print <code>msg</code> in <code>colorama</code> <code>Force.GREEN</code> colour.</p> Source code in <code>alto2txt2fixture/log.py</code> <pre><code>def success(msg: str) -&gt; None:\n    \"\"\"Print ``msg`` in `colorama` `Force.GREEN` colour.\"\"\"\n    print(f\"{Fore.GREEN}{msg}{Style.RESET_ALL}\")\n    return\n</code></pre>"},{"location":"reference/alto2txt2fixture/log.html#alto2txt2fixture.log.warning","title":"warning","text":"<pre><code>warning(msg: str) -&gt; None\n</code></pre> <p>Print <code>msg</code> in <code>colorama</code> <code>Force.YELLOW</code> colour.</p> Source code in <code>alto2txt2fixture/log.py</code> <pre><code>def warning(msg: str) -&gt; None:\n    \"\"\"Print ``msg`` in `colorama` `Force.YELLOW` colour.\"\"\"\n    print(f\"{Fore.YELLOW}Warning: {msg}{Style.RESET_ALL}\")\n    return\n</code></pre>"},{"location":"reference/alto2txt2fixture/parser.html","title":"parser","text":""},{"location":"reference/alto2txt2fixture/parser.html#alto2txt2fixture.parser.fixtures","title":"fixtures","text":"<pre><code>fixtures(\n    filelist: list = [],\n    model: str = \"\",\n    translate: dict = {},\n    rename: dict = {},\n    uniq_keys: list = [],\n) -&gt; Generator[FixtureDict, None, None]\n</code></pre> <p>Generates fixtures for a specified model using a list of files.</p> <p>This function takes a list of files and generates fixtures for a specified model. The fixtures can be used to populate a database or perform other data-related operations.</p> <p>Parameters:</p> Name Type Description Default <code>filelist</code> <code>list</code> <p>A list of files to process and generate fixtures from.</p> <code>[]</code> <code>model</code> <code>str</code> <p>The name of the model for which fixtures are generated. translate: A nested dictionary representing the translation mapping for fields. The structure of the translator follows the format: <pre><code>{\n    'part1': {\n        'part2': {\n            'translated_field': 'pk'\n        }\n    }\n}\n</code></pre> The translated fields will be used as keys, and their corresponding primary keys (obtained from the provided files) will be used as values in the generated fixtures.</p> <code>''</code> <code>rename</code> <code>dict</code> <p>A nested dictionary representing the field renaming mapping. The structure of the dictionary follows the format: <pre><code>{\n    'part1': {\n        'part2': 'new_field_name'\n    }\n}\n</code></pre> The fields specified in the dictionary will be renamed to the provided new field names in the generated fixtures.</p> <code>{}</code> <code>uniq_keys</code> <code>list</code> <p>A list of fields that need to be considered for uniqueness in the fixtures. If specified, the fixtures will yield only unique items based on the combination of these fields.</p> <code>[]</code> <p>Yields:</p> Type Description <code>FixtureDict</code> <p><code>FixtureDict</code> from <code>model</code>, <code>pk</code> and <code>dict</code> of <code>fields</code>.</p> <p>Returns:</p> Type Description <code>Generator[FixtureDict, None, None]</code> <p>This function generates fixtures but does not return any value.</p> Source code in <code>alto2txt2fixture/parser.py</code> <pre><code>def fixtures(\n    filelist: list = [],\n    model: str = \"\",\n    translate: dict = {},\n    rename: dict = {},\n    uniq_keys: list = [],\n) -&gt; Generator[FixtureDict, None, None]:\n    \"\"\"\n    Generates fixtures for a specified model using a list of files.\n\n    This function takes a list of files and generates fixtures for a specified\n    model. The fixtures can be used to populate a database or perform other\n    data-related operations.\n\n    Args:\n        filelist: A list of files to process and generate fixtures from.\n        model: The name of the model for which fixtures are generated.\n            translate: A nested dictionary representing the translation mapping\n            for fields. The structure of the translator follows the format:\n            ```python\n            {\n                'part1': {\n                    'part2': {\n                        'translated_field': 'pk'\n                    }\n                }\n            }\n            ```\n            The translated fields will be used as keys, and their\n            corresponding primary keys (obtained from the provided files) will\n            be used as values in the generated fixtures.\n        rename: A nested dictionary representing the field renaming\n            mapping. The structure of the dictionary follows the format:\n            ```python\n            {\n                'part1': {\n                    'part2': 'new_field_name'\n                }\n            }\n            ```\n            The fields specified in the dictionary will be renamed to the\n            provided new field names in the generated fixtures.\n        uniq_keys: A list of fields that need to be considered for\n            uniqueness in the fixtures. If specified, the fixtures will yield\n            only unique items based on the combination of these fields.\n\n    Yields:\n        `FixtureDict` from ``model``, ``pk`` and `dict` of ``fields``.\n\n    Returns:\n        This function generates fixtures but does not return any value.\n    \"\"\"\n\n    filelist = sorted(filelist, key=lambda x: str(x).split(\"/\")[:-1])\n    count = len(filelist)\n\n    # Process JSONL\n    if [x for x in filelist if \".jsonl\" in x.name]:\n        pk = 0\n        # In the future, we might want to show progress here (tqdm or suchlike)\n        for file in filelist:\n            for line in file.read_text().splitlines():\n                pk += 1\n                line = json.loads(line)\n                yield FixtureDict(\n                    pk=pk,\n                    model=model,\n                    fields=dict(**get_fields(line, translate=translate, rename=rename)),\n                )\n\n        return\n    else:\n        # Process JSON\n        pks = [x for x in range(1, count + 1)]\n\n        if len(uniq_keys):\n            uniq_files = list(uniq(filelist, uniq_keys))\n            count = len(uniq_files)\n            zipped = zip(uniq_files, pks)\n        else:\n            zipped = zip(filelist, pks)\n\n        for x in tqdm(\n            zipped, total=count, desc=f\"{model} ({count:,} objs)\", leave=False\n        ):\n            yield FixtureDict(\n                pk=x[1],\n                model=model,\n                fields=dict(**get_fields(x[0], translate=translate, rename=rename)),\n            )\n\n        return\n</code></pre>"},{"location":"reference/alto2txt2fixture/parser.html#alto2txt2fixture.parser.get_fields","title":"get_fields","text":"<pre><code>get_fields(\n    file: Union[Path, str, dict],\n    translate: dict = {},\n    rename: dict = {},\n    allow_null: bool = False,\n) -&gt; dict\n</code></pre> <p>Retrieves fields from a file and performs modifications and checks.</p> <p>This function takes a file (in various formats: <code>Path</code>, <code>str</code>, or <code>dict</code>) and processes its fields. It retrieves the fields from the file and performs modifications, translations, and checks on the fields.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>Union[Path, str, dict]</code> <p>The file from which the fields are retrieved.</p> required <code>translate</code> <code>dict</code> <p>A nested dictionary representing the translation mapping for fields. The structure of the translator follows the format: <pre><code>{\n    'part1': {\n        'part2': {\n            'translated_field': 'pk'\n        }\n    }\n}\n</code></pre> The translated fields will be used to replace the original fields in the retrieved fields.</p> <code>{}</code> <code>rename</code> <code>dict</code> <p>A nested dictionary representing the field renaming mapping. The structure of the dictionary follows the format: <pre><code>{\n    'part1': {\n        'part2': 'new_field_name'\n    }\n}\n</code></pre> The fields specified in the dictionary will be renamed to the provided new field names in the retrieved fields.</p> <code>{}</code> <code>allow_null</code> <code>bool</code> <p>Determines whether to allow <code>None</code> values for relational fields. If set to <code>True</code>, relational fields with missing values will be assigned <code>None</code>. If set to <code>False</code>, an error will be raised.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary representing the retrieved fields from the file, with modifications and checks applied.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the file type is unsupported or if an error occurs during field retrieval or processing.</p> Source code in <code>alto2txt2fixture/parser.py</code> <pre><code>def get_fields(\n    file: Union[Path, str, dict],\n    translate: dict = {},\n    rename: dict = {},\n    allow_null: bool = False,\n) -&gt; dict:\n    \"\"\"\n    Retrieves fields from a file and performs modifications and checks.\n\n    This function takes a file (in various formats: `Path`, `str`, or `dict`)\n    and processes its fields. It retrieves the fields from the file and\n    performs modifications, translations, and checks on the fields.\n\n    Args:\n        file: The file from which the fields are retrieved.\n        translate: A nested dictionary representing the translation mapping\n            for fields. The structure of the translator follows the format:\n            ```python\n            {\n                'part1': {\n                    'part2': {\n                        'translated_field': 'pk'\n                    }\n                }\n            }\n            ```\n            The translated fields will be used to replace the original fields\n            in the retrieved fields.\n        rename: A nested dictionary representing the field renaming\n            mapping. The structure of the dictionary follows the format:\n            ```python\n            {\n                'part1': {\n                    'part2': 'new_field_name'\n                }\n            }\n            ```\n            The fields specified in the dictionary will be renamed to the\n            provided new field names in the retrieved fields.\n        allow_null: Determines whether to allow ``None`` values for\n            relational fields. If set to ``True``, relational fields with\n            missing values will be assigned ``None``. If set to ``False``, an\n            error will be raised.\n\n    Returns:\n        A dictionary representing the retrieved fields from the file,\n            with modifications and checks applied.\n\n    Raises:\n        RuntimeError: If the file type is unsupported or if an error occurs\n            during field retrieval or processing.\n    \"\"\"\n    if isinstance(file, Path):\n        try:\n            fields = json.loads(file.read_text())\n        except Exception as e:\n            raise RuntimeError(f\"Cannot interpret JSON ({e}): {file}\")\n    elif isinstance(file, str):\n        if \"\\n\" in file:\n            raise RuntimeError(\"File has multiple lines.\")\n        try:\n            fields = json.loads(file)\n        except json.decoder.JSONDecodeError as e:\n            raise RuntimeError(f\"Cannot interpret JSON ({e}): {file}\")\n    elif isinstance(file, dict):\n        fields = file\n    else:\n        raise RuntimeError(f\"Cannot process type {type(file)}.\")\n\n    # Fix relational fields for any file\n    for key in [key for key in fields.keys() if \"__\" in key]:\n        parts = key.split(\"__\")\n\n        try:\n            before = fields[key]\n            if before:\n                before = before.replace(\"---\", \"/\")\n                loc = translate.get(parts[0], {}).get(parts[1], {})\n                fields[key] = loc.get(before)\n                if fields[key] is None:\n                    raise RuntimeError(\n                        f\"Cannot translate fields.{key} from {before}: {loc}\"\n                    )\n\n        except AttributeError:\n            if allow_null:\n                fields[key] = None\n            else:\n                print(\n                    \"Content had relational fields, but something went wrong in parsing the data:\"\n                )\n                print(\"file\", file)\n                print(\"fields\", fields)\n                print(\"KEY:\", key)\n                raise RuntimeError()\n\n        new_name = rename.get(parts[0], {}).get(parts[1], None)\n        if new_name:\n            fields[new_name] = fields[key]\n            del fields[key]\n\n    fields[\"created_at\"] = NOW_str\n    fields[\"updated_at\"] = NOW_str\n\n    try:\n        fields[\"item_type\"] = str(fields[\"item_type\"]).upper()\n    except KeyError:\n        pass\n\n    try:\n        if fields[\"ocr_quality_mean\"] == \"\":\n            fields[\"ocr_quality_mean\"] = 0\n    except KeyError:\n        pass\n\n    try:\n        if fields[\"ocr_quality_sd\"] == \"\":\n            fields[\"ocr_quality_sd\"] = 0\n    except KeyError:\n        pass\n\n    return fields\n</code></pre>"},{"location":"reference/alto2txt2fixture/parser.html#alto2txt2fixture.parser.get_key_from","title":"get_key_from","text":"<pre><code>get_key_from(item: Path, x: str) -&gt; str\n</code></pre> <p>Retrieves a specific key from a file and returns its value.</p> <p>This function reads a file and extracts the value of a specified key. If the key is not found or an error occurs while processing the file, a warning is printed, and an empty string is returned.</p> <p>Parameters:</p> Name Type Description Default <code>item</code> <code>Path</code> <p>The file from which the key is extracted.</p> required <code>x</code> <code>str</code> <p>The key to be retrieved from the file.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The value of the specified key from the file.</p> Source code in <code>alto2txt2fixture/parser.py</code> <pre><code>def get_key_from(item: Path, x: str) -&gt; str:\n    \"\"\"\n    Retrieves a specific key from a file and returns its value.\n\n    This function reads a file and extracts the value of a specified\n    key. If the key is not found or an error occurs while processing\n    the file, a warning is printed, and an empty string is returned.\n\n    Args:\n        item: The file from which the key is extracted.\n        x: The key to be retrieved from the file.\n\n    Returns:\n        The value of the specified key from the file.\n    \"\"\"\n    result = json.loads(item.read_text()).get(x, None)\n    if not result:\n        print(f\"[WARN] Could not find key {x} in {item}\")\n        result = \"\"\n    return result\n</code></pre>"},{"location":"reference/alto2txt2fixture/parser.html#alto2txt2fixture.parser.get_translator","title":"get_translator","text":"<pre><code>get_translator(\n    fields: list[TranslatorTuple] = [TranslatorTuple(\"\", \"\", [])]\n) -&gt; dict\n</code></pre> <p>Converts a list of fields into a nested dictionary representing a translator.</p> <p>Parameters:</p> Name Type Description Default <code>fields</code> <code>list[TranslatorTuple]</code> <p>A list of tuples representing fields to be translated.</p> <code>[TranslatorTuple('', '', [])]</code> <p>Returns:</p> Type Description <code>dict</code> <p>A nested dictionary representing the translator. The structure of the dictionary follows the format: <pre><code>{\n    'part1': {\n          'part2': {\n              'translated_field': 'pk'\n          }\n    }\n}\n</code></pre></p> Example <pre><code>&gt;&gt;&gt; fields = [\n...     TranslatorTuple(\n...         start='start__field1',\n...         finish='field1',\n...         lst=[{\n...             'fields': {'field1': 'translation1'},\n...             'pk': 1}],\n...      )]\n&gt;&gt;&gt; get_translator(fields)\n{'start': {'field1': {'translation1': 1}}}\n</code></pre> Source code in <code>alto2txt2fixture/parser.py</code> <pre><code>def get_translator(\n    fields: list[TranslatorTuple] = [TranslatorTuple(\"\", \"\", [])]\n) -&gt; dict:\n    \"\"\"\n    Converts a list of fields into a nested dictionary representing a\n    translator.\n\n    Args:\n        fields: A list of tuples representing fields to be translated.\n\n    Returns:\n        A nested dictionary representing the translator. The structure of\n            the dictionary follows the format:\n            ```python\n            {\n                'part1': {\n                      'part2': {\n                          'translated_field': 'pk'\n                      }\n                }\n            }\n            ```\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; fields = [\n        ...     TranslatorTuple(\n        ...         start='start__field1',\n        ...         finish='field1',\n        ...         lst=[{\n        ...             'fields': {'field1': 'translation1'},\n        ...             'pk': 1}],\n        ...      )]\n        &gt;&gt;&gt; get_translator(fields)\n        {'start': {'field1': {'translation1': 1}}}\n\n        ```\n    \"\"\"\n    _ = dict()\n    for field in fields:\n        start, finish, lst = field\n        part1, part2 = start.split(\"__\")\n        if part1 not in _:\n            _[part1] = {}\n        if part2 not in _[part1]:\n            _[part1][part2] = {}\n        if isinstance(finish, str):\n            _[part1][part2] = {o[\"fields\"][finish]: o[\"pk\"] for o in lst}\n        elif isinstance(finish, list):\n            _[part1][part2] = {\n                \"-\".join([o[\"fields\"][x] for x in finish]): o[\"pk\"] for o in lst\n            }\n\n    return _\n</code></pre>"},{"location":"reference/alto2txt2fixture/parser.html#alto2txt2fixture.parser.parse","title":"parse","text":"<pre><code>parse(\n    collections: list, cache_home: str, output: str, max_elements_per_file: int\n) -&gt; None\n</code></pre> <p>Parses files from collections and generates fixtures for various models.</p> <p>This function processes files from the specified collections and generates fixtures for different models, such as <code>newspapers.dataprovider</code>, <code>newspapers.ingest</code>, <code>newspapers.digitisation</code>, <code>newspapers.newspaper</code>, <code>newspapers.issue</code>, and <code>newspapers.item</code>.</p> <p>It performs various steps, such as file listing, fixture generation, translation mapping, renaming fields, and saving fixtures to files.</p> <p>Parameters:</p> Name Type Description Default <code>collections</code> <code>list</code> <p>A list of collections from which files are processed and fixtures are generated.</p> required <code>cache_home</code> <code>str</code> <p>The directory path where the collections are located.</p> required <code>output</code> <code>str</code> <p>The directory path where the fixtures will be saved.</p> required <code>max_elements_per_file</code> <code>int</code> <p>The maximum number of elements per file when saving fixtures.</p> required <p>Returns:</p> Type Description <code>None</code> <p>This function generates fixtures but does not return any value.</p> Source code in <code>alto2txt2fixture/parser.py</code> <pre><code>def parse(\n    collections: list, cache_home: str, output: str, max_elements_per_file: int\n) -&gt; None:\n    \"\"\"\n    Parses files from collections and generates fixtures for various models.\n\n    This function processes files from the specified collections and generates\n    fixtures for different models, such as `newspapers.dataprovider`,\n    `newspapers.ingest`, `newspapers.digitisation`, `newspapers.newspaper`,\n    `newspapers.issue`, and `newspapers.item`.\n\n    It performs various steps, such as file listing, fixture generation,\n    translation mapping, renaming fields, and saving fixtures to files.\n\n    Args:\n        collections: A list of collections from which files are\n            processed and fixtures are generated.\n        cache_home: The directory path where the collections are located.\n        output: The directory path where the fixtures will be saved.\n        max_elements_per_file: The maximum number of elements per file\n            when saving fixtures.\n\n    Returns:\n        This function generates fixtures but does not return any value.\n    \"\"\"\n    global CACHE_HOME\n    global OUTPUT\n    global MAX_ELEMENTS_PER_FILE\n\n    CACHE_HOME = cache_home\n    OUTPUT = output\n    MAX_ELEMENTS_PER_FILE = max_elements_per_file\n\n    # Set up output directory\n    reset_fixture_dir(OUTPUT)\n\n    # Get file lists\n    print(\"\\nGetting file lists...\")\n\n    def issues_in_x(x):\n        return \"issues\" in str(x.parent).split(\"/\")\n\n    def newspapers_in_x(x):\n        return not any(\n            [\n                condition\n                for y in str(x.parent).split(\"/\")\n                for condition in [\n                    \"issues\" in y,\n                    \"ingest\" in y,\n                    \"digitisation\" in y,\n                    \"data-provider\" in y,\n                ]\n            ]\n        )\n\n    all_json = [\n        x for y in collections for x in (Path(CACHE_HOME) / y).glob(\"**/*.json\")\n    ]\n    all_jsonl = [\n        x for y in collections for x in (Path(CACHE_HOME) / y).glob(\"**/*.jsonl\")\n    ]\n    print(f\"--&gt; {len(all_json):,} JSON files altogether\")\n    print(f\"--&gt; {len(all_jsonl):,} JSONL files altogether\")\n\n    print(\"\\nSetting up fixtures...\")\n\n    # Process data providers\n    def data_provider_in_x(x):\n        return \"data-provider\" in str(x.parent).split(\"/\")\n\n    data_provider_json = list(\n        fixtures(\n            model=\"newspapers.dataprovider\",\n            filelist=[x for x in all_json if data_provider_in_x(x)],\n            uniq_keys=[\"name\"],\n        )\n    )\n    print(f\"--&gt; {len(data_provider_json):,} DataProvider fixtures\")\n\n    # Process ingest\n    def ingest_in_x(x):\n        return \"ingest\" in str(x.parent).split(\"/\")\n\n    ingest_json = list(\n        fixtures(\n            model=\"newspapers.ingest\",\n            filelist=[x for x in all_json if ingest_in_x(x)],\n            uniq_keys=[\"lwm_tool_name\", \"lwm_tool_version\"],\n        )\n    )\n    print(f\"--&gt; {len(ingest_json):,} Ingest fixtures\")\n\n    # Process digitisation\n    def digitisation_in_x(x):\n        return \"digitisation\" in str(x.parent).split(\"/\")\n\n    digitisation_json = list(\n        fixtures(\n            model=\"newspapers.digitisation\",\n            filelist=[x for x in all_json if digitisation_in_x(x)],\n            uniq_keys=[\"software\"],\n        )\n    )\n    print(f\"--&gt; {len(digitisation_json):,} Digitisation fixtures\")\n\n    # Process newspapers\n    newspaper_json = list(\n        fixtures(\n            model=\"newspapers.newspaper\",\n            filelist=[file for file in all_json if newspapers_in_x(file)],\n        )\n    )\n    print(f\"--&gt; {len(newspaper_json):,} Newspaper fixtures\")\n\n    # Process issue\n    translate = get_translator(\n        [\n            TranslatorTuple(\n                \"publication__publication_code\", \"publication_code\", newspaper_json\n            )\n        ]\n    )\n    rename = {\"publication\": {\"publication_code\": \"newspaper_id\"}}\n\n    issue_json = list(\n        fixtures(\n            model=\"newspapers.issue\",\n            filelist=[file for file in all_json if issues_in_x(file)],\n            translate=translate,\n            rename=rename,\n        )\n    )\n    print(f\"--&gt; {len(issue_json):,} Issue fixtures\")\n\n    # Create translator/clear up memory before processing items\n    translate = get_translator(\n        [\n            (\"issue__issue_identifier\", \"issue_code\", issue_json),\n            (\"digitisation__software\", \"software\", digitisation_json),\n            (\"data_provider__name\", \"name\", data_provider_json),\n            (\n                \"ingest__lwm_tool_identifier\",\n                [\"lwm_tool_name\", \"lwm_tool_version\"],\n                ingest_json,\n            ),\n        ]\n    )\n\n    rename = {\n        \"issue\": {\"issue_identifier\": \"issue_id\"},\n        \"digitisation\": {\"software\": \"digitisation_id\"},\n        \"data_provider\": {\"name\": \"data_provider_id\"},\n        \"ingest\": {\"lwm_tool_identifier\": \"ingest_id\"},\n    }\n\n    save_fixture(newspaper_json, \"Newspaper\")\n    save_fixture(issue_json, \"Issue\")\n\n    del newspaper_json\n    del issue_json\n    gc.collect()\n\n    print(\"\\nSaving...\")\n\n    save_fixture(digitisation_json, \"Digitisation\")\n    save_fixture(ingest_json, \"Ingest\")\n    save_fixture(data_provider_json, \"DataProvider\")\n\n    # Process items\n    item_json = fixtures(\n        model=\"newspapers.item\",\n        filelist=all_jsonl,\n        translate=translate,\n        rename=rename,\n    )\n    save_fixture(item_json, \"Item\")\n\n    return\n</code></pre>"},{"location":"reference/alto2txt2fixture/parser.html#alto2txt2fixture.parser.reset_fixture_dir","title":"reset_fixture_dir","text":"<pre><code>reset_fixture_dir(output: str | Path) -&gt; None\n</code></pre> <p>Resets the fixture directory by removing all JSON files inside it.</p> <p>This function takes a directory path (<code>output</code>) as input and removes all JSON files within the directory.</p> <p>Prior to removal, it prompts the user for confirmation to proceed. If the user confirms, the function clears the fixture directory by deleting the JSON files.</p> <p>Parameters:</p> Name Type Description Default <code>output</code> <code>str | Path</code> <p>The directory path of the fixture directory to be reset.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the <code>output</code> directory is not specified as a string.</p> Source code in <code>alto2txt2fixture/parser.py</code> <pre><code>def reset_fixture_dir(output: str | Path) -&gt; None:\n    \"\"\"\n    Resets the fixture directory by removing all JSON files inside it.\n\n    This function takes a directory path (``output``) as input and removes all\n    JSON files within the directory.\n\n    Prior to removal, it prompts the user for confirmation to proceed. If the\n    user confirms, the function clears the fixture directory by deleting the\n    JSON files.\n\n    Args:\n        output: The directory path of the fixture directory to be reset.\n\n    Raises:\n        RuntimeError: If the ``output`` directory is not specified as a string.\n    \"\"\"\n\n    if not isinstance(output, str):\n        raise RuntimeError(\"`output` directory needs to be specified as a string.\")\n\n    output = Path(output)\n\n    y = input(\n        f\"This command will automatically empty the fixture directory ({output.absolute()}). \"\n        \"Do you want to proceed? [y/N]\"\n    )\n\n    if not y.lower() == \"y\":\n        output.mkdir(parents=True, exist_ok=True)\n        return\n\n    print(\"\\nClearing up the fixture directory\")\n\n    # Ensure directory exists\n    output.mkdir(parents=True, exist_ok=True)\n\n    # Drop all JSON files\n    [x.unlink() for x in Path(output).glob(\"*.json\")]\n\n    return\n</code></pre>"},{"location":"reference/alto2txt2fixture/parser.html#alto2txt2fixture.parser.uniq","title":"uniq","text":"<pre><code>uniq(filelist: list, keys: list = []) -&gt; Generator[Any, None, None]\n</code></pre> <p>Generates unique items from a list of files based on specified keys.</p> <p>This function takes a list of files and yields unique items based on a combination of keys. The keys are extracted from each file using the <code>get_key_from</code> function, and duplicate items are ignored.</p> <p>Parameters:</p> Name Type Description Default <code>filelist</code> <code>list</code> <p>A list of files from which unique items are generated.</p> required <code>keys</code> <code>list</code> <p>A list of keys used for uniqueness. Each key specifies a field to be used for uniqueness checking in the generated items.</p> <code>[]</code> <p>Yields:</p> Type Description <code>Any</code> <p>A unique item from <code>filelist</code>.</p> Source code in <code>alto2txt2fixture/parser.py</code> <pre><code>def uniq(filelist: list, keys: list = []) -&gt; Generator[Any, None, None]:\n    \"\"\"\n    Generates unique items from a list of files based on specified keys.\n\n    This function takes a list of files and yields unique items based on a\n    combination of keys. The keys are extracted from each file using the\n    ``get_key_from`` function, and duplicate items are ignored.\n\n    Args:\n        filelist: A list of files from which unique items are\n            generated.\n        keys: A list of keys used for uniqueness. Each key specifies\n            a field to be used for uniqueness checking in the generated\n            items.\n\n    Yields:\n        A unique item from `filelist`.\n    \"\"\"\n\n    seen = set()\n    for item in filelist:\n        key = \"-\".join([get_key_from(item, x) for x in keys])\n\n        if key not in seen:\n            seen.add(key)\n            yield item\n        else:\n            # Drop it if duplicate\n            pass\n</code></pre>"},{"location":"reference/alto2txt2fixture/patterns.html","title":"patterns","text":"<p>Useful regular expressions, intially just <code>PUBLICATION_CODE</code>.</p>"},{"location":"reference/alto2txt2fixture/plaintext.html","title":"plaintext","text":""},{"location":"reference/alto2txt2fixture/plaintext.html#alto2txt2fixture.plaintext.FullTextPathDict","title":"FullTextPathDict","text":"<p>             Bases: <code>TypedDict</code></p> <p>A <code>dict</code> of <code>lwmdb.newspapers.models.FullText</code> fixture structure.</p> <p>Attributes:</p> Name Type Description <code>text_path</code> <code>PathLike</code> <p>PlainText file path.</p> <code>text_compressed_path</code> <code>PathLike | None</code> <p>If <code>path</code> is within a compressed file, <code>compressed_path</code> is that source. Else None.</p> <code>primary_key</code> <code>int</code> <p>An <code>int &gt;= 1</code> for a <code>SQL</code> table primary key (<code>pk</code>).</p>"},{"location":"reference/alto2txt2fixture/plaintext.html#alto2txt2fixture.plaintext.PlainTextFixture","title":"PlainTextFixture  <code>dataclass</code>","text":"<p>Manage exporting <code>plaintext</code> for <code>lwmdb.newspapers.models.FullText</code>.</p> <p>Attributes:</p> Name Type Description <code>path</code> <code>PathLike</code> <p>PathLike source for fixtures as either a folder or file.</p> <code>data_provider_code</code> <code>str | None</code> <p>A short string to uniquely identify <code>DataProviders</code>, primarily to match sources in <code>self.data_provider_code_dict</code>.</p> <code>files</code> <code>tuple[PathLike, ...] | None</code> <p>A iterable <code>PathLike</code> collection of to either read as plaintext or decomepress to extract plaintext.</p> <code>compressed_glob_regex</code> <code>str</code> <p>A Regular Expression to filter plaintext files from uncompressed <code>self.files</code>, more specifically <code>self.compressed_files</code>.</p> <code>data_provider</code> <code>DataProviderFixtureDict | None</code> <p>If available a <code>DataProviderFixtureDict</code> for <code>DataProvider</code> metadata. By default all options are stored in <code>self.data_provider_code_dict</code>.</p> <code>model_str</code> <code>str</code> <p>The name of the <code>lwmdb</code> <code>django</code> model the fixture is for. This is of the form <code>app_name.model_name</code>. Following the default config for <code>lwmdb</code>: <pre><code>FULLTEXT_DJANGO_MODEL: Final[str] = \"newspapers.fulltext\"\n</code></pre> the <code>newspapers</code> app has a <code>fulltext</code> <code>model</code> <code>class</code> specified in <code>lwmdb.newspapers.models.fulltext</code>. A <code>sql</code> table is generated from on that <code>FullText</code> <code>class</code> and the <code>json</code> <code>fixture</code> structure generated from this class is where records will be stored.</p> <code>fixture_info</code> <code>str</code> <p>Text to include in the <code>info</code> portion for output fixture.</p> <code>include_text_fixture_paths</code> <code>bool</code> <p>Include <code>text_fixture_path</code> fields in output fixture.</p> <code>is_canonical</code> <code>bool</code> <p>Set the <code>canonical</code> field for output Fixture.</p> <code>extract_subdir</code> <code>PathLike</code> <p>Folder to extract <code>self.compressed_files</code> to.</p> <code>plaintext_extension</code> <code>str</code> <p>What file extension to use to filter <code>plaintext</code> files.</p> <code>data_provider_code_dict</code> <code>dict[str, DataProviderFixtureDict]</code> <p>A <code>dict</code> of metadata for preconfigured <code>DataProvider</code> records in <code>lwmdb</code>.</p> <code>max_plaintext_per_fixture_file</code> <code>int</code> <p>A maximum number of fixtures per fixture file, designed to configure chunking fixtures.</p> <code>saved_fixture_prefix</code> <code>str</code> <p>A <code>str</code> to prefix all saved <code>json</code> fixture filenames.</p> <code>export_directory</code> <code>PathLike</code> <p>Directory to save all exported fixtures to.</p> <code>initial_pk</code> <code>int</code> <p>Default begins at 1, can be set to another number if needed to add to add more to pre-existing set of records up to a given <code>pk</code></p> <code>json_0_file_name_padding</code> <code>int</code> <p>Number of <code>0</code>s to prefix file name numbering.</p> <code>_disk_usage</code> <code>int</code> <p>Available harddrive space. Designed to help mitigate decompressing too many files for available disk space.</p> <code>self._uncompressed_source_file_dict</code> <code>int</code> <p>A dictionary of extracted plaintext to compressed source file. This is a field in <code>json</code> fixture records.</p> Example <pre><code>&gt;&gt;&gt; tmp_path = getfixture('tmp_path')\n&gt;&gt;&gt; path = getfixture('bl_lwm')\n&gt;&gt;&gt; logger_initial_level: int = logger.level\n&gt;&gt;&gt; logger.setLevel(INFO)\n&gt;&gt;&gt; plaintext_bl_lwm = PlainTextFixture(\n...     data_provider_code='bl-lwm',\n...     path=path,\n...     compressed_glob_regex=\"*_plaintext.zip\",\n...     )\n&gt;&gt;&gt; plaintext_bl_lwm\n&lt;PlainTextFixture(path='...bl_lwm')&gt;\n&gt;&gt;&gt; plaintext_bl_lwm.info()\n&lt;BLANKLINE&gt;\n...PlainTextFixture for 2 'bl-lwm' files...\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500...\u2510\n\u2502 Path                \u2502 '...bl_lwm'                    ...\u2502\n\u2502 Compressed Files    \u2502 '...bl_lwm...0003079-test_plain...\u2502\n\u2502                     \u2502 '...bl_lwm...0003548-test_plain...\u2502\n\u2502 Extract Path        \u2502 '...bl_lwm...extracted'        ...\u2502\n\u2502 Uncompressed Files  \u2502 None                           ...\u2502\n\u2502 Data Provider       \u2502 'Living with Machines'         ...\u2502\n\u2502 Initial Primary Key \u2502 1                              ...\u2502\n\u2502 Max Rows Per JSON   \u2502 100                            ...\u2502\n\u2502 JSON File Name 0s   \u2502 6                              ...\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500...\u2518\n&gt;&gt;&gt; plaintext_bl_lwm.free_hd_space_in_GB &gt; 1\nTrue\n&gt;&gt;&gt; plaintext_bl_lwm.extract_compressed()\n&lt;BLANKLINE&gt;\n...Extract path:...\n...Extracting:...'...lwm...00030...\n...Extracting:...'...lwm...00035...\n&gt;&gt;&gt; plaintext_bl_lwm.delete_decompressed()\nDeleting all files in:...'...bl_lwm...tracted'\n&gt;&gt;&gt; logger.setLevel(logger_initial_level)\n</code></pre>"},{"location":"reference/alto2txt2fixture/plaintext.html#alto2txt2fixture.plaintext.PlainTextFixture.compressed_files","title":"compressed_files  <code>property</code>","text":"<pre><code>compressed_files: tuple[PathLike, ...]\n</code></pre> <p>Return a tuple of all <code>self.files</code> with known archive file names.</p>"},{"location":"reference/alto2txt2fixture/plaintext.html#alto2txt2fixture.plaintext.PlainTextFixture.compressed_json_export_paths","title":"compressed_json_export_paths  <code>property</code>","text":"<pre><code>compressed_json_export_paths: Generator[Path, None, None]\n</code></pre> <p>Yield from <code>self._compressed_exported_json_paths</code> if it exists.</p> <p>Yields:</p> Type Description <p>Each path from <code>self._compressed_exported_json_paths</code> if set, else None.</p> Example <pre><code>&gt;&gt;&gt; plaintext_bl_lwm = getfixture('bl_lwm_plaintext_json_export')\n&lt;BLANKLINE&gt;\n...\n&gt;&gt;&gt; tuple(plaintext_bl_lwm.compressed_json_export_paths)\n&lt;BLANKLINE&gt;\n...No compressed paths set. Try running...'.compress_json_exports()'...\n()\n&gt;&gt;&gt; logger_initial_level: int = logger.level\n&gt;&gt;&gt; logger.setLevel(DEBUG)\n&gt;&gt;&gt; compressed_paths: Path = plaintext_bl_lwm.compress_json_exports(\n...     format='tar')\n&lt;BLANKLINE&gt;\n...Compressing...'...01.json...'...to...'tar'...in:...\n&gt;&gt;&gt; tuple(plaintext_bl_lwm.compressed_json_export_paths)\n(...Path('...plaintext_fixture-000001.json.tar'),)\n&gt;&gt;&gt; compressed_paths == tuple(\n...     plaintext_bl_lwm.compressed_json_export_paths)\nTrue\n&gt;&gt;&gt; logger.setLevel(logger_initial_level)\n</code></pre>"},{"location":"reference/alto2txt2fixture/plaintext.html#alto2txt2fixture.plaintext.PlainTextFixture.data_provider_name","title":"data_provider_name  <code>property</code>","text":"<pre><code>data_provider_name: str | None\n</code></pre> <p>Return <code>self.data_provider</code> <code>code</code> attributre or <code>None</code>.</p> Todo <ul> <li>Add check without risk of recursion for <code>self.data_provider_code</code></li> </ul> Example <pre><code>&gt;&gt;&gt; bl_hmd = PlainTextFixture(\n...     path=\".\",\n...     data_provider_code=\"bl-hmd\")\n&gt;&gt;&gt; bl_hmd.data_provider_name\n'Heritage Made Digital'\n&gt;&gt;&gt; bl_lwm = PlainTextFixture(\n...     path='.',\n...     data_provider=NEWSPAPER_DATA_PROVIDER_CODE_DICT['bl-lwm'],\n...     )\n&gt;&gt;&gt; bl_lwm.data_provider_name\n'Living with Machines'\n&gt;&gt;&gt; logger_initial_level: int = logger.level\n&gt;&gt;&gt; logger.setLevel(DEBUG)\n&gt;&gt;&gt; no_provider_fixture = PlainTextFixture(path=\".\")\n&lt;BLANKLINE&gt;\n...'.data_provider' and '.data_provider_code'...\n...are...'None'...in...&lt;PlainTextFixture(path='.')&gt;...\n&gt;&gt;&gt; no_provider_fixture.data_provider\n&gt;&gt;&gt; no_provider_fixture.data_provider_name\n&gt;&gt;&gt; logger.setLevel(logger_initial_level)\n</code></pre>"},{"location":"reference/alto2txt2fixture/plaintext.html#alto2txt2fixture.plaintext.PlainTextFixture.exported_json_paths","title":"exported_json_paths  <code>property</code>","text":"<pre><code>exported_json_paths: Generator[Path, None, None]\n</code></pre> <p>If <code>self._exported_json_paths</code> return <code>Generator</code> of those paths.</p> <p>Yields:</p> Type Description <p>Each path from <code>self._exported_json_paths</code></p> Example <pre><code>&gt;&gt;&gt; if is_platform_win:\n...     pytest.skip('decompression fails on Windows: issue #55')\n&gt;&gt;&gt; plaintext_bl_lwm = getfixture('bl_lwm_plaintext_json_export')\n&lt;BLANKLINE&gt;\n...\n&gt;&gt;&gt; tuple(plaintext_bl_lwm.exported_json_paths)\n(...Path('...plaintext_fixture-000001.json'),)\n</code></pre>"},{"location":"reference/alto2txt2fixture/plaintext.html#alto2txt2fixture.plaintext.PlainTextFixture.extract_path","title":"extract_path  <code>property</code>","text":"<pre><code>extract_path: Path\n</code></pre> <p>Path any compressed files would be extracted to.</p>"},{"location":"reference/alto2txt2fixture/plaintext.html#alto2txt2fixture.plaintext.PlainTextFixture.free_hd_space_in_GB","title":"free_hd_space_in_GB  <code>property</code>","text":"<pre><code>free_hd_space_in_GB: float\n</code></pre> <p>Return remaing hard drive space estimate in gigabytes.</p>"},{"location":"reference/alto2txt2fixture/plaintext.html#alto2txt2fixture.plaintext.PlainTextFixture.info_table","title":"info_table  <code>property</code>","text":"<pre><code>info_table: Table\n</code></pre> <p>Generate a <code>rich.table.Table</code> of config information.</p> Example <pre><code>&gt;&gt;&gt; hmd_plaintext_fixture = PlainTextFixture(\n...     path=\".\",\n...     data_provider_code=\"bl-hmd\")\n&gt;&gt;&gt; table = hmd_plaintext_fixture.info_table\n&gt;&gt;&gt; table.title\n\"PlainTextFixture for 0 'bl-hmd' files\"\n</code></pre>"},{"location":"reference/alto2txt2fixture/plaintext.html#alto2txt2fixture.plaintext.PlainTextFixture.plaintext_provided_uncompressed","title":"plaintext_provided_uncompressed  <code>property</code>","text":"<pre><code>plaintext_provided_uncompressed: tuple[PathLike, ...]\n</code></pre> <p>Return a tuple of all <code>self.files</code> with <code>self.plaintext_extension</code>.</p>"},{"location":"reference/alto2txt2fixture/plaintext.html#alto2txt2fixture.plaintext.PlainTextFixture.trunc_compressed_file_names_str","title":"trunc_compressed_file_names_str  <code>property</code>","text":"<pre><code>trunc_compressed_file_names_str: str\n</code></pre> <p>Return truncated <code>self.compressed_files</code> file names or empty <code>str</code>.</p>"},{"location":"reference/alto2txt2fixture/plaintext.html#alto2txt2fixture.plaintext.PlainTextFixture.trunc_extract_path_str","title":"trunc_extract_path_str  <code>property</code>","text":"<pre><code>trunc_extract_path_str: str\n</code></pre> <p>Return truncated <code>self.extract_path</code> or empty <code>str</code>.</p>"},{"location":"reference/alto2txt2fixture/plaintext.html#alto2txt2fixture.plaintext.PlainTextFixture.trunc_uncompressed_file_names_str","title":"trunc_uncompressed_file_names_str  <code>property</code>","text":"<pre><code>trunc_uncompressed_file_names_str: str\n</code></pre> <p>Return truncated <code>self.plaintext_provided_uncompressed</code> file names or empty <code>str</code>.</p>"},{"location":"reference/alto2txt2fixture/plaintext.html#alto2txt2fixture.plaintext.PlainTextFixture.zipinfo","title":"zipinfo  <code>property</code>","text":"<pre><code>zipinfo: Generator[list[ZipInfo], None, None]\n</code></pre> <p>If <code>self.compressed_files</code> is in <code>zip</code>, return info, else None.</p> Example <pre><code>&gt;&gt;&gt; plaintext_bl_lwm = getfixture('bl_lwm_plaintext')\n&gt;&gt;&gt; zipfile_info_list: list[ZipInfo] = list(plaintext_bl_lwm.zipinfo)\nGetting zipfile info from &lt;PlainTextFixture(path='bl_lwm')&gt;\n&gt;&gt;&gt; zipfile_info_list[0][-1].filename\n'0003079...1898...0204...0003079_18980204_sect0001.txt'\n&gt;&gt;&gt; zipfile_info_list[-1][-1].filename\n'0003548...1904...0707...0003548_19040707_art0059.txt'\n&gt;&gt;&gt; zipfile_info_list[0][-1].file_size\n70192\n&gt;&gt;&gt; zipfile_info_list[0][-1].compress_size\n39911\n</code></pre>"},{"location":"reference/alto2txt2fixture/plaintext.html#alto2txt2fixture.plaintext.PlainTextFixture.__len__","title":"__len__","text":"<pre><code>__len__() -&gt; int\n</code></pre> <p>Return the number of files to process.</p> Source code in <code>alto2txt2fixture/plaintext.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of files to process.\"\"\"\n    return len(self.files) if self.files else 0\n</code></pre>"},{"location":"reference/alto2txt2fixture/plaintext.html#alto2txt2fixture.plaintext.PlainTextFixture.__post_init__","title":"__post_init__","text":"<pre><code>__post_init__() -&gt; None\n</code></pre> <p>Manage populating additional attributes if necessary.</p> Source code in <code>alto2txt2fixture/plaintext.py</code> <pre><code>def __post_init__(self) -&gt; None:\n    \"\"\"Manage populating additional attributes if necessary.\"\"\"\n    self._check_and_set_files_attr(force=True)\n    self._check_and_set_data_provider(force=True)\n    self._disk_usage: DiskUsageTuple = disk_usage(self.path)\n    self._uncompressed_source_file_dict: OrderedDict[\n        PathLike, PathLike\n    ] = OrderedDict()\n    self._pk_plaintext_dict: OrderedDict[PathLike, int] = OrderedDict()\n</code></pre>"},{"location":"reference/alto2txt2fixture/plaintext.html#alto2txt2fixture.plaintext.PlainTextFixture.__repr__","title":"__repr__","text":"<pre><code>__repr__() -&gt; str\n</code></pre> <p>Return <code>class</code> name with <code>path</code> attribute.</p> Source code in <code>alto2txt2fixture/plaintext.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return `class` name with `path` attribute.\"\"\"\n    return f\"&lt;{type(self).__name__}(path='{self.path}')&gt;\"\n</code></pre>"},{"location":"reference/alto2txt2fixture/plaintext.html#alto2txt2fixture.plaintext.PlainTextFixture.__str__","title":"__str__","text":"<pre><code>__str__() -&gt; str\n</code></pre> <p>Return class name with count and <code>DataProvider</code> if available.</p> Source code in <code>alto2txt2fixture/plaintext.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return class name with count and `DataProvider` if available.\"\"\"\n    return (\n        f\"{type(self).__name__} \"\n        f\"for {len(self)} \"\n        f\"{self._data_provider_code_quoted_with_trailing_space}files\"\n    )\n</code></pre>"},{"location":"reference/alto2txt2fixture/plaintext.html#alto2txt2fixture.plaintext.PlainTextFixture.compress_json_exports","title":"compress_json_exports","text":"<pre><code>compress_json_exports(\n    output_path: PathLike | None = None, format: ArchiveFormatEnum | None = None\n) -&gt; tuple[Path, ...]\n</code></pre> <p>Compress <code>self._exported_json_paths</code> to <code>format</code>.</p> <p>Parameters:</p> Name Type Description Default <code>output_path</code> <code>PathLike | None</code> <p><code>Path</code> to save compressed <code>json</code> files to. Uses <code>self.json_export_compression_subdir</code> if <code>None</code> is passed.</p> <code>None</code> <code>format</code> <code>ArchiveFormatEnum | None</code> <p>What compression format to use from <code>ArchiveFormatEnum</code>. Uses <code>self.json_export_compression_format</code> if <code>None</code> is passed.</p> <code>None</code> Note <p>Neither <code>output_path</code> nor <code>format</code> overwrite the related attributes of <code>self</code>.</p> <p>Returns: The the <code>output_path</code> passed to save compressed <code>json</code>.</p> Example <pre><code>&gt;&gt;&gt; if is_platform_win:\n...     pytest.skip('decompression fails on Windows: issue #55')\n&gt;&gt;&gt; logger_initial_level: int = logger.level\n&gt;&gt;&gt; logger.setLevel(DEBUG)\n&gt;&gt;&gt; plaintext_bl_lwm = getfixture('bl_lwm_plaintext_json_export')\n&lt;BLANKLINE&gt;\n...\n&gt;&gt;&gt; compressed_paths: Path = plaintext_bl_lwm.compress_json_exports(\n...     format='tar')\n&lt;BLANKLINE&gt;\n...Compressing...'...01.json...'...to...'tar'...in:...\n&gt;&gt;&gt; compressed_paths\n(...Path('.../plaintext_fixture-000001.json.tar'),)\n&gt;&gt;&gt; logger.setLevel(logger_initial_level)\n</code></pre> Source code in <code>alto2txt2fixture/plaintext.py</code> <pre><code>def compress_json_exports(\n    self,\n    output_path: PathLike | None = None,\n    format: ArchiveFormatEnum | None = None,\n) -&gt; tuple[Path, ...]:\n    \"\"\"Compress `self._exported_json_paths` to `format`.\n\n    Args:\n        output_path:\n            `Path` to save compressed `json` files to. Uses\n            `self.json_export_compression_subdir` if `None` is passed.\n        format:\n            What compression format to use from `ArchiveFormatEnum`. Uses\n            `self.json_export_compression_format` if `None` is passed.\n\n    Note:\n        Neither `output_path` nor `format` overwrite the related attributes\n        of `self`.\n\n    Returns: The the `output_path` passed to save compressed `json`.\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; if is_platform_win:\n        ...     pytest.skip('decompression fails on Windows: issue #55')\n        &gt;&gt;&gt; logger_initial_level: int = logger.level\n        &gt;&gt;&gt; logger.setLevel(DEBUG)\n        &gt;&gt;&gt; plaintext_bl_lwm = getfixture('bl_lwm_plaintext_json_export')\n        &lt;BLANKLINE&gt;\n        ...\n        &gt;&gt;&gt; compressed_paths: Path = plaintext_bl_lwm.compress_json_exports(\n        ...     format='tar')\n        &lt;BLANKLINE&gt;\n        ...Compressing...'...01.json...'...to...'tar'...in:...\n        &gt;&gt;&gt; compressed_paths\n        (...Path('.../plaintext_fixture-000001.json.tar'),)\n        &gt;&gt;&gt; logger.setLevel(logger_initial_level)\n\n        ```\n\n    \"\"\"\n    output_path = (\n        Path(self.json_export_compression_subdir)\n        if not output_path\n        else Path(output_path)\n    )\n    format = self.json_export_compression_format if not format else format\n    compressed_paths: list[Path] = []\n    for json_path in self.exported_json_paths:\n        compressed_paths.append(\n            compress_fixture(json_path, output_path=output_path, format=format)\n        )\n    self._compressed_exported_json_paths: tuple[Path, ...] = tuple(compressed_paths)\n    return self._compressed_exported_json_paths\n</code></pre>"},{"location":"reference/alto2txt2fixture/plaintext.html#alto2txt2fixture.plaintext.PlainTextFixture.delete_decompressed","title":"delete_decompressed","text":"<pre><code>delete_decompressed(ignore_errors: bool = True) -&gt; None\n</code></pre> <p>Remove all files in <code>self.extract_path</code>.</p> Example <pre><code>&gt;&gt;&gt; plaintext_bl_lwm = getfixture('bl_lwm_plaintext_extracted')\n&lt;BLANKLINE&gt;\n...Extract path:...'...bl_lwm...extracted'...\n&gt;&gt;&gt; plaintext_bl_lwm.delete_decompressed()\nDeleting all files in:...\n&gt;&gt;&gt; plaintext_bl_lwm.delete_decompressed()\n&lt;BLANKLINE&gt;\n...Extract path empty:...'...bl_lwm...extracted'...\n</code></pre> Source code in <code>alto2txt2fixture/plaintext.py</code> <pre><code>def delete_decompressed(self, ignore_errors: bool = True) -&gt; None:\n    \"\"\"Remove all files in `self.extract_path`.\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; plaintext_bl_lwm = getfixture('bl_lwm_plaintext_extracted')\n        &lt;BLANKLINE&gt;\n        ...Extract path:...'...bl_lwm...extracted'...\n        &gt;&gt;&gt; plaintext_bl_lwm.delete_decompressed()\n        Deleting all files in:...\n        &gt;&gt;&gt; plaintext_bl_lwm.delete_decompressed()\n        &lt;BLANKLINE&gt;\n        ...Extract path empty:...'...bl_lwm...extracted'...\n\n        ```\n    \"\"\"\n    if self.extract_path.exists():\n        console.print(f\"Deleting all files in: '{self.extract_path}'\")\n        rmtree(self.extract_path, ignore_errors=ignore_errors)\n    else:\n        console.log(f\"Extract path empty: '{self.extract_path}'\")\n</code></pre>"},{"location":"reference/alto2txt2fixture/plaintext.html#alto2txt2fixture.plaintext.PlainTextFixture.export_to_json_fixtures","title":"export_to_json_fixtures","text":"<pre><code>export_to_json_fixtures(\n    output_path: PathLike | None = None,\n    prefix: str | None = None,\n    json_0_file_name_padding: int | None = None,\n) -&gt; None\n</code></pre> <p>Iterate over <code>self.plaintext_paths</code> exporting to <code>json</code> <code>django</code> fixtures.</p> Note <p>For errors running on windows see: #55</p> <p>Parameters:</p> Name Type Description Default <code>output_path</code> <code>PathLike | None</code> <p>Folder to save all <code>json</code> fixtures in.</p> <code>None</code> <code>prefix</code> <code>str | None</code> <p>Any <code>str</code> prefix for saved fixture files.</p> <code>None</code> <code>json_0_file_name_padding</code> <code>int | None</code> <p>Number of <code>0</code>s to prefix file name numbering.</p> <code>None</code> Example <pre><code>&gt;&gt;&gt; if is_platform_win:\n...     pytest.skip('decompression fails on Windows: issue #55')\n&gt;&gt;&gt; bl_lwm: Path = getfixture(\"bl_lwm\")\n&gt;&gt;&gt; first_lwm_plaintext_json_dict: PlainTextFixtureDict = getfixture(\n...     'lwm_plaintext_json_dict_factory')()  # Factory returns `dict`\n&gt;&gt;&gt; plaintext_bl_lwm = getfixture('bl_lwm_plaintext_extracted')\n&lt;BLANKLINE&gt;\n...Extract path:...bl_lwm...extracted...\n&gt;&gt;&gt; plaintext_bl_lwm.export_to_json_fixtures(output_path=bl_lwm / \"output\")\n&lt;BLANKLINE&gt;\nCompressed configs...%...[...]\n&gt;&gt;&gt; len(plaintext_bl_lwm._exported_json_paths)\n1\n&gt;&gt;&gt; plaintext_bl_lwm._exported_json_paths\n(...Path(...plaintext_fixture-000001.json...),)\n&gt;&gt;&gt; import json\n&gt;&gt;&gt; exported_json = json.loads(\n...     plaintext_bl_lwm._exported_json_paths[0].read_text()\n... )\n&gt;&gt;&gt; exported_json[0]['pk'] == first_lwm_plaintext_json_dict['pk']\nTrue\n&gt;&gt;&gt; exported_json[0]['model'] == first_lwm_plaintext_json_dict['model']\nTrue\n&gt;&gt;&gt; (exported_json[0]['fields']['text'] ==\n...  first_lwm_plaintext_json_dict['fields']['text'])\nTrue\n&gt;&gt;&gt; (exported_json[0]['fields']['text_path'] ==\n...  str(first_lwm_plaintext_json_dict['fields']['text_path']))\nTrue\n&gt;&gt;&gt; (exported_json[0]['fields']['text_compressed_path'] ==\n...  str(first_lwm_plaintext_json_dict['fields']['text_compressed_path']))\nTrue\n&gt;&gt;&gt; exported_json[0]['fields']['created_at']\n'20...'\n&gt;&gt;&gt; (exported_json[0]['fields']['updated_at'] ==\n...  exported_json[0]['fields']['updated_at'])\nTrue\n</code></pre> Source code in <code>alto2txt2fixture/plaintext.py</code> <pre><code>def export_to_json_fixtures(\n    self,\n    output_path: PathLike | None = None,\n    prefix: str | None = None,\n    json_0_file_name_padding: int | None = None,\n) -&gt; None:\n    \"\"\"Iterate over `self.plaintext_paths` exporting to `json` `django` fixtures.\n\n    Note:\n        For errors running on windows see:\n        [#55](https://github.com/Living-with-machines/alto2txt2fixture/issues/55)\n\n    Args:\n        output_path:\n            Folder to save all `json` fixtures in.\n        prefix:\n            Any `str` prefix for saved fixture files.\n        json_0_file_name_padding:\n            Number of `0`s to prefix file name numbering.\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; if is_platform_win:\n        ...     pytest.skip('decompression fails on Windows: issue #55')\n        &gt;&gt;&gt; bl_lwm: Path = getfixture(\"bl_lwm\")\n        &gt;&gt;&gt; first_lwm_plaintext_json_dict: PlainTextFixtureDict = getfixture(\n        ...     'lwm_plaintext_json_dict_factory')()  # Factory returns `dict`\n        &gt;&gt;&gt; plaintext_bl_lwm = getfixture('bl_lwm_plaintext_extracted')\n        &lt;BLANKLINE&gt;\n        ...Extract path:...bl_lwm...extracted...\n        &gt;&gt;&gt; plaintext_bl_lwm.export_to_json_fixtures(output_path=bl_lwm / \"output\")\n        &lt;BLANKLINE&gt;\n        Compressed configs...%...[...]\n        &gt;&gt;&gt; len(plaintext_bl_lwm._exported_json_paths)\n        1\n        &gt;&gt;&gt; plaintext_bl_lwm._exported_json_paths\n        (...Path(...plaintext_fixture-000001.json...),)\n        &gt;&gt;&gt; import json\n        &gt;&gt;&gt; exported_json = json.loads(\n        ...     plaintext_bl_lwm._exported_json_paths[0].read_text()\n        ... )\n        &gt;&gt;&gt; exported_json[0]['pk'] == first_lwm_plaintext_json_dict['pk']\n        True\n        &gt;&gt;&gt; exported_json[0]['model'] == first_lwm_plaintext_json_dict['model']\n        True\n        &gt;&gt;&gt; (exported_json[0]['fields']['text'] ==\n        ...  first_lwm_plaintext_json_dict['fields']['text'])\n        True\n        &gt;&gt;&gt; (exported_json[0]['fields']['text_path'] ==\n        ...  str(first_lwm_plaintext_json_dict['fields']['text_path']))\n        True\n        &gt;&gt;&gt; (exported_json[0]['fields']['text_compressed_path'] ==\n        ...  str(first_lwm_plaintext_json_dict['fields']['text_compressed_path']))\n        True\n        &gt;&gt;&gt; exported_json[0]['fields']['created_at']\n        '20...'\n        &gt;&gt;&gt; (exported_json[0]['fields']['updated_at'] ==\n        ...  exported_json[0]['fields']['updated_at'])\n        True\n\n        ```\n    \"\"\"\n    output_path = self.export_directory if not output_path else output_path\n    prefix = self.saved_fixture_prefix if not prefix else prefix\n    json_0_file_name_padding = (\n        self.json_0_file_name_padding\n        if not json_0_file_name_padding\n        else json_0_file_name_padding\n    )\n    # Consider iterating over self.plaintext_paths_to_dicts(),\n    save_fixture(\n        self.plaintext_paths_to_dicts(),\n        prefix=prefix,\n        output_path=output_path,\n        add_created=True,\n        max_elements_per_file=self.max_plaintext_per_fixture_file,\n        file_name_0_padding=json_0_file_name_padding,\n        add_fixture_name=self.include_text_fixture_paths,\n        fixture_name_field=\"text_fixture_path\",\n    )\n    self.set_exported_json_paths(\n        export_directory=output_path, saved_fixture_prefix=prefix\n    )\n</code></pre>"},{"location":"reference/alto2txt2fixture/plaintext.html#alto2txt2fixture.plaintext.PlainTextFixture.extract_compressed","title":"extract_compressed","text":"<pre><code>extract_compressed(\n    overwite_extracts: bool = False, use_saved_if_exists: bool = False\n) -&gt; None\n</code></pre> <p>Extract <code>self.compressed_files</code> to <code>self.extracted_subdir_name</code>.</p> Example <pre><code>&gt;&gt;&gt; plaintext_bl_lwm = getfixture('bl_lwm_plaintext')\n&gt;&gt;&gt; plaintext_bl_lwm.extract_compressed()\n&lt;BLANKLINE&gt;\n...Extract path:...'...bl_lwm...extracted'...\n&gt;&gt;&gt; filter_sect1_txt: list[str] = [txt_file for txt_file in\n...  plaintext_bl_lwm._uncompressed_source_file_dict.keys()\n...  if txt_file.name.endswith('204_sect0001.txt')]\n&gt;&gt;&gt; len(filter_sect1_txt)\n1\n&gt;&gt;&gt; plaintext_bl_lwm._uncompressed_source_file_dict[\n...     filter_sect1_txt[0]\n...     ]\n&lt;BLANKLINE&gt;\n...Path('...bl_lwm...0003079-test_plaintext.zip')\n&gt;&gt;&gt; plaintext_bl_lwm.delete_decompressed()\nDeleting all files in:...'...bl_lwm...tracted'\n</code></pre> Source code in <code>alto2txt2fixture/plaintext.py</code> <pre><code>def extract_compressed(\n    self, overwite_extracts: bool = False, use_saved_if_exists: bool = False\n) -&gt; None:\n    \"\"\"Extract `self.compressed_files` to `self.extracted_subdir_name`.\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; plaintext_bl_lwm = getfixture('bl_lwm_plaintext')\n        &gt;&gt;&gt; plaintext_bl_lwm.extract_compressed()\n        &lt;BLANKLINE&gt;\n        ...Extract path:...'...bl_lwm...extracted'...\n        &gt;&gt;&gt; filter_sect1_txt: list[str] = [txt_file for txt_file in\n        ...  plaintext_bl_lwm._uncompressed_source_file_dict.keys()\n        ...  if txt_file.name.endswith('204_sect0001.txt')]\n        &gt;&gt;&gt; len(filter_sect1_txt)\n        1\n        &gt;&gt;&gt; plaintext_bl_lwm._uncompressed_source_file_dict[\n        ...     filter_sect1_txt[0]\n        ...     ]\n        &lt;BLANKLINE&gt;\n        ...Path('...bl_lwm...0003079-test_plaintext.zip')\n        &gt;&gt;&gt; plaintext_bl_lwm.delete_decompressed()\n        Deleting all files in:...'...bl_lwm...tracted'\n\n        ```\n\n    \"\"\"\n    if self.extract_path.exists():\n        logger.info(f\"Extract path exists: '{self.extract_path}'\")\n        if self.extract_path.is_file():\n            raise FileExistsError(\n                f\"Cannot extract to existing file: '{self.extract_path}'\"\n            )\n        shallow_sub_dirs: tuple[Path, ...] = tuple(\n            self.yield_extract_path_root_dirs\n        )\n        shallow_sub_files: tuple[Path, ...] = tuple(\n            files_in_path(self.extract_path)\n        )\n        if shallow_sub_files or shallow_sub_dirs:\n            logger.info(\n                f\"{len(shallow_sub_dirs)} folders and \"\n                f\"{len(shallow_sub_files)} files\"\n            )\n            if overwite_extracts:\n                self.delete_decompressed()\n                self._extract_all_from_extract_path()\n            elif use_saved_if_exists:\n                logger.info(f\"Checking existing extracts: '{self.extract_path}'\")\n                for compressed_file in tqdm(\n                    self.compressed_files,\n                    total=len(self.compressed_files),\n                ):\n                    self._add_path_to_uncompressed(compressed_file)\n            else:\n                logger.warning(\n                    f\"Cannot extract to folder with files: '{self.extract_path}'\"\n                )\n    else:\n        self._extract_all_from_extract_path()\n</code></pre>"},{"location":"reference/alto2txt2fixture/plaintext.html#alto2txt2fixture.plaintext.PlainTextFixture.info","title":"info","text":"<pre><code>info() -&gt; None\n</code></pre> <p>Print <code>self.info_table</code> to the <code>console</code>.</p> Source code in <code>alto2txt2fixture/plaintext.py</code> <pre><code>def info(self) -&gt; None:\n    \"\"\"Print `self.info_table` to the `console`.\"\"\"\n    console.print(self.info_table)\n</code></pre>"},{"location":"reference/alto2txt2fixture/plaintext.html#alto2txt2fixture.plaintext.PlainTextFixture.plaintext_paths","title":"plaintext_paths","text":"<pre><code>plaintext_paths(reset_cache=False) -&gt; Generator[FullTextPathDict, None, None]\n</code></pre> <p>Return a generator of all <code>plaintext</code> files for potential fixtures.</p> Example <pre><code>&gt;&gt;&gt; plaintext_bl_lwm = getfixture('bl_lwm_plaintext_extracted')\n&lt;BLANKLINE&gt;\n...Extract path: 'bl_lwm/test-extracted'...\n&gt;&gt;&gt; plaintext_paths = plaintext_bl_lwm.plaintext_paths()\n&gt;&gt;&gt; first_path_fixture_dict = next(iter(plaintext_paths))\n&gt;&gt;&gt; first_path_fixture_dict['text_path'].name\n'0003079_18980107_art0001.txt'\n&gt;&gt;&gt; first_path_fixture_dict['text_compressed_path'].name\n'0003079-test_plaintext.zip'\n&gt;&gt;&gt; len(plaintext_bl_lwm._pk_plaintext_dict)\n1\n&gt;&gt;&gt; plaintext_bl_lwm._pk_plaintext_dict[\n...     first_path_fixture_dict['text_path']\n... ] # This demonstrates the `pk` begins from 1 following `SQL` standards\n1\n</code></pre> Source code in <code>alto2txt2fixture/plaintext.py</code> <pre><code>def plaintext_paths(\n    self, reset_cache=False\n) -&gt; Generator[FullTextPathDict, None, None]:\n    \"\"\"Return a generator of all `plaintext` files for potential fixtures.\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; plaintext_bl_lwm = getfixture('bl_lwm_plaintext_extracted')\n        &lt;BLANKLINE&gt;\n        ...Extract path: 'bl_lwm/test-extracted'...\n        &gt;&gt;&gt; plaintext_paths = plaintext_bl_lwm.plaintext_paths()\n        &gt;&gt;&gt; first_path_fixture_dict = next(iter(plaintext_paths))\n        &gt;&gt;&gt; first_path_fixture_dict['text_path'].name\n        '0003079_18980107_art0001.txt'\n        &gt;&gt;&gt; first_path_fixture_dict['text_compressed_path'].name\n        '0003079-test_plaintext.zip'\n        &gt;&gt;&gt; len(plaintext_bl_lwm._pk_plaintext_dict)\n        1\n        &gt;&gt;&gt; plaintext_bl_lwm._pk_plaintext_dict[\n        ...     first_path_fixture_dict['text_path']\n        ... ] # This demonstrates the `pk` begins from 1 following `SQL` standards\n        1\n\n        ```\n    \"\"\"\n    if self.compressed_files and not self.extract_path.exists():\n        console.print(\n            \"Compressed files not yet extracted. Try `extract_compression()`.\"\n        )\n    else:\n        i: int = 0\n        pk: int\n        if self._uncompressed_source_file_dict:\n            for i, uncompressed_tuple in enumerate(\n                tqdm(\n                    self._uncompressed_source_file_dict.items(),\n                    desc=\"Compressed configs  :\",\n                    total=len(self._uncompressed_source_file_dict),\n                )\n            ):\n                pk = i + self.initial_pk  # Most `SQL` `pk` begins at 1\n                self._pk_plaintext_dict[uncompressed_tuple[0]] = pk\n                yield FullTextPathDict(\n                    text_path=uncompressed_tuple[0],\n                    text_compressed_path=uncompressed_tuple[1],\n                    primary_key=pk,\n                )\n        if self.plaintext_provided_uncompressed:\n            for j, path in enumerate(\n                tqdm(\n                    self.plaintext_provided_uncompressed,\n                    desc=\"Uncompressed configs:\",\n                    total=len(self.plaintext_provided_uncompressed),\n                )\n            ):\n                pk = j + i + self.initial_pk\n                self._pk_plaintext_dict[path] = pk\n                yield FullTextPathDict(\n                    path=path, compressed_path=None, primary_key=pk\n                )\n</code></pre>"},{"location":"reference/alto2txt2fixture/plaintext.html#alto2txt2fixture.plaintext.PlainTextFixture.plaintext_paths_to_dicts","title":"plaintext_paths_to_dicts","text":"<pre><code>plaintext_paths_to_dicts(\n    convert_to_relative_paths: bool = True,\n    infer_item_code_from_path: bool = True,\n) -&gt; Generator[PlainTextFixtureDict, None, None]\n</code></pre> <p>Generate fixture dicts from <code>self.plaintext_paths</code>.</p> Note <p>For errors running on windows see: #55</p> Example <pre><code>&gt;&gt;&gt; if is_platform_win:\n...     pytest.skip('decompression fails on Windows: issue #55')\n&gt;&gt;&gt; logger_initial_level: int = logger.level\n&gt;&gt;&gt; logger.setLevel(DEBUG)\n&gt;&gt;&gt; plaintext_bl_lwm = getfixture('bl_lwm_plaintext_extracted')\n&lt;BLANKLINE&gt;\n...Extract path:...bl_lwm...extracted...\n&gt;&gt;&gt; paths_dict = list(plaintext_bl_lwm.plaintext_paths_to_dicts())\nCompressed configs  :...%...[ ... it/s ]\n&gt;&gt;&gt; plaintext_bl_lwm.delete_decompressed()\nDeleting all files in: '...tracted'\n&gt;&gt;&gt; logger.setLevel(logger_initial_level)\n</code></pre> Source code in <code>alto2txt2fixture/plaintext.py</code> <pre><code>def plaintext_paths_to_dicts(\n    self,\n    convert_to_relative_paths: bool = True,\n    infer_item_code_from_path: bool = True,\n) -&gt; Generator[PlainTextFixtureDict, None, None]:\n    \"\"\"Generate fixture dicts from `self.plaintext_paths`.\n\n    Note:\n        For errors running on windows see:\n        [#55](https://github.com/Living-with-machines/alto2txt2fixture/issues/55)\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; if is_platform_win:\n        ...     pytest.skip('decompression fails on Windows: issue #55')\n        &gt;&gt;&gt; logger_initial_level: int = logger.level\n        &gt;&gt;&gt; logger.setLevel(DEBUG)\n        &gt;&gt;&gt; plaintext_bl_lwm = getfixture('bl_lwm_plaintext_extracted')\n        &lt;BLANKLINE&gt;\n        ...Extract path:...bl_lwm...extracted...\n        &gt;&gt;&gt; paths_dict = list(plaintext_bl_lwm.plaintext_paths_to_dicts())\n        Compressed configs  :...%...[ ... it/s ]\n        &gt;&gt;&gt; plaintext_bl_lwm.delete_decompressed()\n        Deleting all files in: '...tracted'\n        &gt;&gt;&gt; logger.setLevel(logger_initial_level)\n\n        ```\n    \"\"\"\n    text: str\n    error_str: str | None = None\n    for plaintext_path_dict in self.plaintext_paths():\n        error_str = None\n        try:\n            text = Path(plaintext_path_dict[\"text_path\"]).read_text()\n        except UnicodeDecodeError as err:\n            logger.warning(err)\n            text = \"\"\n            error_str = str(err)\n        path_for_json: str = (\n            str(\n                Path(plaintext_path_dict[\"text_path\"]).relative_to(\n                    self.extract_path\n                )\n            )\n            if convert_to_relative_paths\n            else str(plaintext_path_dict[\"text_path\"])\n        )\n        compressed_path_for_json: str = (\n            str(\n                Path(plaintext_path_dict[\"text_compressed_path\"]).relative_to(\n                    self.path\n                )\n            )\n            if (\n                convert_to_relative_paths\n                and plaintext_path_dict[\"text_compressed_path\"]\n            )\n            else str(plaintext_path_dict[\"text_compressed_path\"])\n        )\n        item_code: str | None = (\n            file_path_to_item_code(Path(path_for_json))\n            if infer_item_code_from_path\n            else None\n        )\n\n        fields: PlainTextFixtureFieldsDict = PlainTextFixtureFieldsDict(\n            text=text,\n            item=None,\n            item_code=item_code,\n            text_path=path_for_json,\n            # text_fixture_path=None,\n            text_compressed_path=compressed_path_for_json,\n            errors=error_str,\n            info=self.fixture_info,\n            canonical=self.is_canonical,\n        )\n        yield PlainTextFixtureDict(\n            model=self.model_str,\n            fields=fields,\n            pk=plaintext_path_dict[\"primary_key\"],\n        )\n</code></pre>"},{"location":"reference/alto2txt2fixture/plaintext.html#alto2txt2fixture.plaintext.PlainTextFixture.set_exported_json_paths","title":"set_exported_json_paths","text":"<pre><code>set_exported_json_paths(\n    export_directory: PathLike | None,\n    saved_fixture_prefix: str | None,\n    overwrite: bool = False,\n) -&gt; None\n</code></pre> <p>Set <code>self._exported_json_paths</code> for use with <code>self.exported_json_paths</code>.</p> Note <p>If provided <code>export_directory</code> and <code>saved_fixture_prefix</code> will overwite those attributes on <code>self.</code></p> <p>Parameters:</p> Name Type Description Default <code>export_directory</code> <code>PathLike | None</code> <p><code>Path</code> to check for saved <code>json</code> files.</p> required <code>saved_fixture_prefix</code> <code>str | None</code> <p><code>str</code> to prefix each exported <code>json</code> file with.</p> required <code>overwrite</code> <code>bool</code> <p>Force replace <code>self._exported_json_paths</code> if already set.</p> <code>False</code> Example <pre><code>&gt;&gt;&gt; if is_platform_win:\n...     pytest.skip('decompression fails on Windows: issue #55')\n&gt;&gt;&gt; tmp_path = getfixture('tmp_path')\n&gt;&gt;&gt; plaintext_bl_lwm = getfixture('bl_lwm_plaintext_json_export')\n&lt;BLANKLINE&gt;\n...\n&gt;&gt;&gt; tuple(plaintext_bl_lwm.exported_json_paths)\n(...Path('...plaintext_fixture-000001.json'),)\n&gt;&gt;&gt; plaintext_bl_lwm.set_exported_json_paths(tmp_path, 'check-prefix')\nTraceback (most recent call last):\n    ...\nValueError: Cannot overwrite 'self._exported_json_paths' without\n'overwrite' = True. Current 'self._exported_json_paths':\n(...Path('...plaintext_fixture-000001.json'),)\n&gt;&gt;&gt; logger_initial_level: int = logger.level\n&gt;&gt;&gt; logger.setLevel(DEBUG)\n&gt;&gt;&gt; plaintext_bl_lwm.set_exported_json_paths(tmp_path,\n...     'check-prefix', overwrite=True)\n&lt;BLANKLINE&gt;\n...Force change '._exported_json_paths' in...&lt;PlainTextFixture...\n&gt;&gt;&gt; plaintext_bl_lwm.export_directory == tmp_path\nTrue\n&gt;&gt;&gt; plaintext_bl_lwm.saved_fixture_prefix\n'check-prefix'\n&gt;&gt;&gt; logger.setLevel(logger_initial_level)\n</code></pre> Source code in <code>alto2txt2fixture/plaintext.py</code> <pre><code>def set_exported_json_paths(\n    self,\n    export_directory: PathLike | None,\n    saved_fixture_prefix: str | None,\n    overwrite: bool = False,\n) -&gt; None:\n    \"\"\"Set `self._exported_json_paths` for use with `self.exported_json_paths`.\n\n    Note:\n        If provided `export_directory` and `saved_fixture_prefix` will\n        overwite those attributes on `self.`\n\n    Params:\n        export_directory:\n            `Path` to check for saved `json` files.\n        saved_fixture_prefix:\n            `str` to prefix each exported `json` file with.\n        overwrite:\n            Force replace `self._exported_json_paths` if already set.\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; if is_platform_win:\n        ...     pytest.skip('decompression fails on Windows: issue #55')\n        &gt;&gt;&gt; tmp_path = getfixture('tmp_path')\n        &gt;&gt;&gt; plaintext_bl_lwm = getfixture('bl_lwm_plaintext_json_export')\n        &lt;BLANKLINE&gt;\n        ...\n        &gt;&gt;&gt; tuple(plaintext_bl_lwm.exported_json_paths)\n        (...Path('...plaintext_fixture-000001.json'),)\n        &gt;&gt;&gt; plaintext_bl_lwm.set_exported_json_paths(tmp_path, 'check-prefix')\n        Traceback (most recent call last):\n            ...\n        ValueError: Cannot overwrite 'self._exported_json_paths' without\n        'overwrite' = True. Current 'self._exported_json_paths':\n        (...Path('...plaintext_fixture-000001.json'),)\n        &gt;&gt;&gt; logger_initial_level: int = logger.level\n        &gt;&gt;&gt; logger.setLevel(DEBUG)\n        &gt;&gt;&gt; plaintext_bl_lwm.set_exported_json_paths(tmp_path,\n        ...     'check-prefix', overwrite=True)\n        &lt;BLANKLINE&gt;\n        ...Force change '._exported_json_paths' in...&lt;PlainTextFixture...\n        &gt;&gt;&gt; plaintext_bl_lwm.export_directory == tmp_path\n        True\n        &gt;&gt;&gt; plaintext_bl_lwm.saved_fixture_prefix\n        'check-prefix'\n        &gt;&gt;&gt; logger.setLevel(logger_initial_level)\n\n        ```\n    \"\"\"\n    if hasattr(self, \"_exported_json_paths\"):\n        if overwrite:\n            logger.info(f\"Force change '._exported_json_paths' in {repr(self)}\")\n        else:\n            raise ValueError(\n                f\"Cannot overwrite 'self._exported_json_paths' without \"\n                f\"'overwrite' = True. Current 'self._exported_json_paths':\\n \"\n                f\"{pformat(self._exported_json_paths)}\"\n            )\n    self.export_directory = (\n        export_directory if export_directory else self.export_directory\n    )\n    self.saved_fixture_prefix = (\n        saved_fixture_prefix if saved_fixture_prefix else self.saved_fixture_prefix\n    )\n    self._exported_json_paths = path_globs_to_tuple(\n        self.export_directory, f\"**/{self.saved_fixture_prefix}*.json\"\n    )\n</code></pre>"},{"location":"reference/alto2txt2fixture/router.html","title":"router","text":""},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Archive","title":"Archive","text":"<pre><code>Archive(\n    path: str | Path,\n    collection: str = \"\",\n    report_id: str | None = None,\n    jisc_papers: DataFrame | None = None,\n    json_indent: int = JSON_INDENT,\n)\n</code></pre> <p>Manage extracting information from a ZIP archive.</p> <p>The <code>Archive</code> class represents a zip archive of XML files. The class is used to extract information from a ZIP archive, and it contains several methods to process the data contained in the archive.</p> <p><code>open(Archive)</code> context manager</p> <p>Archive can be opened with a context manager, which creates a meta object, with timings for the object. When closed, it will save the meta JSON to the correct paths.</p> <p>Attributes:</p> Name Type Description <code>path</code> <code>Path</code> <p>The path to the zip archive.</p> <code>collection</code> <code>str</code> <p>The collection of the XML files in the archive. Default is \"\".</p> <code>report</code> <code>Path</code> <p>The file path of the report file for the archive.</p> <code>report_id</code> <code>str</code> <p>The report ID for the archive. If not provided, a random UUID is generated.</p> <code>report_parent</code> <code>Path</code> <p>The parent directory of the report file for the archive.</p> <code>jisc_papers</code> <code>DataFrame</code> <p>A DataFrame of JISC papers.</p> <code>size</code> <code>str | float</code> <p>The size of the archive, in human-readable format.</p> <code>size_raw</code> <code>str | float</code> <p>The raw size of the archive, in bytes.</p> <code>roots</code> <code>Generator[Element, None, None]</code> <p>The root elements of the XML documents contained in the archive.</p> <code>meta</code> <code>dotdict</code> <p>Metadata about the archive, such as its path, size, and number of contents.</p> <code>json_indent</code> <code>int</code> <p>Indentation formatting of <code>json</code> output</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the <code>path</code> does not exist.</p> <p>Constructor method.</p> Source code in <code>alto2txt2fixture/router.py</code> <pre><code>def __init__(\n    self,\n    path: str | Path,\n    collection: str = \"\",\n    report_id: str | None = None,\n    jisc_papers: pd.DataFrame | None = None,\n    json_indent: int = JSON_INDENT,\n):\n    \"\"\"Constructor method.\"\"\"\n\n    self.path: Path = Path(path)\n\n    if not self.path.exists():\n        raise RuntimeError(\"Path does not exist.\")\n\n    self.size: str | float = get_size_from_path(self.path)\n    self.size_raw: str | float = get_size_from_path(self.path, raw=True)\n    self.zip_file: zipfile.ZipFile = zipfile.ZipFile(self.path)\n    self.collection: str = collection\n    self.roots: Generator[ET.Element, None, None] = self.get_roots()\n\n    self.meta: dotdict = dotdict(\n        path=str(self.path),\n        bytes=self.size_raw,\n        size=self.size,\n        contents=len(self.filelist),\n    )\n\n    if not report_id:\n        self.report_id: str = str(uuid.uuid4())\n    else:\n        self.report_id = report_id\n\n    self.jisc_papers: pd.DataFrame = jisc_papers\n    self.report_parent: Path = Path(f\"{REPORT_DIR}/{self.report_id}\")\n    self.report: Path = (\n        self.report_parent / f\"{self.path.stem.replace('_metadata', '')}.json\"\n    )\n    self.json_indent: int = json_indent\n</code></pre>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Archive.documents","title":"documents  <code>property</code>","text":"<pre><code>documents\n</code></pre> <p>Property that calls the <code>get_documents</code> method</p>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Archive.filelist","title":"filelist  <code>property</code>","text":"<pre><code>filelist\n</code></pre> <p>Returns the list of files in the zip file</p>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Archive.__len__","title":"__len__","text":"<pre><code>__len__()\n</code></pre> <p>The number of files inside the zip archive.</p> Source code in <code>alto2txt2fixture/router.py</code> <pre><code>def __len__(self):\n    \"\"\"The number of files inside the zip archive.\"\"\"\n    return len(self.filelist)\n</code></pre>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Archive.get_documents","title":"get_documents","text":"<pre><code>get_documents() -&gt; Generator[Document, None, None]\n</code></pre> <p>A generator that yields instances of the Document class for each XML file in the ZIP archive.</p> <p>It uses the <code>tqdm</code> library to display a progress bar in the terminal while it is running.</p> <p>If the contents of the ZIP file are not empty, the method creates an instance of the <code>Document</code> class by passing the root element of the XML file, the collection name, meta information about the archive, and the JISC papers data frame (if provided) to the constructor of the <code>Document</code> class. The instance of the <code>Document</code> class is then returned by the generator.</p> <p>Yields:</p> Type Description <code>Document</code> <p><code>Document</code> class instance for each unzipped <code>XML</code> file.</p> Source code in <code>alto2txt2fixture/router.py</code> <pre><code>def get_documents(self) -&gt; Generator[Document, None, None]:\n    \"\"\"\n    A generator that yields instances of the Document class for each XML\n    file in the ZIP archive.\n\n    It uses the `tqdm` library to display a progress bar in the terminal\n    while it is running.\n\n    If the contents of the ZIP file are not empty, the method creates an\n    instance of the ``Document`` class by passing the root element of the XML\n    file, the collection name, meta information about the archive, and the\n    JISC papers data frame (if provided) to the constructor of the\n    ``Document`` class. The instance of the ``Document`` class is then\n    returned by the generator.\n\n    Yields:\n        ``Document`` class instance for each unzipped `XML` file.\n    \"\"\"\n    for xml_file in tqdm(\n        self.filelist,\n        desc=f\"{Path(self.zip_file.filename).stem} ({self.meta.size})\",\n        leave=False,\n        colour=\"green\",\n    ):\n        with self.zip_file.open(xml_file) as f:\n            xml = f.read()\n            if xml:\n                yield Document(\n                    root=ET.fromstring(xml),\n                    collection=self.collection,\n                    meta=self.meta,\n                    jisc_papers=self.jisc_papers,\n                )\n</code></pre>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Archive.get_roots","title":"get_roots","text":"<pre><code>get_roots() -&gt; Generator[Element, None, None]\n</code></pre> <p>Yields the root elements of the XML documents contained in the archive.</p> Source code in <code>alto2txt2fixture/router.py</code> <pre><code>def get_roots(self) -&gt; Generator[ET.Element, None, None]:\n    \"\"\"\n    Yields the root elements of the XML documents contained in the archive.\n    \"\"\"\n    for xml_file in tqdm(self.filelist, leave=False, colour=\"blue\"):\n        with self.zip_file.open(xml_file) as f:\n            xml = f.read()\n            if xml:\n                yield ET.fromstring(xml)\n</code></pre>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Cache","title":"Cache","text":"<pre><code>Cache()\n</code></pre> <p>The Cache class provides a blueprint for creating and managing cache data. The class has several methods that help in getting the cache path, converting the data to a dictionary, and writing the cache data to a file.</p> <p>It is inherited by many other classes in this document.</p> <p>Initializes the Cache class object.</p> Source code in <code>alto2txt2fixture/router.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Initializes the Cache class object.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Cache.__str__","title":"__str__","text":"<pre><code>__str__() -&gt; str\n</code></pre> <p>Returns the string representation of the cache data as a dictionary.</p> Source code in <code>alto2txt2fixture/router.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"\n    Returns the string representation of the cache data as a dictionary.\n    \"\"\"\n    return str(self.as_dict())\n</code></pre>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Cache.as_dict","title":"as_dict","text":"<pre><code>as_dict() -&gt; dict\n</code></pre> <p>Converts the cache data to a dictionary and returns it.</p> Source code in <code>alto2txt2fixture/router.py</code> <pre><code>def as_dict(self) -&gt; dict:\n    \"\"\"\n    Converts the cache data to a dictionary and returns it.\n    \"\"\"\n    return {}\n</code></pre>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Cache.get_cache_path","title":"get_cache_path","text":"<pre><code>get_cache_path() -&gt; Path\n</code></pre> <p>Returns the cache path, which is used to store the cache data. The path is normally constructed using some of the object's properties (collection, kind, and id) but can be changed when inherited.</p> Source code in <code>alto2txt2fixture/router.py</code> <pre><code>def get_cache_path(self) -&gt; Path:\n    \"\"\"\n    Returns the cache path, which is used to store the cache data.\n    The path is normally constructed using some of the object's\n    properties (collection, kind, and id) but can be changed when\n    inherited.\n    \"\"\"\n    return Path(f\"{CACHE_HOME}/{self.collection}/{self.kind}/{self.id}.json\")\n</code></pre>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Cache.write_to_cache","title":"write_to_cache","text":"<pre><code>write_to_cache(json_indent: int = JSON_INDENT) -&gt; Optional[bool]\n</code></pre> <p>Writes the cache data to a file at the specified cache path. The cache data is first converted to a dictionary using the as_dict method. If the cache path already exists, the function returns True.</p> Source code in <code>alto2txt2fixture/router.py</code> <pre><code>def write_to_cache(self, json_indent: int = JSON_INDENT) -&gt; Optional[bool]:\n    \"\"\"\n    Writes the cache data to a file at the specified cache path. The cache\n    data is first converted to a dictionary using the as_dict method. If\n    the cache path already exists, the function returns True.\n    \"\"\"\n\n    path = self.get_cache_path()\n\n    try:\n        if path.exists():\n            return True\n    except AttributeError:\n        error(\n            f\"Error occurred when getting cache path for \"\n            f\"{self.kind}: {path}. It was not of expected \"\n            f\"type Path but of type {type(path)}:\",\n        )\n\n    path.parent.mkdir(parents=True, exist_ok=True)\n\n    with open(path, \"w+\") as f:\n        f.write(json.dumps(self.as_dict(), indent=json_indent))\n\n    return\n</code></pre>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Collection","title":"Collection","text":"<pre><code>Collection(name: str = 'hmd', jisc_papers: Optional[DataFrame] = None)\n</code></pre> <p>A Collection represents a group of newspaper archives from any passed alto2txt metadata output.</p> <p>A Collection is initialised with a name and an optional pandas DataFrame of JISC papers. The <code>archives</code> property returns an iterable of the <code>Archive</code> objects within the collection.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the collection (default \"hmd\")</p> <code>jisc_papers</code> <code>DataFrame</code> <p>DataFrame of JISC papers, optional</p> <p>Constructor method.</p> Source code in <code>alto2txt2fixture/router.py</code> <pre><code>def __init__(self, name: str = \"hmd\", jisc_papers: Optional[pd.DataFrame] = None):\n    \"\"\"Constructor method.\"\"\"\n\n    self.name: str = name\n    self.jisc_papers: pd.DataFrame | None = jisc_papers\n    self.dir: Path = Path(f\"{MNT}/{self.name}-alto2txt/metadata\")\n    self.zip_files: list[Path] = sorted(\n        list(self.dir.glob(\"*.zip\")), key=lambda x: x.stat().st_size\n    )\n    self.zip_file_count: int = sum([1 for _ in self.dir.glob(\"*.zip\")])\n    self.report_id: str = str(uuid.uuid4())\n    self.empty: bool = self.zip_file_count == 0\n</code></pre>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.DataProvider","title":"DataProvider","text":"<pre><code>DataProvider(collection: str)\n</code></pre> <p>             Bases: <code>Cache</code></p> <p>The DataProvider class extends the Cache class and represents a newspaper data provider. The class has several properties and methods that allow creation of a data provider object and the manipulation of its data.</p> <p>Attributes:</p> Name Type Description <code>collection</code> <code>str</code> <p>A string representing publication collection</p> <code>kind</code> <code>str</code> <p>Indication of object type, defaults to <code>data-provider</code></p> <code>providers_meta_data</code> <code>list[FixtureDict]</code> <p>structured dict of metadata for known collection sources</p> <code>collection_type</code> <code>str</code> <p>related data sources and potential linkage source</p> <code>index_field</code> <code>str</code> <p>field name for querying existing records</p> Example <pre><code>&gt;&gt;&gt; hmd = DataProvider(\"hmd\")\n&gt;&gt;&gt; hmd.pk\n2\n&gt;&gt;&gt; pprint(hmd.as_dict())\n{'code': 'bl-hmd',\n 'collection': 'newspapers',\n 'legacy_code': 'hmd',\n 'name': 'Heritage Made Digital',\n 'source_note': 'British Library-funded digitised newspapers provided by the '\n                'British Newspaper Archive'}\n</code></pre> <p>Constructor method.</p> Source code in <code>alto2txt2fixture/router.py</code> <pre><code>def __init__(self, collection: str):\n    \"\"\"Constructor method.\"\"\"\n    self.collection: str = collection\n</code></pre>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.DataProvider.meta_data","title":"meta_data  <code>property</code>","text":"<pre><code>meta_data: FixtureDict | dict\n</code></pre> <p>Return <code>self.providers_meta_data[self.collection]</code> or <code>{}</code>.</p>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.DataProvider.meta_data_fields","title":"meta_data_fields  <code>property</code>","text":"<pre><code>meta_data_fields: FixtureDict | dict\n</code></pre> <p>Return <code>self.providers_meta_data[self.collection]</code> or <code>{}</code>.</p>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.DataProvider.pk","title":"pk  <code>property</code>","text":"<pre><code>pk: int | None\n</code></pre> <p>Return <code>pk</code> if provided via <code>providers_meta_data</code>, else <code>None</code>.</p>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.DataProvider.providers_index_dict","title":"providers_index_dict  <code>property</code>","text":"<pre><code>providers_index_dict: dict[str, FixtureDict]\n</code></pre> <p>Return all <code>self.index_field</code> values from <code>providers_meta_data</code>.</p>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.DataProvider.as_dict","title":"as_dict","text":"<pre><code>as_dict() -&gt; dict\n</code></pre> <p>Return a <code>dict</code> of the data provider object.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary representation of the DataProvider object</p> Source code in <code>alto2txt2fixture/router.py</code> <pre><code>def as_dict(self) -&gt; dict:\n    \"\"\"\n    Return a `dict` of the data provider object.\n\n    Returns:\n        Dictionary representation of the DataProvider object\n    \"\"\"\n    if self.meta_data:\n        return {\n            \"name\": self.meta_data_fields[\"name\"],\n            \"code\": self.meta_data_fields[\"code\"],\n            \"legacy_code\": self.collection,\n            \"source_note\": self.meta_data_fields[\"source_note\"],\n            \"collection\": self.collection_type,\n        }\n    else:\n        return {\n            \"name\": self.collection,\n            \"code\": slugify(self.collection),\n            \"source_note\": \"\",\n            \"legacy_code\": None,\n            \"collection\": self.collection_type,\n        }\n</code></pre>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Digitisation","title":"Digitisation","text":"<pre><code>Digitisation(root: Element, collection: str = '')\n</code></pre> <p>             Bases: <code>Cache</code></p> <p>The Digitisation class extends the Cache class and represents a newspaper digitisation. The class has several properties and methods that allow creation of an digitisation object and the manipulation of its data.</p> <p>Attributes:</p> Name Type Description <code>root</code> <code>Element</code> <p>An xml element that represents the root of the publication</p> <code>collection</code> <code>str</code> <p>A string that represents the collection of the publication</p> <p>Constructor method.</p> Source code in <code>alto2txt2fixture/router.py</code> <pre><code>def __init__(self, root: ET.Element, collection: str = \"\"):\n    \"\"\"Constructor method.\"\"\"\n\n    if not isinstance(root, ET.Element):\n        raise RuntimeError(f\"Expected root to be xml.etree.Element: {type(root)}\")\n\n    self.root: ET.Element = root\n    self.collection: str = collection\n</code></pre>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Digitisation.kind","title":"kind  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>kind = 'digitisation'\n</code></pre> <p>A string that represents the type of the object, set to \"digitisation\".</p>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Digitisation.as_dict","title":"as_dict","text":"<pre><code>as_dict() -&gt; dict\n</code></pre> <p>A method that returns a dictionary representation of the digitisation object.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary representation of the Digitising object</p> Source code in <code>alto2txt2fixture/router.py</code> <pre><code>def as_dict(self) -&gt; dict:\n    \"\"\"\n    A method that returns a dictionary representation of the digitisation\n    object.\n\n    Returns:\n        Dictionary representation of the Digitising object\n    \"\"\"\n    dic = {\n        x.tag: x.text or \"\"\n        for x in self.root.findall(\"./process/*\")\n        if x.tag\n        in [\n            \"xml_flavour\",\n            \"software\",\n            \"mets_namespace\",\n            \"alto_namespace\",\n        ]\n    }\n    if not dic.get(\"software\"):\n        return {}\n\n    return dic\n</code></pre>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Document","title":"Document","text":"<pre><code>Document(*args, **kwargs)\n</code></pre> <p>The Document class is a representation of a document that contains information about a publication, newspaper, item, digitisation, and ingest. This class holds all the relevant information about a document in a structured manner and provides properties that can be used to access different aspects of the document.</p> <p>Attributes:</p> Name Type Description <code>collection</code> <code>str | None</code> <p>A string that represents the collection of the publication</p> <code>root</code> <code>Element | None</code> <p>An <code>XML</code> element that represents the root of the publication</p> <code>zip_file</code> <code>str | None</code> <p>A path to a valid <code>zip</code> file</p> <code>jisc_papers</code> <code>DataFrame | None</code> <p>A <code>pandas</code> <code>DataFrame</code> object that holds information about the JISC papers</p> <code>meta</code> <code>dotdict | None</code> <p>TODO</p> <p>Constructor method.</p> Source code in <code>alto2txt2fixture/router.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"Constructor method.\"\"\"\n\n    self.collection: str | None = kwargs.get(\"collection\")\n    if not self.collection or not isinstance(self.collection, str):\n        raise RuntimeError(\"A valid collection must be passed\")\n\n    self.root: ET.Element | None = kwargs.get(\"root\")\n    if not self.root or not isinstance(self.root, ET.Element):\n        raise RuntimeError(\"A valid XML root must be passed\")\n\n    self.zip_file: str | None = kwargs.get(\"zip_file\")\n    if self.zip_file and not isinstance(self.zip_file, str):\n        raise RuntimeError(\"A valid zip file must be passed\")\n\n    self.jisc_papers: pd.DataFrame | None = kwargs.get(\"jisc_papers\")\n    if not isinstance(self.jisc_papers, pd.DataFrame):\n        raise RuntimeError(\n            \"A valid DataFrame containing JISC papers must be passed\"\n        )\n\n    self.meta: dotdict | None = kwargs.get(\"meta\")\n\n    self._publication_elem = None\n    self._input_sub_path = None\n    self._ingest = None\n    self._digitisation = None\n    self._item = None\n    self._issue = None\n    self._newspaper = None\n    self._data_provider = None\n</code></pre>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Document.publication","title":"publication  <code>property</code>","text":"<pre><code>publication: Element\n</code></pre> <p>This property returns an ElementTree object representing the publication information in the XML document.</p>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Ingest","title":"Ingest","text":"<pre><code>Ingest(root: Element, collection: str = '')\n</code></pre> <p>             Bases: <code>Cache</code></p> <p>The Ingest class extends the Cache class and represents a newspaper ingest. The class has several properties and methods that allow the creation of an ingest object and the manipulation of its data.</p> <p>Attributes:</p> Name Type Description <code>root</code> <code>Element</code> <p>An xml element that represents the root of the publication</p> <code>collection</code> <code>str</code> <p>A string that represents the collection of the publication</p> <p>Constructor method.</p> Source code in <code>alto2txt2fixture/router.py</code> <pre><code>def __init__(self, root: ET.Element, collection: str = \"\"):\n    \"\"\"Constructor method.\"\"\"\n\n    if not isinstance(root, ET.Element):\n        raise RuntimeError(f\"Expected root to be xml.etree.Element: {type(root)}\")\n\n    self.root: ET.Element = root\n    self.collection: str = collection\n</code></pre>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Ingest.kind","title":"kind  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>kind = 'ingest'\n</code></pre> <p>A string that represents the type of the object, set to \"ingest\".</p>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Ingest.as_dict","title":"as_dict","text":"<pre><code>as_dict() -&gt; dict\n</code></pre> <p>A method that returns a dictionary representation of the ingest object.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary representation of the Ingest object</p> Source code in <code>alto2txt2fixture/router.py</code> <pre><code>def as_dict(self) -&gt; dict:\n    \"\"\"\n    A method that returns a dictionary representation of the ingest\n    object.\n\n    Returns:\n        Dictionary representation of the Ingest object\n    \"\"\"\n    return {\n        f\"lwm_tool_{x.tag}\": x.text or \"\"\n        for x in self.root.findall(\"./process/lwm_tool/*\")\n    }\n</code></pre>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Issue","title":"Issue","text":"<pre><code>Issue(\n    publication: Element,\n    newspaper: Optional[Newspaper] = None,\n    collection: str = \"\",\n    input_sub_path: str = \"\",\n    meta: dotdict = dotdict(),\n)\n</code></pre> <p>             Bases: <code>Cache</code></p> <p>The Issue class extends the Cache class and represents a newspaper issue. The class has several properties and methods that allow the creation of an issue object and the manipulation of its data.</p> <p>Attributes:</p> Name Type Description <code>root</code> <p>An xml element that represents the root of the publication</p> <code>newspaper</code> <code>Newspaper | None</code> <p>The parent newspaper</p> <code>collection</code> <code>str</code> <p>A string that represents the collection of the publication</p> <code>input_sub_path</code> <code>str</code> <p>TODO</p> <code>meta</code> <code>dotdict</code> <p>TODO</p> <p>Constructor method.</p> Source code in <code>alto2txt2fixture/router.py</code> <pre><code>def __init__(\n    self,\n    publication: ET.Element,\n    newspaper: Optional[Newspaper] = None,\n    collection: str = \"\",\n    input_sub_path: str = \"\",\n    meta: dotdict = dotdict(),\n):\n    \"\"\"Constructor method.\"\"\"\n\n    self.publication: ET.Element = publication\n    self.newspaper: Newspaper | None = newspaper\n    self.collection: str = collection\n    self.input_sub_path: str = input_sub_path\n    self.meta: dotdict = meta\n\n    self._issue = None\n    self._issue_date = None\n\n    path: str = str(self.get_cache_path())\n    if not self.meta.issue_paths:\n        self.meta.issue_paths = [path]\n    elif path not in self.meta.issue_paths:\n        self.meta.issue_paths.append(path)\n</code></pre>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Issue.issue_code","title":"issue_code  <code>property</code>","text":"<pre><code>issue_code: str\n</code></pre> <p>Sets up and saves the issue code for easy access as property.</p>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Issue.issue_date","title":"issue_date  <code>property</code>","text":"<pre><code>issue_date: str\n</code></pre> <p>Sets up and saves the issue date for easy access as property.</p>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Issue.kind","title":"kind  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>kind = 'issue'\n</code></pre> <p>A string that represents the type of the object, set to \"issue\".</p>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Issue.as_dict","title":"as_dict","text":"<pre><code>as_dict() -&gt; dict\n</code></pre> <p>A method that returns a dictionary representation of the issue object.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary representation of the Issue object</p> Source code in <code>alto2txt2fixture/router.py</code> <pre><code>def as_dict(self) -&gt; dict:\n    \"\"\"\n    A method that returns a dictionary representation of the issue\n    object.\n\n    Returns:\n        Dictionary representation of the Issue object\n    \"\"\"\n\n    if not self._issue:\n        self._issue = dict(\n            issue_code=self.issue_code,\n            issue_date=self.issue_date,\n            publication__publication_code=self.newspaper.publication_code,\n            input_sub_path=self.input_sub_path,\n        )\n\n    return self._issue\n</code></pre>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Issue.get_cache_path","title":"get_cache_path","text":"<pre><code>get_cache_path() -&gt; Path\n</code></pre> <p>Returns the path to the cache file for the issue object.</p> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the cache file for the issue object</p> Source code in <code>alto2txt2fixture/router.py</code> <pre><code>def get_cache_path(self) -&gt; Path:\n    \"\"\"\n    Returns the path to the cache file for the issue object.\n\n    Returns:\n        Path to the cache file for the issue object\n    \"\"\"\n\n    json_file = f\"/{self.newspaper.publication_code}/issues/{self.issue_code}.json\"\n\n    return Path(\n        f\"{CACHE_HOME}/{self.collection}/\"\n        + \"/\".join(self.newspaper.number_paths)\n        + json_file\n    )\n</code></pre>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Item","title":"Item","text":"<pre><code>Item(\n    root: Element,\n    issue_code: str = \"\",\n    digitisation: dict = {},\n    ingest: dict = {},\n    collection: str = \"\",\n    newspaper: Optional[Newspaper] = None,\n    meta: dotdict = dotdict(),\n)\n</code></pre> <p>             Bases: <code>Cache</code></p> <p>The Newspaper class extends the Cache class and represents a newspaper item, i.e. an article. The class has several properties and methods that allow the creation of an article object and the manipulation of its data.</p> <p>Attributes:</p> Name Type Description <code>root</code> <code>Element</code> <p>An xml element that represents the root of the publication</p> <code>issue_code</code> <code>str</code> <p>A string that represents the issue code</p> <code>digitisation</code> <code>dict</code> <p>TODO</p> <code>ingest</code> <code>dict</code> <p>TODO</p> <code>collection</code> <code>str</code> <p>A string that represents the collection of the publication</p> <code>newspaper</code> <code>Newspaper | None</code> <p>The parent newspaper</p> <code>meta</code> <code>dotdict</code> <p>TODO</p> <p>Constructor method.</p> Source code in <code>alto2txt2fixture/router.py</code> <pre><code>def __init__(\n    self,\n    root: ET.Element,\n    issue_code: str = \"\",\n    digitisation: dict = {},\n    ingest: dict = {},\n    collection: str = \"\",\n    newspaper: Optional[Newspaper] = None,\n    meta: dotdict = dotdict(),\n):\n    \"\"\"Constructor method.\"\"\"\n\n    if not isinstance(root, ET.Element):\n        raise RuntimeError(f\"Expected root to be xml.etree.Element: {type(root)}\")\n\n    if not isinstance(newspaper, Newspaper):\n        raise RuntimeError(\"Expected newspaper to be of type router.Newspaper\")\n\n    self.root: ET.Element = root\n    self.issue_code: str = issue_code\n    self.digitisation: dict = digitisation\n    self.ingest: dict = ingest\n    self.collection: str = collection\n    self.newspaper: Newspaper | None = newspaper\n    self.meta: dotdict = meta\n\n    self._item_elem = None\n    self._item_code = None\n    self._item = None\n\n    path: str = str(self.get_cache_path())\n    if not self.meta.item_paths:\n        self.meta.item_paths = [path]\n    elif path not in self.meta.item_paths:\n        self.meta.item_paths.append(path)\n</code></pre>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Item.item_code","title":"item_code  <code>property</code>","text":"<pre><code>item_code: str\n</code></pre> <p>Sets up and saves the item code for easy access as property.</p>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Item.item_elem","title":"item_elem  <code>property</code>","text":"<pre><code>item_elem\n</code></pre> <p>Sets up and saves the issue XML item for easy access as a property.</p>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Item.kind","title":"kind  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>kind = 'item'\n</code></pre> <p>A string that represents the type of the object, set to \"item\".</p>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Item.as_dict","title":"as_dict","text":"<pre><code>as_dict() -&gt; dict\n</code></pre> <p>A method that returns a dictionary representation of the item object (i.e. article).</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary representation of the Item object</p> Source code in <code>alto2txt2fixture/router.py</code> <pre><code>def as_dict(self) -&gt; dict:\n    \"\"\"\n    A method that returns a dictionary representation of the item object\n    (i.e. article).\n\n    Returns:\n        Dictionary representation of the Item object\n    \"\"\"\n\n    if not self._item:\n        self._item = {\n            f\"{x.tag}\": x.text or \"\"\n            for x in self.item_elem.findall(\"*\")\n            if x.tag\n            in [\n                \"title\",\n                \"word_count\",\n                \"ocr_quality_mean\",\n                \"ocr_quality_sd\",\n                \"plain_text_file\",\n                \"item_type\",\n            ]\n        }\n\n        self._item[\"title\"] = self._item.get(\"title\", \"\")[:2097151]\n\n        self._item = {\n            \"item_code\": self.item_code,\n            \"word_count\": self._item.get(\"word_count\", 0),\n            \"title\": self._item.get(\"title\"),\n            \"item_type\": self._item.get(\"item_type\"),\n            \"input_filename\": self._item.get(\"plain_text_file\", \"\"),\n            \"ocr_quality_mean\": self._item.get(\"ocr_quality_mean\", 0),\n            \"ocr_quality_sd\": self._item.get(\"ocr_quality_sd\", 0),\n            \"digitisation__software\": self.digitisation.id,\n            \"ingest__lwm_tool_identifier\": self.ingest.id,\n            \"issue__issue_identifier\": self.issue_code,\n            \"data_provider__name\": self.collection,\n        }\n\n    return self._item\n</code></pre>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Item.get_cache_path","title":"get_cache_path","text":"<pre><code>get_cache_path() -&gt; Path\n</code></pre> <p>Returns the path to the cache file for the item (article) object.</p> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the cache file for the article object</p> Source code in <code>alto2txt2fixture/router.py</code> <pre><code>def get_cache_path(self) -&gt; Path:\n    \"\"\"\n    Returns the path to the cache file for the item (article) object.\n\n    Returns:\n        Path to the cache file for the article object\n    \"\"\"\n    return Path(\n        f\"{CACHE_HOME}/{self.collection}/\"\n        + \"/\".join(self.newspaper.number_paths)\n        + f\"/{self.newspaper.publication_code}/items.jsonl\"\n    )\n</code></pre>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Item.write_to_cache","title":"write_to_cache","text":"<pre><code>write_to_cache(json_indent=JSON_INDENT) -&gt; None\n</code></pre> <p>Special cache-write function that appends rather than writes at the end of the process.</p> <p>Returns:</p> Type Description <code>None</code> <p>None.</p> Source code in <code>alto2txt2fixture/router.py</code> <pre><code>def write_to_cache(self, json_indent=JSON_INDENT) -&gt; None:\n    \"\"\"\n    Special cache-write function that appends rather than writes at the\n    end of the process.\n\n    Returns:\n        None.\n    \"\"\"\n    path = self.get_cache_path()\n\n    path.parent.mkdir(parents=True, exist_ok=True)\n\n    with open(path, \"a+\") as f:\n        f.write(json.dumps(self.as_dict(), indent=json_indent) + \"\\n\")\n\n    return\n</code></pre>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Newspaper","title":"Newspaper","text":"<pre><code>Newspaper(\n    root: Element,\n    collection: str = \"\",\n    meta: dotdict = dotdict(),\n    jisc_papers: Optional[DataFrame] = None,\n)\n</code></pre> <p>             Bases: <code>Cache</code></p> <p>The Newspaper class extends the Cache class and represents a newspaper.</p> <p>The class has several properties and methods that allow the creation of a newspaper object and the manipulation of its data.</p> <p>Attributes:</p> Name Type Description <code>root</code> <p>An xml element that represents the root of the publication.</p> <code>collection</code> <p>A string that represents the collection of the publication.</p> <code>meta</code> <p>A dotdict object that holds metadata about the publication.</p> <code>jisc_papers</code> <p>A pandas DataFrame object for JISC paper information.</p> <p>Constructor method.</p> Source code in <code>alto2txt2fixture/router.py</code> <pre><code>def __init__(\n    self,\n    root: ET.Element,\n    collection: str = \"\",\n    meta: dotdict = dotdict(),\n    jisc_papers: Optional[pd.DataFrame] = None,\n):\n    \"\"\"Constructor method.\"\"\"\n\n    if not isinstance(root, ET.Element):\n        raise RuntimeError(f\"Expected root to be xml.etree.Element: {type(root)}\")\n\n    self.publication = root.find(\"./publication\")\n    self.input_sub_path = root.find(\"./process/input_sub_path\").text\n    self.issue_date = self.publication.find(\"./issue/date\").text\n    self.collection = collection\n    self.meta = meta\n    self.jisc_papers = jisc_papers\n\n    self._newspaper = None\n    self._title = None\n    self._publication_code = None\n\n    path = str(self.get_cache_path())\n    if not self.meta.newspaper_paths:\n        self.meta.newspaper_paths = []\n    elif path not in self.meta.newspaper_paths:\n        self.meta.newspaper_paths.append(path)\n\n    if not self.meta.publication_codes:\n        self.meta.publication_codes = [self.publication_code]\n    elif self.publication_code not in self.meta.publication_codes:\n        self.meta.publication_codes.append(self.publication_code)\n\n    self.zip_file = Path(meta.path).name\n</code></pre>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Newspaper.kind","title":"kind  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>kind = 'newspaper'\n</code></pre> <p>A string that represents the type of the object, set to \"newspaper\".</p>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Newspaper.number_paths","title":"number_paths  <code>property</code>","text":"<pre><code>number_paths: list\n</code></pre> <p>Returns the nested directories in which we want to save the cache file.</p> <p>Returns:</p> Type Description <code>list</code> <p>List of the desired directories in descending order</p>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Newspaper.publication_code","title":"publication_code  <code>property</code>","text":"<pre><code>publication_code: str\n</code></pre> <p>A property that returns the code of the publication.</p> <p>Returns:</p> Type Description <code>str</code> <p>The code of the publication</p>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Newspaper.title","title":"title  <code>property</code>","text":"<pre><code>title: str\n</code></pre> <p>A property that returns the title of the newspaper.</p> <p>Returns:</p> Type Description <code>str</code> <p>The title of the newspaper</p>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Newspaper.as_dict","title":"as_dict","text":"<pre><code>as_dict() -&gt; dict\n</code></pre> <p>A method that returns a dictionary representation of the newspaper object.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary representation of the Newspaper object</p> Source code in <code>alto2txt2fixture/router.py</code> <pre><code>def as_dict(self) -&gt; dict:\n    \"\"\"\n    A method that returns a dictionary representation of the newspaper\n    object.\n\n    Returns:\n        Dictionary representation of the Newspaper object\n    \"\"\"\n\n    if not self._newspaper:\n        self._newspaper = dict(\n            **dict(publication_code=self.publication_code, title=self.title),\n            **{\n                x.tag: x.text or \"\"\n                for x in self.publication.findall(\"*\")\n                if x.tag in [\"location\"]\n            },\n        )\n    return self._newspaper\n</code></pre>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Newspaper.get_cache_path","title":"get_cache_path","text":"<pre><code>get_cache_path() -&gt; Path\n</code></pre> <p>Returns the path to the cache file for the newspaper object.</p> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the cache file for the newspaper object</p> Source code in <code>alto2txt2fixture/router.py</code> <pre><code>def get_cache_path(self) -&gt; Path:\n    \"\"\"\n    Returns the path to the cache file for the newspaper object.\n\n    Returns:\n        Path to the cache file for the newspaper object\n    \"\"\"\n    json_file = f\"/{self.publication_code}/{self.publication_code}.json\"\n\n    return Path(\n        f\"{CACHE_HOME}/{self.collection}/\" + \"/\".join(self.number_paths) + json_file\n    )\n</code></pre>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.Newspaper.publication_code_from_input_sub_path","title":"publication_code_from_input_sub_path","text":"<pre><code>publication_code_from_input_sub_path() -&gt; str | None\n</code></pre> <p>A method that returns the publication code from the input sub-path of the publication process.</p> <p>Returns:</p> Type Description <code>str | None</code> <p>The code of the publication</p> Source code in <code>alto2txt2fixture/router.py</code> <pre><code>def publication_code_from_input_sub_path(self) -&gt; str | None:\n    \"\"\"\n    A method that returns the publication code from the input sub-path of\n    the publication process.\n\n    Returns:\n        The code of the publication\n    \"\"\"\n\n    g = PUBLICATION_CODE.findall(self.input_sub_path)\n    if len(g) == 1:\n        return g[0]\n    return None\n</code></pre>"},{"location":"reference/alto2txt2fixture/router.html#alto2txt2fixture.router.route","title":"route","text":"<pre><code>route(\n    collections: list,\n    cache_home: str,\n    mountpoint: str,\n    jisc_papers_path: str,\n    report_dir: str,\n) -&gt; None\n</code></pre> <p>This function is responsible for setting up the path for the alto2txt mountpoint, setting up the JISC papers and routing the collections for processing.</p> <p>Parameters:</p> Name Type Description Default <code>collections</code> <code>list</code> <p>List of collection names</p> required <code>cache_home</code> <code>str</code> <p>Directory path for the cache</p> required <code>mountpoint</code> <code>str</code> <p>Directory path for the alto2txt mountpoint</p> required <code>jisc_papers_path</code> <code>str</code> <p>Path to the JISC papers</p> required <code>report_dir</code> <code>str</code> <p>Path to the report directory</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alto2txt2fixture/router.py</code> <pre><code>def route(\n    collections: list,\n    cache_home: str,\n    mountpoint: str,\n    jisc_papers_path: str,\n    report_dir: str,\n) -&gt; None:\n    \"\"\"\n    This function is responsible for setting up the path for the alto2txt\n    mountpoint, setting up the JISC papers and routing the collections for\n    processing.\n\n    Args:\n        collections: List of collection names\n        cache_home: Directory path for the cache\n        mountpoint: Directory path for the alto2txt mountpoint\n        jisc_papers_path: Path to the JISC papers\n        report_dir: Path to the report directory\n\n    Returns:\n        None\n    \"\"\"\n\n    global CACHE_HOME\n    global MNT\n    global REPORT_DIR\n\n    CACHE_HOME = cache_home\n    REPORT_DIR = report_dir\n\n    MNT = Path(mountpoint) if isinstance(mountpoint, str) else mountpoint\n    if not MNT.exists():\n        error(\n            f\"The mountpoint provided for alto2txt does not exist. \"\n            f\"Either create a local copy or blobfuse it to \"\n            f\"`{MNT.absolute()}`.\"\n        )\n\n    jisc_papers = setup_jisc_papers(path=jisc_papers_path)\n\n    for collection_name in collections:\n        collection = Collection(name=collection_name, jisc_papers=jisc_papers)\n\n        if collection.empty:\n            error(\n                f\"It looks like {collection_name} is empty in the \"\n                f\"alto2txt mountpoint: `{collection.dir.absolute()}`.\"\n            )\n\n        for archive in collection.archives:\n            with archive as _:\n                [\n                    (\n                        doc.item.write_to_cache(),\n                        doc.newspaper.write_to_cache(),\n                        doc.issue.write_to_cache(),\n                        doc.data_provider.write_to_cache(),\n                        doc.ingest.write_to_cache(),\n                        doc.digitisation.write_to_cache(),\n                    )\n                    for doc in archive.documents\n                ]\n\n    return\n</code></pre>"},{"location":"reference/alto2txt2fixture/settings.html","title":"settings","text":"<p>The <code>settings</code> module provides configuration for running <code>alto2txt2fixture</code>.</p> <p>Most of these are managed within the <code>settings</code> variable within this module.</p> <p>Note</p> <p>See the command line interface parameters documentation for means of modifying <code>settings</code> when run.</p> <p>Attributes:</p> Name Type Description <code>JSON_INDEX</code> <p>Amount of indentation to include in output <code>JSON</code> files</p> <code>DATA_PROVIDER_INDEX</code> <code>Final[str]</code> <p>The <code>field</code> used to index <code>DataProvider</code> records</p> <code>NEWSPAPER_COLLECTION_METADATA</code> <code>Final[list[DataProviderFixtureDict]]</code> <p>A list of <code>FixtureDict</code>s specifying speific newspaper data providers</p> <code>SETUP_TITLE</code> <code>str</code> <p>the title printed at the commandline via <code>cli.show_setup()</code> function</p> <code>settings</code> <code>dotdict</code> <p>a <code>docdict</code> configuration for running <code>newspaper</code> portions of <code>alto2txt2fixture</code></p>"},{"location":"reference/alto2txt2fixture/types.html","title":"types","text":""},{"location":"reference/alto2txt2fixture/types.html#alto2txt2fixture.types.DataProviderFieldsDict","title":"DataProviderFieldsDict","text":"<p>             Bases: <code>TypedDict</code></p> <p>Fields within the <code>fields</code> portion of a <code>FixtureDict</code> to fit <code>lwmdb</code>.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of the collection data source. For <code>lwmdb</code> this should be less than 600 characters.</p> <code>code</code> <code>str | NEWSPAPER_OCR_FORMATS</code> <p>A short slug-like, url-compatible (replace spaces with <code>-</code>) <code>str</code> to uniquely identify a data provider in <code>urls</code>, <code>api</code> calls etc. Designed to fit <code>NEWSPAPER_OCR_FORMATS</code> and any future slug-like codes.</p> <code>legacy_code</code> <code>LEGACY_NEWSPAPER_OCR_FORMATS | None</code> <p>Either blank or a legacy slug-like, url-compatible (replace spaces with <code>-</code>) <code>str</code> originally used by <code>alto2txt</code> following <code>LEGACY_NEWSPAPER_OCR_FORMATSNEWSPAPER_OCR_FORMATS</code>.</p> <code>collection</code> <code>str</code> <p>Data Provider type.</p> <code>source_note</code> <code>str | None</code> <p>A sentence about the data provider.</p>"},{"location":"reference/alto2txt2fixture/types.html#alto2txt2fixture.types.DataProviderFixtureDict","title":"DataProviderFixtureDict","text":"<p>             Bases: <code>FixtureDictBaseClass</code></p> <p>A <code>dict</code> structure for <code>DataProvider</code> sources in line with <code>lwmdb</code>.</p> <p>Attributes:</p> Name Type Description <code>pk</code> <code>int</code> <p>an id to uniquely define and query each entry</p> <code>model</code> <code>str</code> <p>what model a given record is for</p> <code>fields</code> <code>DataProviderFieldsDict</code> <p>a <code>DataProviderFieldsDict</code></p>"},{"location":"reference/alto2txt2fixture/types.html#alto2txt2fixture.types.FixtureDict","title":"FixtureDict","text":"<p>             Bases: <code>FixtureDictBaseClass</code></p> <p>A <code>dict</code> structure to ease use as a <code>json</code> database fixture.</p> <p>Attributes:</p> Name Type Description <code>pk</code> <p>an id to uniquely define and query each entry</p> <code>model</code> <p>what model a given record is for</p> <code>fields</code> <code>dict[str, Any]</code> <p>a <code>dict</code> of record information conforming to <code>model</code> table</p>"},{"location":"reference/alto2txt2fixture/types.html#alto2txt2fixture.types.FixtureDictBaseClass","title":"FixtureDictBaseClass","text":"<p>             Bases: <code>TypedDict</code></p> <p>A base <code>dict</code> structure for <code>json</code> fixtures.</p>"},{"location":"reference/alto2txt2fixture/types.html#alto2txt2fixture.types.PlainTextFixtureDict","title":"PlainTextFixtureDict","text":"<p>             Bases: <code>FixtureDictBaseClass</code></p> <p>A <code>dict</code> structure for <code>Fulltext</code> sources in line with <code>lwmdb</code>.</p> <p>Attributes:</p> Name Type Description <code>model</code> <code>str</code> <p><code>str</code> in <code>django</code> fixture spec to indicate what model a record is for</p> <code>fields</code> <code>PlainTextFixtureFieldsDict</code> <p>a <code>PlainTextFixtureFieldsDict</code> <code>dict</code> instance</p> <code>pk</code> <code>int</code> <p><code>int</code> id for fixture record</p> Note <p>No <code>pk</code> is included. By not specifying one, <code>django</code> should generate new onces during import.</p>"},{"location":"reference/alto2txt2fixture/types.html#alto2txt2fixture.types.PlainTextFixtureFieldsDict","title":"PlainTextFixtureFieldsDict","text":"<p>             Bases: <code>TypedDict</code></p> <p>A typed <code>dict</code> for PlainText Fixutres to match <code>lwmdb.newspapers.FullText</code> <code>model</code></p> <p>Attributes:</p> Name Type Description <code>text</code> <code>str</code> <p>PlainText, potentially quite large newspaper articles. May have unusual or unreadable sequences of characters due to issues with Optical Character Recognition quality.</p> <code>item</code> <code>int | None</code> <p>An integer of the ForiengKey to the relate <code>lwmdb.Newspaper.Item</code> record.</p> <code>item_code</code> <code>str | None</code> <p>A unique <code>str</code> to match to <code>lwmdb.Newspaper.Item</code> record.</p> <code>text_path</code> <code>str | None</code> <p>Path of provided plaintext file. If <code>compressed_path</code> is <code>None</code>, this is the original relative <code>Path</code> of the <code>PlainText</code> file.</p> <code>text_compressed_path</code> <code>str | None</code> <p>The path of a compressed data source, the extraction of which provides access to <code>PlainText</code> files.</p> <code>text_fixture_path</code> <code>str | None</code> <p>Path to relavant generated FixtureFile (likely <code>json</code>).</p> <code>errors</code> <code>str | None</code> <p>Text to document errors in the process the text was created.</p> <code>info</code> <code>str | None</code> <p>Further information about the text, including potential OCR method.</p> <code>canonical</code> <code>bool</code> <p>Whether this record is the default record for the related <code>Item</code>.</p>"},{"location":"reference/alto2txt2fixture/types.html#alto2txt2fixture.types.TranslatorTuple","title":"TranslatorTuple","text":"<p>             Bases: <code>NamedTuple</code></p> <p>A named tuple of fields for translation.</p> <p>Attributes:</p> Name Type Description <code>start</code> <code>str</code> <p>A string representing the starting field name.</p> <code>finish</code> <code>str | list</code> <p>A string or list specifying the field(s) to be translated. If it is a string, the translated field will be a direct mapping of the specified field in each item of the input list. If it is a list, the translated field will be a hyphen-separated concatenation of the specified fields in each item of the input list.</p> <code>lst</code> <code>list[dict]</code> <p>A list of dictionaries representing the items to be translated. Each dictionary should contain the necessary fields for translation, with the field names specified in the <code>start</code> parameter.</p>"},{"location":"reference/alto2txt2fixture/types.html#alto2txt2fixture.types.dotdict","title":"dotdict","text":"<p>             Bases: <code>dict</code></p> <p>dot.notation access to dictionary attributes</p>"},{"location":"reference/alto2txt2fixture/utils.html","title":"utils","text":""},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.DEFAULT_TRUNCATION_CHARS","title":"DEFAULT_TRUNCATION_CHARS  <code>module-attribute</code>","text":"<pre><code>DEFAULT_TRUNCATION_CHARS: Final[str] = '...'\n</code></pre> <p>Default characters to trail a truncated string.</p>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.DataSource","title":"DataSource  <code>dataclass</code>","text":"<p>Class to manage storing/deleting data files.</p> Attr <p>file_name: Name of file (not local path). app: Name of app the file is for to generate a local path. url: Url to dowload file from. read_func: Function to call on downloaded file. description: Text descriping the data source. citation: An optional link (ideally DOI) for citation. license: License data is available through. _download_exception: Exception to raise if download fails. _str_truncation_length: Maximum lenght of <code>str</code> to use in     print outs.</p> Example <pre><code>&gt;&gt;&gt; from os import chdir\n&gt;&gt;&gt; tmp_path: Path = getfixture(\"tmp_path\")\n&gt;&gt;&gt; chdir(tmp_path)\n&gt;&gt;&gt; from pandas import read_csv\n\n&gt;&gt;&gt; rsd_1851: DataSource = DataSource(\n...     file_name=demographics_1851_local_path.name,\n...     app=\"census\",\n...     url=\"https://reshare.ukdataservice.ac.uk/853547/4/1851_RSD_data.csv\",\n...     read_func=read_csv,\n...     description=\"Demographic and socio-economic variables for \"\n...                 \"Registration Sub-Districts (RSDs) in England and Wales, \"\n...                 \"1851\",\n...     citation=\"https://dx.doi.org/10.5255/UKDA-SN-853547\",\n...     license=\"http://creativecommons.org/licenses/by/4.0/\",\n... )\n&gt;&gt;&gt; assert rsd_1851.local_path == demographics_1851_local_path\n&gt;&gt;&gt; df = rsd_1851.read()\n&lt;BLANKLINE&gt;\n...'census/data/demographics_england_wales_2015.csv'...\n&gt;&gt;&gt; df.columns[:5].tolist()\n['CEN_1851', 'REGCNTY', 'REGDIST', 'SUBDIST', 'POP_DENS']\n&gt;&gt;&gt; rsd_1851.delete()\nDeleting local copy of 'de...csv'...\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.DataSource.is_empty","title":"is_empty  <code>property</code>","text":"<pre><code>is_empty: bool\n</code></pre> <p>Return if <code>Path</code> to store <code>self.file_name</code> has 0 file size.</p>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.DataSource.is_file","title":"is_file  <code>property</code>","text":"<pre><code>is_file: bool\n</code></pre> <p>Return if <code>self.local_path</code> is a file.</p>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.DataSource.is_local","title":"is_local  <code>property</code>","text":"<pre><code>is_local: bool\n</code></pre> <p>Return if <code>self.url</code> is storred locally at <code>self.file_name</code>.</p>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.DataSource.local_path","title":"local_path  <code>property</code>","text":"<pre><code>local_path: Path\n</code></pre> <p>Return path to store <code>self.file_name</code>.</p>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.DataSource.url_suffix","title":"url_suffix  <code>property</code>","text":"<pre><code>url_suffix: str\n</code></pre> <p>Return suffix of <code>self.url</code> or None if not found.</p>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.DataSource.__repr__","title":"__repr__","text":"<pre><code>__repr__() -&gt; str\n</code></pre> <p>Detailed, truncated reprt of <code>file_name</code> for <code>app</code>.</p> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Detailed, truncated reprt of `file_name` for `app`.\"\"\"\n    return (\n        f\"{self.__class__.__name__}({self.app!r}, \"\n        f\"'{_short_text_trunc(str(self.file_name))}')\"\n    )\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.DataSource.__str__","title":"__str__","text":"<pre><code>__str__() -&gt; str\n</code></pre> <p>Readable description of which <code>file_name</code> from which <code>app</code>.</p> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Readable description of which `file_name` from which `app`.\"\"\"\n    return f\"'{_short_text_trunc(str(self.file_name))}' \" f\"for `{self.app}`\"\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.DataSource.delete","title":"delete","text":"<pre><code>delete() -&gt; None\n</code></pre> <p>Delete local save of <code>self.url</code> at <code>self.file_name</code>.</p> Note <p>No error raised if missing.</p> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def delete(self) -&gt; None:\n    \"\"\"Delete local save of `self.url` at `self.file_name`.\n\n    Note:\n        No error raised if missing.\n    \"\"\"\n    if self.is_local:\n        console.log(f\"Deleting local copy of {self}.\")\n        self.local_path.unlink(missing_ok=True)\n    else:\n        console.info(f\"'{self.local_path}' cannot be deleted (not saved locally)\")\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.DataSource.download","title":"download","text":"<pre><code>download(force: bool = False) -&gt; bool\n</code></pre> <p>Download <code>self.url</code> to save locally at <code>self.file_name</code>.</p> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def download(self, force: bool = False) -&gt; bool:\n    \"\"\"Download `self.url` to save locally at `self.file_name`.\"\"\"\n    if self.is_local and not force:\n        console.log(f\"{self} already downloaded \" f\"(add `force=True` to override)\")\n        return True\n    else:\n        return download_file(self.local_path, self.url)\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.DataSource.read","title":"read","text":"<pre><code>read(force: bool = False) -&gt; DataFrame | Series\n</code></pre> <p>Return data in <code>self.local_path</code> processed by <code>self.read_func</code>.</p> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def read(self, force: bool = False) -&gt; DataFrame | Series:\n    \"\"\"Return data in `self.local_path` processed by `self.read_func`.\"\"\"\n    if not self.is_local:\n        success: bool = self.download(force=force)\n        if not success:\n            self._download_exception = DataSourceDownloadError(\n                f\"Failed to access {self} data from {self.url}\"\n            )\n            logger.error(str(self._download_exception))\n    assert self.is_local\n    return self.read_func(self.local_path)\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.DiskUsageTuple","title":"DiskUsageTuple","text":"<p>             Bases: <code>NamedTuple</code></p> <p>Type hint for <code>nametuple</code> returned from <code>disk_usage</code>.</p>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.app_data_path","title":"app_data_path","text":"<pre><code>app_data_path(\n    app_name: str, data_path: PathLike = DEFAULT_APP_DATA_FOLDER\n) -&gt; Path\n</code></pre> <p>Return <code>app_name</code> data <code>Path</code> and ensure exists.</p> Example <pre><code>&gt;&gt;&gt; from os import chdir\n&gt;&gt;&gt; tmp_path: Path = getfixture(\"tmp_path\")\n&gt;&gt;&gt; chdir(tmp_path)\n&gt;&gt;&gt; app_data_path('mitchells')\nPosixPath('mitchells/data')\n</code></pre> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def app_data_path(app_name: str, data_path: PathLike = DEFAULT_APP_DATA_FOLDER) -&gt; Path:\n    \"\"\"Return `app_name` data `Path` and ensure exists.\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; from os import chdir\n        &gt;&gt;&gt; tmp_path: Path = getfixture(\"tmp_path\")\n        &gt;&gt;&gt; chdir(tmp_path)\n        &gt;&gt;&gt; app_data_path('mitchells')\n        PosixPath('mitchells/data')\n\n        ```\n    \"\"\"\n    path = Path(app_name) / Path(data_path)\n    path.mkdir(exist_ok=True, parents=True)\n    return path\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.check_newspaper_collection_configuration","title":"check_newspaper_collection_configuration","text":"<pre><code>check_newspaper_collection_configuration(\n    collections: Iterable[str] = settings.COLLECTIONS,\n    newspaper_collections: Iterable[\n        FixtureDict\n    ] = NEWSPAPER_COLLECTION_METADATA,\n    data_provider_index: str = DATA_PROVIDER_INDEX,\n) -&gt; set[str]\n</code></pre> <p>Check the names in <code>collections</code> match the names in <code>newspaper_collections</code>.</p> <p>Parameters:</p> Name Type Description Default <code>collections</code> <code>Iterable[str]</code> <p>Names of newspaper collections, defaults to <code>settings.COLLECTIONS</code></p> <code>COLLECTIONS</code> <code>newspaper_collections</code> <code>Iterable[FixtureDict]</code> <p>Newspaper collections in a list of <code>FixtureDict</code> format. Defaults     to <code>settings.FIXTURE_TABLE['dataprovider]</code></p> <code>NEWSPAPER_COLLECTION_METADATA</code> <code>data_provider_index</code> <code>str</code> <p><code>dict</code> <code>fields</code> <code>key</code> used to check matchiching <code>collections</code> name</p> <code>DATA_PROVIDER_INDEX</code> <p>Returns:</p> Type Description <code>set[str]</code> <p>A set of <code>collections</code> without a matching <code>newspaper_collections</code> record.</p> Example <pre><code>&gt;&gt;&gt; check_newspaper_collection_configuration()\nset()\n&gt;&gt;&gt; unmatched: set[str] = check_newspaper_collection_configuration(\n...     [\"cat\", \"dog\"])\n&lt;BLANKLINE&gt;\n...Warning: 2 `collections` not in `newspaper_collections`: ...\n&gt;&gt;&gt; unmatched == {'dog', 'cat'}\nTrue\n</code></pre> <p>Note</p> <p>Set orders are random so checking <code>unmatched == {'dog, 'cat'}</code> to ensure correctness irrespective of order in the example above.</p> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def check_newspaper_collection_configuration(\n    collections: Iterable[str] = settings.COLLECTIONS,\n    newspaper_collections: Iterable[FixtureDict] = NEWSPAPER_COLLECTION_METADATA,\n    data_provider_index: str = DATA_PROVIDER_INDEX,\n) -&gt; set[str]:\n    \"\"\"Check the names in `collections` match the names in `newspaper_collections`.\n\n    Arguments:\n        collections:\n            Names of newspaper collections, defaults to ``settings.COLLECTIONS``\n        newspaper_collections:\n            Newspaper collections in a list of `FixtureDict` format. Defaults\n                to ``settings.FIXTURE_TABLE['dataprovider]``\n        data_provider_index:\n            `dict` `fields` `key` used to check matchiching `collections` name\n\n    Returns:\n        A set of ``collections`` without a matching `newspaper_collections` record.\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; check_newspaper_collection_configuration()\n        set()\n        &gt;&gt;&gt; unmatched: set[str] = check_newspaper_collection_configuration(\n        ...     [\"cat\", \"dog\"])\n        &lt;BLANKLINE&gt;\n        ...Warning: 2 `collections` not in `newspaper_collections`: ...\n        &gt;&gt;&gt; unmatched == {'dog', 'cat'}\n        True\n\n        ```\n\n        !!! note\n\n            Set orders are random so checking `unmatched == {'dog, 'cat'}` to\n            ensure correctness irrespective of order in the example above.\n\n    \"\"\"\n    newspaper_collection_names: tuple[str, ...] = tuple(\n        dict_from_list_fixture_fields(\n            newspaper_collections, field_name=data_provider_index\n        ).keys()\n    )\n    collection_diff: set[str] = set(collections) - set(newspaper_collection_names)\n    if collection_diff:\n        warning(\n            f\"{len(collection_diff)} `collections` \"\n            f\"not in `newspaper_collections`: {collection_diff}\"\n        )\n    return collection_diff\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.clear_cache","title":"clear_cache","text":"<pre><code>clear_cache(dir: str | Path) -&gt; None\n</code></pre> <p>Clears the cache directory by removing all <code>.json</code> files in it.</p> <p>Parameters:</p> Name Type Description Default <code>dir</code> <code>str | Path</code> <p>The path of the directory to be cleared.</p> required Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def clear_cache(dir: str | Path) -&gt; None:\n    \"\"\"\n    Clears the cache directory by removing all `.json` files in it.\n\n    Args:\n        dir: The path of the directory to be cleared.\n    \"\"\"\n\n    dir = get_path_from(dir)\n\n    y = input(\n        f\"Do you want to erase the cache path now that the \"\n        f\"files have been generated ({dir.absolute()})? [y/N]\"\n    )\n\n    if y.lower() == \"y\":\n        info(\"Clearing up the cache directory\")\n        for x in dir.glob(\"*.json\"):\n            x.unlink()\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.compress_fixture","title":"compress_fixture","text":"<pre><code>compress_fixture(\n    path: PathLike,\n    output_path: PathLike | str = settings.OUTPUT,\n    suffix: str = \"\",\n    format: str | ArchiveFormatEnum = ZIP_FILE_EXTENSION,\n    force_overwrite: bool = False,\n    dry_run: bool = False,\n) -&gt; Path\n</code></pre> <p>Compress exported <code>fixtures</code> files using <code>make_archive</code>.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>PathLike</code> <p><code>Path</code> to file to compress</p> required <code>output_path</code> <code>PathLike | str</code> <p>Compressed file name (without extension specified from <code>format</code>).</p> <code>OUTPUT</code> <code>format</code> <code>str | ArchiveFormatEnum</code> <p>A <code>str</code> of one of the registered compression formats. By default <code>Python</code> provides <code>zip</code>, <code>tar</code>, <code>gztar</code>, <code>bztar</code>, and <code>xztar</code>. See <code>ArchiveFormatEnum</code> variable for options checked.</p> <code>ZIP_FILE_EXTENSION</code> <code>suffix</code> <code>str</code> <p><code>str</code> to add to comprssed file name saved. For example: if <code>path = plaintext_fixture-1.json</code> and <code>suffix=_compressed</code>, then the saved file might be called <code>plaintext_fixture-1_compressed.json.zip</code></p> <code>''</code> <code>force_overwrite</code> <code>bool</code> <p>Force overwriting <code>output_path</code> if it already exists.</p> <code>False</code> <code>dry_run</code> <code>bool</code> <p>Attempt compression without modifying any files.</p> <code>False</code> Example <pre><code>&gt;&gt;&gt; logger_initial_level: int = logger.level\n&gt;&gt;&gt; logger.setLevel(logging.DEBUG)\n&gt;&gt;&gt; plaintext_bl_lwm = getfixture('bl_lwm_plaintext_json_export')\n&lt;BLANKLINE&gt;\n...\n&gt;&gt;&gt; tmp_path = getfixture('tmp_path')\n&gt;&gt;&gt; json_path: Path = next(plaintext_bl_lwm.exported_json_paths)\n&gt;&gt;&gt; assert 'lwm_test_output' in str(json_path)\n&gt;&gt;&gt; compressed_path: Path = compress_fixture(path=json_path,\n...                                          output_path=tmp_path,\n...                                          dry_run=True)\n&lt;BLANKLINE&gt;\n...Compressing...'...01.json...'...to...'zip'...\n&gt;&gt;&gt; compressed_path.exists()\nFalse\n&gt;&gt;&gt; compressed_path: Path = compress_fixture(path=json_path,\n...                                          output_path=tmp_path,\n...                                          dry_run=False)\n&lt;BLANKLINE&gt;\n...creating...'...01.json.zip...'...adding...\n...'plain...01.json'...to...it...\n&gt;&gt;&gt; from zipfile import ZipFile, ZipInfo\n&gt;&gt;&gt; zipfile_info_list: list[ZipInfo] = ZipFile(\n...     tmp_path / 'plaintext_fixture-000001.json.zip'\n... ).infolist()\n&gt;&gt;&gt; len(zipfile_info_list)\n1\n&gt;&gt;&gt; Path(zipfile_info_list[0].filename).name\n'plaintext_fixture-000001.json'\n&gt;&gt;&gt; logger.setLevel(logger_initial_level)\n</code></pre> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def compress_fixture(\n    path: PathLike,\n    output_path: PathLike | str = settings.OUTPUT,\n    suffix: str = \"\",\n    format: str | ArchiveFormatEnum = ZIP_FILE_EXTENSION,\n    # base_dir: PathLike | None = None,\n    force_overwrite: bool = False,\n    dry_run: bool = False,\n) -&gt; Path:\n    \"\"\"Compress exported `fixtures` files using `make_archive`.\n\n    Args:\n        path:\n            `Path` to file to compress\n\n        output_path:\n            Compressed file name (without extension specified from `format`).\n\n        format:\n            A `str` of one of the registered compression formats. By default\n            `Python` provides `zip`, `tar`, `gztar`, `bztar`, and `xztar`.\n            See `ArchiveFormatEnum` variable for options checked.\n\n        suffix:\n            `str` to add to comprssed file name saved.\n            For example: if `path = plaintext_fixture-1.json` and\n            `suffix=_compressed`, then the saved file might be called\n            `plaintext_fixture-1_compressed.json.zip`\n\n        force_overwrite:\n            Force overwriting `output_path` if it already exists.\n\n        dry_run:\n            Attempt compression without modifying any files.\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; logger_initial_level: int = logger.level\n        &gt;&gt;&gt; logger.setLevel(logging.DEBUG)\n        &gt;&gt;&gt; plaintext_bl_lwm = getfixture('bl_lwm_plaintext_json_export')\n        &lt;BLANKLINE&gt;\n        ...\n        &gt;&gt;&gt; tmp_path = getfixture('tmp_path')\n        &gt;&gt;&gt; json_path: Path = next(plaintext_bl_lwm.exported_json_paths)\n        &gt;&gt;&gt; assert 'lwm_test_output' in str(json_path)\n        &gt;&gt;&gt; compressed_path: Path = compress_fixture(path=json_path,\n        ...                                          output_path=tmp_path,\n        ...                                          dry_run=True)\n        &lt;BLANKLINE&gt;\n        ...Compressing...'...01.json...'...to...'zip'...\n        &gt;&gt;&gt; compressed_path.exists()\n        False\n        &gt;&gt;&gt; compressed_path: Path = compress_fixture(path=json_path,\n        ...                                          output_path=tmp_path,\n        ...                                          dry_run=False)\n        &lt;BLANKLINE&gt;\n        ...creating...'...01.json.zip...'...adding...\n        ...'plain...01.json'...to...it...\n        &gt;&gt;&gt; from zipfile import ZipFile, ZipInfo\n        &gt;&gt;&gt; zipfile_info_list: list[ZipInfo] = ZipFile(\n        ...     tmp_path / 'plaintext_fixture-000001.json.zip'\n        ... ).infolist()\n        &gt;&gt;&gt; len(zipfile_info_list)\n        1\n        &gt;&gt;&gt; Path(zipfile_info_list[0].filename).name\n        'plaintext_fixture-000001.json'\n        &gt;&gt;&gt; logger.setLevel(logger_initial_level)\n\n        ```\n    \"\"\"\n    path = Path(path)\n    absolute_path = path.absolute()\n    root_dir: str | None = None\n    base_dir: str | None = None\n    if not path.exists():\n        raise ValueError(f\"Cannot compress; 'path' does not exist: {path}\")\n    if isinstance(format, str):\n        try:\n            format = ArchiveFormatEnum(format)\n        except ValueError:\n            raise ValueError(\n                f\"format '{format}' not valid, \"\n                f\"options are:'\\n{pformat(ARCHIVE_FORMATS)}\"\n            )\n\n    if absolute_path.is_file():\n        root_dir = str(Path(path).parent)\n        base_dir = path.name\n    elif absolute_path.is_dir():\n        root_dir = str(absolute_path)\n\n    else:\n        raise ValueError(\n            f\"Path must exist and be a file or folder. \" f\"Not valid: '{path}'\"\n        )\n\n    save_file_name: Path = Path(Path(path).stem + suffix + \"\".join(Path(path).suffixes))\n    save_path: Path = Path(output_path) / save_file_name\n    if Path(str(save_path) + f\".{format}\").exists():\n        error_message: str = f\"Path to save to already exists: '{save_path}'\"\n        if force_overwrite:\n            logger.warn(error_message)\n            logger.warn(f\"Overwriting '{save_path}'\")\n        else:\n            raise ValueError(error_message)\n    logger.info(f\"Compressing '{path}' to '{format}' in: '{save_path.parent}'\")\n\n    archive_path: Path = Path(\n        make_archive(\n            base_name=str(save_path),\n            format=str(format),\n            root_dir=root_dir,\n            base_dir=base_dir,\n            dry_run=dry_run,\n            logger=logger,\n        )\n    )\n\n    return archive_path\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.copy_dict_paths","title":"copy_dict_paths","text":"<pre><code>copy_dict_paths(copy_path_dict: dict[PathLike, PathLike]) -&gt; None\n</code></pre> <p>Copy files from <code>copy_path_dict</code> <code>keys</code> to <code>values</code>.</p> Example <pre><code>&gt;&gt;&gt; tmp_path: Path = getfixture('tmp_path')\n&gt;&gt;&gt; test_files_path: Path = (tmp_path / 'copy_dict')\n&gt;&gt;&gt; test_files_path.mkdir(exist_ok=True)\n&gt;&gt;&gt; for i in range(4):\n...     (test_files_path / f'test_file-{i}.txt').touch(exist_ok=True)\n&gt;&gt;&gt; pprint(sorted(test_files_path.iterdir()))\n[...Path('...file-0.txt'),\n ...Path('...file-1.txt'),\n ...Path('...file-2.txt'),\n ...Path('...file-3.txt')]\n&gt;&gt;&gt; output_path = test_files_path / 'save'\n&gt;&gt;&gt; output_path.mkdir(exist_ok=True)\n&gt;&gt;&gt; logger_initial_level: int = logger.level\n&gt;&gt;&gt; logger.setLevel(logging.DEBUG)\n&gt;&gt;&gt; copy_dict_paths(\n...     glob_path_rename_by_0_padding(test_files_path,\n...                                   glob_regex_str=\"*.txt\",\n...                                   output_path=output_path))\n&lt;BLANKLINE&gt;\n...Specified...'...'...for...saving...file...copies...\n...'...-0...txt'...to...'...-00...txt...'...\n...'...-1...txt'...to...'...-01...txt...'\n...'...-2...txt'...to...'...-02...txt...'\n...'...-3...txt'...to...'...-03...txt...'\n&gt;&gt;&gt; pprint(sorted(test_files_path.iterdir()))\n[...Path('...save'),\n ...Path('...test_file-0.txt'),\n ...Path('...test_file-1.txt'),\n ...Path('...test_file-2.txt'),\n ...Path('...test_file-3.txt')]\n&gt;&gt;&gt; pprint(sorted((test_files_path / 'save').iterdir()))\n [...Path('...test_file-00.txt'),\n  ...Path('...test_file-01.txt'),\n  ...Path('...test_file-02.txt'),\n  ...Path('...test_file-03.txt')]\n&gt;&gt;&gt; logger.setLevel(logger_initial_level)\n</code></pre> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def copy_dict_paths(copy_path_dict: dict[PathLike, PathLike]) -&gt; None:\n    \"\"\"Copy files from `copy_path_dict` `keys` to `values`.\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; tmp_path: Path = getfixture('tmp_path')\n        &gt;&gt;&gt; test_files_path: Path = (tmp_path / 'copy_dict')\n        &gt;&gt;&gt; test_files_path.mkdir(exist_ok=True)\n        &gt;&gt;&gt; for i in range(4):\n        ...     (test_files_path / f'test_file-{i}.txt').touch(exist_ok=True)\n        &gt;&gt;&gt; pprint(sorted(test_files_path.iterdir()))\n        [...Path('...file-0.txt'),\n         ...Path('...file-1.txt'),\n         ...Path('...file-2.txt'),\n         ...Path('...file-3.txt')]\n        &gt;&gt;&gt; output_path = test_files_path / 'save'\n        &gt;&gt;&gt; output_path.mkdir(exist_ok=True)\n        &gt;&gt;&gt; logger_initial_level: int = logger.level\n        &gt;&gt;&gt; logger.setLevel(logging.DEBUG)\n        &gt;&gt;&gt; copy_dict_paths(\n        ...     glob_path_rename_by_0_padding(test_files_path,\n        ...                                   glob_regex_str=\"*.txt\",\n        ...                                   output_path=output_path))\n        &lt;BLANKLINE&gt;\n        ...Specified...'...'...for...saving...file...copies...\n        ...'...-0...txt'...to...'...-00...txt...'...\n        ...'...-1...txt'...to...'...-01...txt...'\n        ...'...-2...txt'...to...'...-02...txt...'\n        ...'...-3...txt'...to...'...-03...txt...'\n        &gt;&gt;&gt; pprint(sorted(test_files_path.iterdir()))\n        [...Path('...save'),\n         ...Path('...test_file-0.txt'),\n         ...Path('...test_file-1.txt'),\n         ...Path('...test_file-2.txt'),\n         ...Path('...test_file-3.txt')]\n        &gt;&gt;&gt; pprint(sorted((test_files_path / 'save').iterdir()))\n         [...Path('...test_file-00.txt'),\n          ...Path('...test_file-01.txt'),\n          ...Path('...test_file-02.txt'),\n          ...Path('...test_file-03.txt')]\n        &gt;&gt;&gt; logger.setLevel(logger_initial_level)\n\n        ```\n    \"\"\"\n    for current_path, copy_path in copy_path_dict.items():\n        logger.info(f\"Copying '{current_path}' to '{copy_path}'\")\n        Path(copy_path).parent.mkdir(exist_ok=True)\n        copyfile(current_path, copy_path)\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.create_lookup","title":"create_lookup","text":"<pre><code>create_lookup(lst: list = [], on: list = []) -&gt; dict\n</code></pre> <p>Create a lookup dictionary from a list of dictionaries.</p> <p>Parameters:</p> Name Type Description Default <code>lst</code> <code>list</code> <p>A list of dictionaries that should be used to generate the lookup.</p> <code>[]</code> <code>on</code> <code>list</code> <p>A list of keys from the dictionaries in the list that should be used as the keys in the lookup.</p> <code>[]</code> <p>Returns:</p> Type Description <code>dict</code> <p>The generated lookup dictionary.</p> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def create_lookup(lst: list = [], on: list = []) -&gt; dict:\n    \"\"\"\n    Create a lookup dictionary from a list of dictionaries.\n\n    Args:\n        lst: A list of dictionaries that should be used to generate the lookup.\n        on: A list of keys from the dictionaries in the list that should be used as the keys in the lookup.\n\n    Returns:\n        The generated lookup dictionary.\n    \"\"\"\n    return {get_key(x, on): x[\"pk\"] for x in lst}\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.dict_from_list_fixture_fields","title":"dict_from_list_fixture_fields","text":"<pre><code>dict_from_list_fixture_fields(\n    fixture_list: Iterable[FixtureDict] = NEWSPAPER_COLLECTION_METADATA,\n    field_name: str = DATA_PROVIDER_INDEX,\n) -&gt; dict[str, FixtureDict]\n</code></pre> <p>Create a <code>dict</code> from <code>fixture_list</code> with <code>attr_name</code> as <code>key</code>.</p> <p>Parameters:</p> Name Type Description Default <code>fixture_list</code> <code>Iterable[FixtureDict]</code> <p><code>list</code> of <code>FixtureDict</code> with <code>attr_name</code> key <code>fields</code>.</p> <code>NEWSPAPER_COLLECTION_METADATA</code> <code>field_name</code> <code>str</code> <p>key for values within <code>fixture_list</code> <code>fields</code>.</p> <code>DATA_PROVIDER_INDEX</code> <p>Returns:</p> Type Description <code>dict[str, FixtureDict]</code> <p>A <code>dict</code> where extracted <code>field_name</code> is key for related <code>FixtureDict</code> values.</p> Example <pre><code>&gt;&gt;&gt; fixture_dict: dict[str, FixtureDict] = dict_from_list_fixture_fields()\n&gt;&gt;&gt; fixture_dict['hmd']['pk']\n2\n&gt;&gt;&gt; fixture_dict['hmd']['fields'][DATA_PROVIDER_INDEX]\n'hmd'\n&gt;&gt;&gt; fixture_dict['hmd']['fields']['code']\n'bl-hmd'\n</code></pre> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def dict_from_list_fixture_fields(\n    fixture_list: Iterable[FixtureDict] = NEWSPAPER_COLLECTION_METADATA,\n    field_name: str = DATA_PROVIDER_INDEX,\n) -&gt; dict[str, FixtureDict]:\n    \"\"\"Create a `dict` from ``fixture_list`` with ``attr_name`` as `key`.\n\n    Args:\n        fixture_list: `list` of `FixtureDict` with ``attr_name`` key `fields`.\n        field_name: key for values within ``fixture_list`` `fields`.\n\n    Returns:\n        A `dict` where extracted `field_name` is key for related `FixtureDict` values.\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; fixture_dict: dict[str, FixtureDict] = dict_from_list_fixture_fields()\n        &gt;&gt;&gt; fixture_dict['hmd']['pk']\n        2\n        &gt;&gt;&gt; fixture_dict['hmd']['fields'][DATA_PROVIDER_INDEX]\n        'hmd'\n        &gt;&gt;&gt; fixture_dict['hmd']['fields']['code']\n        'bl-hmd'\n\n        ```\n    \"\"\"\n    return {record[\"fields\"][field_name]: record for record in fixture_list}\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.dirs_in_path","title":"dirs_in_path","text":"<pre><code>dirs_in_path(path: PathLike) -&gt; Generator[Path, None, None]\n</code></pre> <p>Yield all folder paths (not recursively) in <code>path</code>.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>PathLike</code> <p><code>Path</code> to count subfolders in.</p> required <p>Yields:</p> Type Description <code>Path</code> <p>Each folder one walk length in <code>path</code></p> Example <pre><code>&gt;&gt;&gt; tmp_path = getfixture('tmp_path')\n&gt;&gt;&gt; len(tuple(dir.name for dir in dirs_in_path(tmp_path)))\n0\n&gt;&gt;&gt; (tmp_path / 'a_file_not_dir').touch()\n&gt;&gt;&gt; len(tuple(dir.name for dir in dirs_in_path(tmp_path)))\n0\n&gt;&gt;&gt; (tmp_path / 'test_dir').mkdir()\n&gt;&gt;&gt; tuple(dir.name for dir in dirs_in_path(tmp_path))\n('test_dir',)\n&gt;&gt;&gt; [(tmp_path / f'new_dir_{i}').mkdir() for i in range(3)]\n[None, None, None]\n&gt;&gt;&gt; tuple(dir.name for dir in sorted(dirs_in_path(tmp_path)))\n('new_dir_0', 'new_dir_1', 'new_dir_2', 'test_dir')\n&gt;&gt;&gt; (tmp_path / 'test_dir' / 'another_dir').mkdir()\n&gt;&gt;&gt; tuple(dir.name for dir in sorted(dirs_in_path(tmp_path)))\n('new_dir_0', 'new_dir_1', 'new_dir_2', 'test_dir')\n</code></pre> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def dirs_in_path(path: PathLike) -&gt; Generator[Path, None, None]:\n    \"\"\"Yield all folder paths (not recursively) in `path`.\n\n    Args:\n        path: `Path` to count subfolders in.\n\n    Yields:\n        Each folder one walk length in `path`\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; tmp_path = getfixture('tmp_path')\n        &gt;&gt;&gt; len(tuple(dir.name for dir in dirs_in_path(tmp_path)))\n        0\n        &gt;&gt;&gt; (tmp_path / 'a_file_not_dir').touch()\n        &gt;&gt;&gt; len(tuple(dir.name for dir in dirs_in_path(tmp_path)))\n        0\n        &gt;&gt;&gt; (tmp_path / 'test_dir').mkdir()\n        &gt;&gt;&gt; tuple(dir.name for dir in dirs_in_path(tmp_path))\n        ('test_dir',)\n        &gt;&gt;&gt; [(tmp_path / f'new_dir_{i}').mkdir() for i in range(3)]\n        [None, None, None]\n        &gt;&gt;&gt; tuple(dir.name for dir in sorted(dirs_in_path(tmp_path)))\n        ('new_dir_0', 'new_dir_1', 'new_dir_2', 'test_dir')\n        &gt;&gt;&gt; (tmp_path / 'test_dir' / 'another_dir').mkdir()\n        &gt;&gt;&gt; tuple(dir.name for dir in sorted(dirs_in_path(tmp_path)))\n        ('new_dir_0', 'new_dir_1', 'new_dir_2', 'test_dir')\n\n        ```\n    \"\"\"\n    for sub_path in Path(path).iterdir():\n        if sub_path.is_dir():\n            yield sub_path\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.download_file","title":"download_file","text":"<pre><code>download_file(local_path: PathLike, url: str, force: bool = False) -&gt; bool\n</code></pre> <p>If <code>force</code> or not available, download <code>url</code> to <code>local_path</code>.</p> Example <pre><code>&gt;&gt;&gt; jpg_url: str = \"https://commons.wikimedia.org/wiki/File:Wassily_Leontief_1973.jpg\"\n&gt;&gt;&gt; local_path: Path = Path('test.jpg')\n&gt;&gt;&gt; local_path.unlink(missing_ok=True)  # Ensure png deleted\n&gt;&gt;&gt; success: bool = download_file(local_path, jpg_url)\n&lt;BLANKLINE&gt;\n...'test.jpg' not...found...downloading...\n...wiki/File:Wassily_Leonti..._1973.jpg'...\n...Saved to 'test.jpg'...\n&gt;&gt;&gt; success\nTrue\n&gt;&gt;&gt; local_path.unlink()  # Delete downloaded jpg\n</code></pre> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def download_file(\n    local_path: PathLike,\n    url: str,\n    force: bool = False,\n) -&gt; bool:\n    \"\"\"If `force` or not available, download `url` to `local_path`.\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; jpg_url: str = \"https://commons.wikimedia.org/wiki/File:Wassily_Leontief_1973.jpg\"\n        &gt;&gt;&gt; local_path: Path = Path('test.jpg')\n        &gt;&gt;&gt; local_path.unlink(missing_ok=True)  # Ensure png deleted\n        &gt;&gt;&gt; success: bool = download_file(local_path, jpg_url)\n        &lt;BLANKLINE&gt;\n        ...'test.jpg' not...found...downloading...\n        ...wiki/File:Wassily_Leonti..._1973.jpg'...\n        ...Saved to 'test.jpg'...\n        &gt;&gt;&gt; success\n        True\n        &gt;&gt;&gt; local_path.unlink()  # Delete downloaded jpg\n\n        ```\n    \"\"\"\n    local_path = Path(local_path)\n    if not validate_url(url):\n        console.log(\n            f\"'{url}' is not a valid url\",\n        )\n        return False\n    if not local_path.exists() or force:\n        if force:\n            console.log(\n                f\"Overwriting '{local_path}' by downloading from '{url}'\",\n            )\n        else:\n            console.log(\n                f\"'{local_path}' not found, downloading from '{url}'\",\n            )\n        try:\n            with (\n                urlopen(url) as response,\n                open(str(local_path), \"wb\") as out_file,\n            ):\n                copyfileobj(response, out_file)\n        except IsADirectoryError:\n            console.log(\n                f\"'{local_path}' must be a file, not a directory\",\n            )\n            return False\n        except URLError:\n            console.log(\n                f\"Download error (likely no internet connection): '{url}'\",\n            )\n            return False\n        else:\n            console.log(f\"Saved to '{local_path}'\")\n    if not local_path.is_file():\n        console.log(\n            f\"'{local_path}' is not a file\",\n        )\n        return False\n    if not local_path.stat().st_size &gt; 0:\n        console.log(\n            f\"'{local_path}' from '{url}' is empty\",\n        )\n        return False\n    else:\n        logger.debug(\n            f\"'{url}' file available from '{local_path}'\",\n        )\n        return True\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.export_fixtures","title":"export_fixtures","text":"<pre><code>export_fixtures(\n    fixture_tables: dict[str, Sequence[FixtureDict]],\n    path: str | PathLike = settings.FIXTURE_TABLES_OUTPUT,\n    prefix: str = \"test-\",\n    add_created: bool = True,\n    add_fixutre_name: bool = False,\n    fixture_name_field: str = \"\",\n    formats: Sequence[EXPORT_FORMATS] = settings.FIXTURE_TABLES_FORMATS,\n    file_name_0_padding: int = FILE_NAME_0_PADDING_DEFAULT,\n) -&gt; None\n</code></pre> <p>Export <code>fixture_tables</code> in <code>formats</code>.</p> Note <p>This is still in experimental phase of development and not recommended for production.</p> <p>Parameters:</p> Name Type Description Default <code>fixture_tables</code> <code>dict[str, Sequence[FixtureDict]]</code> <p><code>dict</code> of table name (eg: <code>dataprovider</code>) and <code>FixtureDict</code></p> required <code>path</code> <code>str | PathLike</code> <p><code>Path</code> to save exports in</p> <code>FIXTURE_TABLES_OUTPUT</code> <code>prefix</code> <code>str</code> <p><code>str</code> to prefix export file names with</p> <code>'test-'</code> <code>formats</code> <code>Sequence[EXPORT_FORMATS]</code> <p><code>list</code> of <code>EXPORT_FORMATS</code> to export</p> <code>FIXTURE_TABLES_FORMATS</code> <code>file_name_0_padding</code> <code>int</code> <p>Zeros to prefix the number of each fixture file name.</p> <code>FILE_NAME_0_PADDING_DEFAULT</code> Example <pre><code>&gt;&gt;&gt; tmp_path = getfixture('tmp_path')\n&gt;&gt;&gt; test_fixture_tables: dict[str, FixtureDict] = {\n...     'test0': NEWSPAPER_COLLECTION_METADATA,\n...     'test1': NEWSPAPER_COLLECTION_METADATA}\n&gt;&gt;&gt; export_fixtures(test_fixture_tables, path=tmp_path / 'exports')\n&lt;BLANKLINE&gt;\n...Warning: Saving test0...\n...Warning: Saving test1...\n&gt;&gt;&gt; from pandas import read_csv\n&gt;&gt;&gt; fixture0_json = load_json(tmp_path / 'exports/test-test0-000001.json')\n&gt;&gt;&gt; fixture0_df = read_csv(tmp_path / 'exports/test-test0-000001.csv')\n&gt;&gt;&gt; fixture1_json = load_json(tmp_path / 'exports/test-test1-000001.json')\n&gt;&gt;&gt; fixture1_df = read_csv(tmp_path / 'exports/test-test1-000001.csv')\n&gt;&gt;&gt; fixture0_json == fixture1_json\nTrue\n&gt;&gt;&gt; all(fixture0_df == fixture1_df)\nTrue\n&gt;&gt;&gt; all(field in fixture0_json[0]['fields']\n...     for field in ['created_at', 'updated_at'])\nTrue\n&gt;&gt;&gt; fixture0_json[1]['pk']\n2\n&gt;&gt;&gt; fixture0_json[1]['fields'][DATA_PROVIDER_INDEX]\n'hmd'\n&gt;&gt;&gt; fixture0_df[['pk', DATA_PROVIDER_INDEX]].iloc[1].to_list()\n[2, 'hmd']\n</code></pre> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def export_fixtures(\n    fixture_tables: dict[str, Sequence[FixtureDict]],\n    path: str | PathLike = settings.FIXTURE_TABLES_OUTPUT,\n    prefix: str = \"test-\",\n    add_created: bool = True,\n    add_fixutre_name: bool = False,\n    fixture_name_field: str = \"\",\n    formats: Sequence[EXPORT_FORMATS] = settings.FIXTURE_TABLES_FORMATS,\n    file_name_0_padding: int = FILE_NAME_0_PADDING_DEFAULT,\n) -&gt; None:\n    \"\"\"Export `fixture_tables` in `formats`.\n\n    Note:\n        This is still in experimental phase of development and not recommended\n        for production.\n\n    Args:\n        fixture_tables:\n            `dict` of table name (eg: `dataprovider`) and `FixtureDict`\n        path:\n            `Path` to save exports in\n        prefix:\n            `str` to prefix export file names with\n        formats:\n            `list` of `EXPORT_FORMATS` to export\n        file_name_0_padding:\n            Zeros to prefix the number of each fixture file name.\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; tmp_path = getfixture('tmp_path')\n        &gt;&gt;&gt; test_fixture_tables: dict[str, FixtureDict] = {\n        ...     'test0': NEWSPAPER_COLLECTION_METADATA,\n        ...     'test1': NEWSPAPER_COLLECTION_METADATA}\n        &gt;&gt;&gt; export_fixtures(test_fixture_tables, path=tmp_path / 'exports')\n        &lt;BLANKLINE&gt;\n        ...Warning: Saving test0...\n        ...Warning: Saving test1...\n        &gt;&gt;&gt; from pandas import read_csv\n        &gt;&gt;&gt; fixture0_json = load_json(tmp_path / 'exports/test-test0-000001.json')\n        &gt;&gt;&gt; fixture0_df = read_csv(tmp_path / 'exports/test-test0-000001.csv')\n        &gt;&gt;&gt; fixture1_json = load_json(tmp_path / 'exports/test-test1-000001.json')\n        &gt;&gt;&gt; fixture1_df = read_csv(tmp_path / 'exports/test-test1-000001.csv')\n        &gt;&gt;&gt; fixture0_json == fixture1_json\n        True\n        &gt;&gt;&gt; all(fixture0_df == fixture1_df)\n        True\n        &gt;&gt;&gt; all(field in fixture0_json[0]['fields']\n        ...     for field in ['created_at', 'updated_at'])\n        True\n        &gt;&gt;&gt; fixture0_json[1]['pk']\n        2\n        &gt;&gt;&gt; fixture0_json[1]['fields'][DATA_PROVIDER_INDEX]\n        'hmd'\n        &gt;&gt;&gt; fixture0_df[['pk', DATA_PROVIDER_INDEX]].iloc[1].to_list()\n        [2, 'hmd']\n\n        ```\n    \"\"\"\n    for table_name, records in fixture_tables.items():\n        warning(\n            f\"Saving {table_name} fixture in {formats} formats \"\n            f\"to {path} *without* checks...\"\n        )\n        if \"json\" in formats:\n            save_fixture(\n                records,\n                prefix=f\"{prefix}{table_name}\",\n                output_path=path,\n                add_created=add_created,\n                file_name_0_padding=file_name_0_padding,\n            )\n        if \"csv\" in formats:\n            fixtures_dict2csv(records, prefix=f\"{prefix}{table_name}\", output_path=path)\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.file_path_to_item_code","title":"file_path_to_item_code","text":"<pre><code>file_path_to_item_code(\n    path: PathLike,\n    separation_char: str = CODE_SEPERATOR_CHAR,\n    file_name_separtion_char: str = FILE_NAME_SEPERATOR_CHAR,\n) -&gt; str\n</code></pre> <p>Extract <code>lwmdb.newspapers.Item.item_code</code> from <code>path</code>.</p> Example <pre><code>&gt;&gt;&gt; file_path_to_item_code('0003548/1904/0707/0003548_19040707_art0037.txt')\n'0003548-19040707-art0037'\n</code></pre> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def file_path_to_item_code(\n    path: PathLike,\n    separation_char: str = CODE_SEPERATOR_CHAR,\n    file_name_separtion_char: str = FILE_NAME_SEPERATOR_CHAR,\n) -&gt; str:\n    \"\"\"Extract `lwmdb.newspapers.Item.item_code` from `path`.\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; file_path_to_item_code('0003548/1904/0707/0003548_19040707_art0037.txt')\n        '0003548-19040707-art0037'\n\n        ```\n    \"\"\"\n    return Path(path).stem.replace(file_name_separtion_char, separation_char)\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.files_in_path","title":"files_in_path","text":"<pre><code>files_in_path(path: PathLike) -&gt; Generator[Path, None, None]\n</code></pre> <p>Yield all file paths (not recursively) in <code>path</code>.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>PathLike</code> <p><code>Path</code> to count files in.</p> required <p>Yields:</p> Type Description <code>Path</code> <p>Each file one walk length in <code>path</code></p> Example <pre><code>&gt;&gt;&gt; tmp_path = getfixture('tmp_path')\n&gt;&gt;&gt; len(tuple(files_in_path(tmp_path)))\n0\n&gt;&gt;&gt; (tmp_path / 'a_file_not_dir').touch()\n&gt;&gt;&gt; tuple(file.name for file in files_in_path(tmp_path))\n('a_file_not_dir',)\n&gt;&gt;&gt; (tmp_path / 'test_dir').mkdir()\n&gt;&gt;&gt; tuple(file.name for file in files_in_path(tmp_path))\n('a_file_not_dir',)\n&gt;&gt;&gt; [(tmp_path / f'new_dir_{i}').mkdir() for i in range(3)]\n[None, None, None]\n&gt;&gt;&gt; tuple(file.name for file in files_in_path(tmp_path))\n('a_file_not_dir',)\n&gt;&gt;&gt; (tmp_path / 'test_dir' / 'another_dir').mkdir()\n&gt;&gt;&gt; (tmp_path / 'test_dir' / 'another_folder_file').touch()\n&gt;&gt;&gt; tuple(file.name for file in files_in_path(tmp_path))\n('a_file_not_dir',)\n&gt;&gt;&gt; (tmp_path / 'another_file_not_dir').touch()\n&gt;&gt;&gt; tuple(file.name for file in files_in_path(tmp_path))\n('a_file_not_dir', 'another_file_not_dir')\n</code></pre> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def files_in_path(path: PathLike) -&gt; Generator[Path, None, None]:\n    \"\"\"Yield all file paths (not recursively) in `path`.\n\n    Args:\n        path: `Path` to count files in.\n\n    Yields:\n        Each file one walk length in `path`\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; tmp_path = getfixture('tmp_path')\n        &gt;&gt;&gt; len(tuple(files_in_path(tmp_path)))\n        0\n        &gt;&gt;&gt; (tmp_path / 'a_file_not_dir').touch()\n        &gt;&gt;&gt; tuple(file.name for file in files_in_path(tmp_path))\n        ('a_file_not_dir',)\n        &gt;&gt;&gt; (tmp_path / 'test_dir').mkdir()\n        &gt;&gt;&gt; tuple(file.name for file in files_in_path(tmp_path))\n        ('a_file_not_dir',)\n        &gt;&gt;&gt; [(tmp_path / f'new_dir_{i}').mkdir() for i in range(3)]\n        [None, None, None]\n        &gt;&gt;&gt; tuple(file.name for file in files_in_path(tmp_path))\n        ('a_file_not_dir',)\n        &gt;&gt;&gt; (tmp_path / 'test_dir' / 'another_dir').mkdir()\n        &gt;&gt;&gt; (tmp_path / 'test_dir' / 'another_folder_file').touch()\n        &gt;&gt;&gt; tuple(file.name for file in files_in_path(tmp_path))\n        ('a_file_not_dir',)\n        &gt;&gt;&gt; (tmp_path / 'another_file_not_dir').touch()\n        &gt;&gt;&gt; tuple(file.name for file in files_in_path(tmp_path))\n        ('a_file_not_dir', 'another_file_not_dir')\n\n        ```\n    \"\"\"\n    for sub_path in Path(path).iterdir():\n        if sub_path.is_file():\n            yield sub_path\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.filter_json_fields","title":"filter_json_fields","text":"<pre><code>filter_json_fields(\n    json_results: list | dict | None = None,\n    file_path: PathLike | None = None,\n    fields: Sequence[str] = [],\n    value: Hashable = \"\",\n    **kwargs\n) -&gt; dict | list\n</code></pre> <p>Return <code>keys</code> and <code>values</code> from <code>json_dict</code> where any <code>fields</code> equal <code>value</code>.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>PathLike | None</code> <p>The file <code>path</code> to load based on extension and filter</p> <code>None</code> <code>fields</code> <code>Sequence[str]</code> <p>Which fields to check equal <code>value</code></p> <code>[]</code> <code>value</code> <code>Hashable</code> <p>Value to filter by</p> <code>''</code> <p>Returns:</p> Type Description <code>dict | list</code> <p>A <code>dict</code> of records indexed by <code>pk</code> which fit filter criteria</p> <p>Raises:</p> Type Description <code>ValueError</code> <p><code>file_path</code> must have a <code>.json</code> <code>suffix</code></p> Example <pre><code>&gt;&gt;&gt; entry_fixture: dict = [\n...     {\"pk\": 4889, \"model\": \"mitchells.entry\",\n...      \"fields\": {\"title\": \"BIRMINGHAM POST .\",\n...                 \"price_raw\": ['2d'],\n...                 \"year\": 1920,\n...                 \"date_established_raw\": \"1857\",\n...                 \"persons\": [], \"newspaper\": \"\"}},\n...      {\"pk\": 9207, \"model\": \"mitchells.entry\",\n...       \"fields\": {\"title\": \"ULVERSTONE ADVERTISER .\",\n...                  \"price_raw\": ['2 \u00bd d', '3 \u00bd d'],\n...                  \"year\": 1856,\n...                  \"date_established_raw\": \"1848\",\n...                  \"persons\": ['Stephen Soulby'],\n...                  \"newspaper\": \"\",}},\n...     {\"pk\": 15, \"model\": \"mitchells.entry\",\n...      \"fields\": {\"title\": \"LLOYD'S WEEKLY LONDON NEWSPAPER .\",\n...                 \"price_raw\": ['2d', '3d'],\n...                 \"year\": 1857,\n...                 \"date_established_raw\": \"November , 1842\",\n...                 \"persons\": ['Mr. Douglas Jerrold', 'Edward Lloyd'],\n...                 \"newspaper\": 1187}}\n...     ]\n&gt;&gt;&gt; pprint(filter_json_fields(entry_fixture,\n...                           fields=(\"newspaper\", \"persons\"),\n...                           value=\"\"))\n[{'fields': {'date_established_raw': '1857',\n             'newspaper': '',\n             'persons': [],\n             'price_raw': ['2d'],\n             'title': 'BIRMINGHAM POST .',\n             'year': 1920},\n  'model': 'mitchells.entry',\n  'pk': 4889},\n {'fields': {'date_established_raw': '1848',\n             'newspaper': '',\n             'persons': ['Stephen Soulby'],\n             'price_raw': ['2 \u00bd d', '3 \u00bd d'],\n             'title': 'ULVERSTONE ADVERTISER .',\n             'year': 1856},\n  'model': 'mitchells.entry',\n  'pk': 9207}]\n</code></pre> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def filter_json_fields(\n    json_results: list | dict | None = None,\n    file_path: PathLike | None = None,\n    fields: Sequence[str] = [],\n    value: Hashable = \"\",\n    **kwargs,\n) -&gt; dict | list:\n    \"\"\"Return `keys` and `values` from `json_dict` where any `fields` equal `value`.\n\n    Args:\n        file_path: The file `path` to load based on extension and filter\n        fields: Which fields to check equal `value`\n        value: Value to filter by\n\n    Returns:\n        A `dict` of records indexed by `pk` which fit filter criteria\n\n    Raises:\n        ValueError: ``file_path`` must have a `.json` `suffix`\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; entry_fixture: dict = [\n        ...     {\"pk\": 4889, \"model\": \"mitchells.entry\",\n        ...      \"fields\": {\"title\": \"BIRMINGHAM POST .\",\n        ...                 \"price_raw\": ['2d'],\n        ...                 \"year\": 1920,\n        ...                 \"date_established_raw\": \"1857\",\n        ...                 \"persons\": [], \"newspaper\": \"\"}},\n        ...      {\"pk\": 9207, \"model\": \"mitchells.entry\",\n        ...       \"fields\": {\"title\": \"ULVERSTONE ADVERTISER .\",\n        ...                  \"price_raw\": ['2 \\u00bd d', '3 \\u00bd d'],\n        ...                  \"year\": 1856,\n        ...                  \"date_established_raw\": \"1848\",\n        ...                  \"persons\": ['Stephen Soulby'],\n        ...                  \"newspaper\": \"\",}},\n        ...     {\"pk\": 15, \"model\": \"mitchells.entry\",\n        ...      \"fields\": {\"title\": \"LLOYD'S WEEKLY LONDON NEWSPAPER .\",\n        ...                 \"price_raw\": ['2d', '3d'],\n        ...                 \"year\": 1857,\n        ...                 \"date_established_raw\": \"November , 1842\",\n        ...                 \"persons\": ['Mr. Douglas Jerrold', 'Edward Lloyd'],\n        ...                 \"newspaper\": 1187}}\n        ...     ]\n        &gt;&gt;&gt; pprint(filter_json_fields(entry_fixture,\n        ...                           fields=(\"newspaper\", \"persons\"),\n        ...                           value=\"\"))\n        [{'fields': {'date_established_raw': '1857',\n                     'newspaper': '',\n                     'persons': [],\n                     'price_raw': ['2d'],\n                     'title': 'BIRMINGHAM POST .',\n                     'year': 1920},\n          'model': 'mitchells.entry',\n          'pk': 4889},\n         {'fields': {'date_established_raw': '1848',\n                     'newspaper': '',\n                     'persons': ['Stephen Soulby'],\n                     'price_raw': ['2 \\u00bd d', '3 \\u00bd d'],\n                     'title': 'ULVERSTONE ADVERTISER .',\n                     'year': 1856},\n          'model': 'mitchells.entry',\n          'pk': 9207}]\n\n        ```\n    \"\"\"\n    if not json_results:\n        assert file_path\n        try:\n            assert Path(file_path).suffix == \".json\"\n        except AssertionError:\n            raise ValueError(f\"{file_path} must be `json` format.\")\n        json_results = load_json(Path(file_path), **kwargs)\n    assert json_results\n    if isinstance(json_results, dict):\n        return {\n            k: v\n            for k, v in json_results.items()\n            if any(v[\"fields\"][field] == value for field in fields)\n        }\n    else:\n        return [\n            v\n            for v in json_results\n            if any(v[\"fields\"][field] == value for field in fields)\n        ]\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.fixture_fields","title":"fixture_fields","text":"<pre><code>fixture_fields(\n    fixture_dict: FixtureDict, include_pk: bool = True, as_dict: bool = False\n) -&gt; tuple[str, ...] | dict[str, Any]\n</code></pre> <p>Generate a tuple of <code>FixtureDict</code> <code>field</code> names.</p> Note <p>This is not in the <code>utils</code> module to avoid a circular import.</p> <p>Parameters:</p> Name Type Description Default <code>fixture_dict</code> <code>FixtureDict</code> <p>A <code>FixtureDict</code> instance to extract names from <code>fields</code></p> required <code>include_pk</code> <code>bool</code> <p>Whether to include the <code>pk</code> (primary key) column</p> <code>True</code> Example <pre><code>&gt;&gt;&gt; fixture_fields(NEWSPAPER_COLLECTION_METADATA[0])\n('pk', 'name', 'code', 'legacy_code', 'collection', 'source_note')\n&gt;&gt;&gt; fixture_fields(NEWSPAPER_COLLECTION_METADATA[0], include_pk=False)\n('name', 'code', 'legacy_code', 'collection', 'source_note')\n&gt;&gt;&gt; hmd_dict: dict[str, Any] = fixture_fields(\n...     NEWSPAPER_COLLECTION_METADATA[1], as_dict=True)\n&gt;&gt;&gt; hmd_dict['code']\n'bl-hmd'\n&gt;&gt;&gt; hmd_dict['pk']\n2\n&gt;&gt;&gt; hmd_dict = fixture_fields(\n...     NEWSPAPER_COLLECTION_METADATA[1], include_pk=False, as_dict=True)\n&gt;&gt;&gt; 'pk' in hmd_dict\nFalse\n</code></pre> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def fixture_fields(\n    fixture_dict: FixtureDict, include_pk: bool = True, as_dict: bool = False\n) -&gt; tuple[str, ...] | dict[str, Any]:\n    \"\"\"Generate a tuple of `FixtureDict` `field` names.\n\n    Note:\n        This is not in the `utils` module to avoid a circular import.\n\n    Args:\n        fixture_dict: A `FixtureDict` instance to extract names from `fields`\n        include_pk: Whether to include the `pk` (primary key) column\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; fixture_fields(NEWSPAPER_COLLECTION_METADATA[0])\n        ('pk', 'name', 'code', 'legacy_code', 'collection', 'source_note')\n        &gt;&gt;&gt; fixture_fields(NEWSPAPER_COLLECTION_METADATA[0], include_pk=False)\n        ('name', 'code', 'legacy_code', 'collection', 'source_note')\n        &gt;&gt;&gt; hmd_dict: dict[str, Any] = fixture_fields(\n        ...     NEWSPAPER_COLLECTION_METADATA[1], as_dict=True)\n        &gt;&gt;&gt; hmd_dict['code']\n        'bl-hmd'\n        &gt;&gt;&gt; hmd_dict['pk']\n        2\n        &gt;&gt;&gt; hmd_dict = fixture_fields(\n        ...     NEWSPAPER_COLLECTION_METADATA[1], include_pk=False, as_dict=True)\n        &gt;&gt;&gt; 'pk' in hmd_dict\n        False\n\n        ```\n    \"\"\"\n    fields: OrderedDict[str, Any] = OrderedDict(fixture_dict[\"fields\"])\n    if include_pk:\n        fields[\"pk\"] = fixture_dict[\"pk\"]\n        fields.move_to_end(\"pk\", last=False)\n    if as_dict:\n        return fields\n    else:\n        return tuple(fields.keys())\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.fixture_or_default_dict","title":"fixture_or_default_dict","text":"<pre><code>fixture_or_default_dict(\n    key: str,\n    fixture_dict: dict[str, FixtureDict],\n    default_dict: FixtureDict | dict = {},\n) -&gt; FixtureDict | dict\n</code></pre> <p>Return a <code>FixtureDict</code> from <code>fixture_list</code> via <code>key</code> index, else <code>default_dict</code>.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>a <code>str</code> to query <code>fixture_dict</code> with</p> required <code>fixture_dict</code> <code>dict[str, FixtureDict]</code> <p>a <code>dict</code> of <code>str</code> to <code>FixtureDict</code>, often generated by <code>dict_from_list_fixture_fields</code></p> required <code>default_dict</code> <code>FixtureDict | dict</code> <p>a <code>dict</code> to return if <code>key</code> is not in <code>fixture_dict</code> index</p> <code>{}</code> Example <pre><code>&gt;&gt;&gt; newspaper_dict: dict[str, FixtureDict] = dict_from_list_fixture_fields(\n...     NEWSPAPER_COLLECTION_METADATA)\n&gt;&gt;&gt; hmd_dict: FixtureDict = fixture_or_default_dict(\n...     'hmd', newspaper_dict\n... )\n&gt;&gt;&gt; hmd_dict == newspaper_dict['hmd']\nTrue\n&gt;&gt;&gt; fixture_or_default_dict(\n...     'hmd', NEWSPAPER_COLLECTION_METADATA\n... )\n{}\n&gt;&gt;&gt; fixture_or_default_dict(\n...     'hmd', NEWSPAPER_COLLECTION_METADATA, {'a': 'default'}\n... )\n{'a': 'default'}\n</code></pre> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def fixture_or_default_dict(\n    key: str,\n    fixture_dict: dict[str, FixtureDict],\n    default_dict: FixtureDict | dict = {},\n) -&gt; FixtureDict | dict:\n    \"\"\"Return a `FixtureDict` from ``fixture_list`` via ``key`` index, else ``default_dict``.\n\n    Args:\n        key:\n            a `str` to query ``fixture_dict`` with\n        fixture_dict:\n            a `dict` of `str` to `FixtureDict`, often generated by\n            ``dict_from_list_fixture_fields``\n        default_dict:\n            a `dict` to return if ``key`` is not in ``fixture_dict`` index\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; newspaper_dict: dict[str, FixtureDict] = dict_from_list_fixture_fields(\n        ...     NEWSPAPER_COLLECTION_METADATA)\n        &gt;&gt;&gt; hmd_dict: FixtureDict = fixture_or_default_dict(\n        ...     'hmd', newspaper_dict\n        ... )\n        &gt;&gt;&gt; hmd_dict == newspaper_dict['hmd']\n        True\n        &gt;&gt;&gt; fixture_or_default_dict(\n        ...     'hmd', NEWSPAPER_COLLECTION_METADATA\n        ... )\n        {}\n        &gt;&gt;&gt; fixture_or_default_dict(\n        ...     'hmd', NEWSPAPER_COLLECTION_METADATA, {'a': 'default'}\n        ... )\n        {'a': 'default'}\n\n        ```\n    \"\"\"\n    if key in fixture_dict:\n        return fixture_dict[key]\n    else:\n        return default_dict\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.fixtures_dict2csv","title":"fixtures_dict2csv","text":"<pre><code>fixtures_dict2csv(\n    fixtures: Iterable[FixtureDict] | Generator[FixtureDict, None, None],\n    prefix: str = \"\",\n    output_path: PathLike | str = settings.OUTPUT,\n    index: bool = False,\n    max_elements_per_file: int = settings.MAX_ELEMENTS_PER_FILE,\n    file_name_0_padding: int = FILE_NAME_0_PADDING_DEFAULT,\n) -&gt; None\n</code></pre> <p>Saves fixtures generated by a generator to separate separate <code>CSV</code> files.</p> <p>This function takes an <code>Iterable</code> or <code>Generator</code> of fixtures and saves to separate <code>CSV</code> files. The fixtures are saved in batches, where each batch is determined by the <code>max_elements_per_file</code> parameter.</p> <p>Parameters:</p> Name Type Description Default <code>fixtures</code> <code>Iterable[FixtureDict] | Generator[FixtureDict, None, None]</code> <p>An <code>Iterable</code> or <code>Generator</code> of the fixtures to be saved.</p> required <code>prefix</code> <code>str</code> <p>A string prefix to be added to the file names of the saved fixtures.</p> <code>''</code> <code>output_path</code> <code>PathLike | str</code> <p>Path to folder fixtures are saved to</p> <code>OUTPUT</code> <code>max_elements_per_file</code> <code>int</code> <p>Maximum <code>JSON</code> records saved in each file</p> <code>MAX_ELEMENTS_PER_FILE</code> <code>file_name_0_padding</code> <code>int</code> <p>Zeros to prefix the number of each fixture file name.</p> <code>FILE_NAME_0_PADDING_DEFAULT</code> <p>Returns:</p> Type Description <code>None</code> <p>This function saves fixtures to files and does not return a value.</p> Example <pre><code>&gt;&gt;&gt; tmp_path: Path = getfixture('tmp_path')\n&gt;&gt;&gt; from pandas import read_csv\n&gt;&gt;&gt; fixtures_dict2csv(NEWSPAPER_COLLECTION_METADATA,\n...                   prefix='test', output_path=tmp_path)\n&gt;&gt;&gt; imported_fixture = read_csv(tmp_path / 'test-000001.csv')\n&gt;&gt;&gt; imported_fixture.iloc[1]['pk']\n2\n&gt;&gt;&gt; imported_fixture.iloc[1][DATA_PROVIDER_INDEX]\n'hmd'\n</code></pre> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def fixtures_dict2csv(\n    fixtures: Iterable[FixtureDict] | Generator[FixtureDict, None, None],\n    prefix: str = \"\",\n    output_path: PathLike | str = settings.OUTPUT,\n    index: bool = False,\n    max_elements_per_file: int = settings.MAX_ELEMENTS_PER_FILE,\n    file_name_0_padding: int = FILE_NAME_0_PADDING_DEFAULT,\n) -&gt; None:\n    \"\"\"Saves fixtures generated by a generator to separate separate `CSV` files.\n\n    This function takes an `Iterable` or `Generator` of fixtures and saves to\n    separate `CSV` files. The fixtures are saved in batches, where each batch\n    is determined by the ``max_elements_per_file`` parameter.\n\n    Args:\n        fixtures:\n            An `Iterable` or `Generator` of the fixtures to be saved.\n        prefix:\n            A string prefix to be added to the file names of the\n            saved fixtures.\n        output_path:\n            Path to folder fixtures are saved to\n        max_elements_per_file:\n            Maximum `JSON` records saved in each file\n        file_name_0_padding:\n            Zeros to prefix the number of each fixture file name.\n\n    Returns:\n        This function saves fixtures to files and does not return a value.\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; tmp_path: Path = getfixture('tmp_path')\n        &gt;&gt;&gt; from pandas import read_csv\n        &gt;&gt;&gt; fixtures_dict2csv(NEWSPAPER_COLLECTION_METADATA,\n        ...                   prefix='test', output_path=tmp_path)\n        &gt;&gt;&gt; imported_fixture = read_csv(tmp_path / 'test-000001.csv')\n        &gt;&gt;&gt; imported_fixture.iloc[1]['pk']\n        2\n        &gt;&gt;&gt; imported_fixture.iloc[1][DATA_PROVIDER_INDEX]\n        'hmd'\n\n        ```\n\n    \"\"\"\n    internal_counter: int = 1\n    counter: int = 1\n    lst: list = []\n    file_name: str\n    df: DataFrame\n    Path(output_path).mkdir(parents=True, exist_ok=True)\n    for item in fixtures:\n        lst.append(fixture_fields(item, as_dict=True))\n        internal_counter += 1\n        if internal_counter &gt; max_elements_per_file:\n            df = DataFrame.from_records(lst)\n\n            file_name = f\"{prefix}-{str(counter).zfill(file_name_0_padding)}.csv\"\n            df.to_csv(Path(output_path) / file_name, index=index)\n            # Save up some memory\n            del lst\n            gc.collect()\n\n            # Re-instantiate\n            lst = []\n            internal_counter = 1\n            counter += 1\n    else:\n        df = DataFrame.from_records(lst)\n        file_name = f\"{prefix}-{str(counter).zfill(file_name_0_padding)}.csv\"\n        df.to_csv(Path(output_path) / file_name, index=index)\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.free_hd_space_in_GB","title":"free_hd_space_in_GB","text":"<pre><code>free_hd_space_in_GB(\n    disk_usage_tuple: DiskUsageTuple | None = None, path: PathLike | None = None\n) -&gt; float\n</code></pre> <p>Return remaing hard drive space estimate in gigabytes.</p> <p>Parameters:</p> Name Type Description Default <code>disk_usage_tuple</code> <code>DiskUsageTuple | None</code> <p>A <code>NamedTuple</code> normally returned from <code>disk_usage()</code> or <code>None</code>.</p> <code>None</code> <code>path</code> <code>PathLike | None</code> <p>A <code>path</code> to pass to <code>disk_usage</code> if <code>disk_usage_tuple</code> is <code>None</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>float</code> <p>A <code>float</code> from dividing the <code>disk_usage_tuple.free</code> value by <code>BYTES_PER_GIGABYTE</code></p> Example <pre><code>&gt;&gt;&gt; space_in_gb = free_hd_space_in_GB()\n&gt;&gt;&gt; space_in_gb &gt; 1  # Hopefully true when run...\nTrue\n</code></pre> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def free_hd_space_in_GB(\n    disk_usage_tuple: DiskUsageTuple | None = None, path: PathLike | None = None\n) -&gt; float:\n    \"\"\"Return remaing hard drive space estimate in gigabytes.\n\n    Args:\n        disk_usage_tuple:\n            A `NamedTuple` normally returned from `disk_usage()` or `None`.\n\n        path:\n            A `path` to pass to `disk_usage` if `disk_usage_tuple` is `None`.\n\n    Returns:\n        A `float` from dividing the `disk_usage_tuple.free` value by `BYTES_PER_GIGABYTE`\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; space_in_gb = free_hd_space_in_GB()\n        &gt;&gt;&gt; space_in_gb &gt; 1  # Hopefully true when run...\n        True\n\n        ```\n    \"\"\"\n    if not disk_usage_tuple:\n        if not path:\n            path = Path(getcwd())\n        disk_usage_tuple = disk_usage(path=path)\n    assert disk_usage_tuple\n    return disk_usage_tuple.free / BYTES_PER_GIGABYTE\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.gen_fixture_tables","title":"gen_fixture_tables","text":"<pre><code>gen_fixture_tables(\n    fixture_tables: dict[str, list[FixtureDict]] = {},\n    include_fixture_pk_column: bool = True,\n) -&gt; Generator[Table, None, None]\n</code></pre> <p>Generator of <code>rich.Table</code> instances from <code>FixtureDict</code> configuration tables.</p> <p>Parameters:</p> Name Type Description Default <code>fixture_tables</code> <code>dict[str, list[FixtureDict]]</code> <p><code>dict</code> where <code>key</code> is for <code>Table</code> title and <code>value</code> is a <code>FixtureDict</code></p> <code>{}</code> <code>include_fixture_pk_column</code> <code>bool</code> <p>whether to include the <code>pk</code> field from <code>FixtureDict</code></p> <code>True</code> Example <pre><code>&gt;&gt;&gt; table_name: str = \"data_provider\"\n&gt;&gt;&gt; tables = tuple(\n...     gen_fixture_tables(\n...         {table_name: NEWSPAPER_COLLECTION_METADATA}\n...     ))\n&gt;&gt;&gt; len(tables)\n1\n&gt;&gt;&gt; assert tables[0].title == table_name\n&gt;&gt;&gt; [column.header for column in tables[0].columns]\n['pk', 'name', 'code', 'legacy_code', 'collection', 'source_note']\n</code></pre> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def gen_fixture_tables(\n    fixture_tables: dict[str, list[FixtureDict]] = {},\n    include_fixture_pk_column: bool = True,\n) -&gt; Generator[Table, None, None]:\n    \"\"\"Generator of `rich.Table` instances from `FixtureDict` configuration tables.\n\n    Args:\n        fixture_tables: `dict` where `key` is for `Table` title and `value` is a `FixtureDict`\n        include_fixture_pk_column: whether to include the `pk` field from `FixtureDict`\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; table_name: str = \"data_provider\"\n        &gt;&gt;&gt; tables = tuple(\n        ...     gen_fixture_tables(\n        ...         {table_name: NEWSPAPER_COLLECTION_METADATA}\n        ...     ))\n        &gt;&gt;&gt; len(tables)\n        1\n        &gt;&gt;&gt; assert tables[0].title == table_name\n        &gt;&gt;&gt; [column.header for column in tables[0].columns]\n        ['pk', 'name', 'code', 'legacy_code', 'collection', 'source_note']\n\n        ```\n    \"\"\"\n    for name, fixture_records in fixture_tables.items():\n        fixture_table: Table = Table(title=name)\n        for i, fixture_dict in enumerate(fixture_records):\n            if i == 0:\n                [\n                    fixture_table.add_column(name)\n                    for name in fixture_fields(fixture_dict, include_fixture_pk_column)\n                ]\n            row_values: tuple[str, ...] = tuple(\n                str(x) for x in (fixture_dict[\"pk\"], *fixture_dict[\"fields\"].values())\n            )\n            fixture_table.add_row(*row_values)\n        yield fixture_table\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.get_chunked_zipfiles","title":"get_chunked_zipfiles","text":"<pre><code>get_chunked_zipfiles(path: Path) -&gt; list\n</code></pre> <p>This function takes in a <code>Path</code> object <code>path</code> and returns a list of lists of <code>zipfiles</code> sorted and chunked according to certain conditions defined in the <code>settings</code> object (see <code>settings.CHUNK_THRESHOLD</code>).</p> <p>Note: the function will also skip zip files of a certain file size, which can be specified in the <code>settings</code> object (see <code>settings.SKIP_FILE_SIZE</code>).</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>The input path where the zipfiles are located</p> required <p>Returns:</p> Type Description <code>list</code> <p>A list of lists of <code>zipfiles</code>, each inner list represents a chunk of zipfiles.</p> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def get_chunked_zipfiles(path: Path) -&gt; list:\n    \"\"\"This function takes in a `Path` object `path` and returns a list of lists\n    of `zipfiles` sorted and chunked according to certain conditions defined\n    in the `settings` object (see `settings.CHUNK_THRESHOLD`).\n\n    Note: the function will also skip zip files of a certain file size, which\n    can be specified in the `settings` object (see `settings.SKIP_FILE_SIZE`).\n\n    Args:\n        path: The input path where the zipfiles are located\n\n    Returns:\n        A list of lists of `zipfiles`, each inner list represents a chunk of\n            zipfiles.\n    \"\"\"\n\n    zipfiles = sorted(\n        path.glob(\"*.zip\"),\n        key=lambda x: x.stat().st_size,\n        reverse=settings.START_WITH_LARGEST,\n    )\n\n    zipfiles = [x for x in zipfiles if x.stat().st_size &lt;= settings.SKIP_FILE_SIZE]\n\n    if len(zipfiles) &gt; settings.CHUNK_THRESHOLD:\n        chunks = array_split(zipfiles, len(zipfiles) / settings.CHUNK_THRESHOLD)\n    else:\n        chunks = [zipfiles]\n\n    return chunks\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.get_key","title":"get_key","text":"<pre><code>get_key(x: dict = dict(), on: list = []) -&gt; str\n</code></pre> <p>Get a string key from a dictionary using values from specified keys.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>dict</code> <p>A dictionary from which the key is generated.</p> <code>dict()</code> <code>on</code> <code>list</code> <p>A list of keys from the dictionary that should be used to generate the key.</p> <code>[]</code> <p>Returns:</p> Type Description <code>str</code> <p>The generated string key.</p> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def get_key(x: dict = dict(), on: list = []) -&gt; str:\n    \"\"\"\n    Get a string key from a dictionary using values from specified keys.\n\n    Args:\n        x: A dictionary from which the key is generated.\n        on: A list of keys from the dictionary that should be used to\n            generate the key.\n\n    Returns:\n        The generated string key.\n    \"\"\"\n\n    return f\"{'-'.join([str(x['fields'][y]) for y in on])}\"\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.get_lockfile","title":"get_lockfile","text":"<pre><code>get_lockfile(collection: str, kind: NewspaperElements, dic: dict) -&gt; Path\n</code></pre> <p>Provides the path to any given lockfile, which controls whether any existing files should be overwritten or not.</p> <p>Parameters:</p> Name Type Description Default <code>collection</code> <code>str</code> <p>Collection folder name</p> required <code>kind</code> <code>NewspaperElements</code> <p>Either <code>newspaper</code> or <code>issue</code> or <code>item</code></p> required <code>dic</code> <code>dict</code> <p>A dictionary with required information for either <code>kind</code> passed</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Path to the resulting lockfile</p> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def get_lockfile(collection: str, kind: NewspaperElements, dic: dict) -&gt; Path:\n    \"\"\"\n    Provides the path to any given lockfile, which controls whether any\n    existing files should be overwritten or not.\n\n    Args:\n        collection: Collection folder name\n        kind: Either `newspaper` or `issue` or `item`\n        dic: A dictionary with required information for either `kind` passed\n\n    Returns:\n        Path to the resulting lockfile\n    \"\"\"\n\n    p: Path\n    base = Path(f\"cache-lockfiles/{collection}\")\n\n    if kind == \"newspaper\":\n        p = base / f\"newspapers/{dic['publication_code']}\"\n    elif kind == \"issue\":\n        p = base / f\"issues/{dic['publication__publication_code']}/{dic['issue_code']}\"\n    elif kind == \"item\":\n        try:\n            if dic.get(\"issue_code\"):\n                p = base / f\"items/{dic['issue_code']}/{dic['item_code']}\"\n            elif dic.get(\"issue__issue_identifier\"):\n                p = base / f\"items/{dic['issue__issue_identifier']}/{dic['item_code']}\"\n        except KeyError:\n            error(\"An unknown error occurred (in get_lockfile)\")\n    else:\n        p = base / \"lockfile\"\n\n    p.parent.mkdir(parents=True, exist_ok=True) if settings.WRITE_LOCKFILES else None\n\n    return p\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.get_now","title":"get_now","text":"<pre><code>get_now(as_str: bool = False) -&gt; datetime | str\n</code></pre> <p>Return <code>datetime.now()</code> as either a string or <code>datetime</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>as_str</code> <code>bool</code> <p>Whether to return <code>now</code> <code>time</code> as a <code>str</code> or not, default: <code>False</code></p> <code>False</code> <p>Returns:</p> Type Description <code>datetime | str</code> <p><code>datetime.now()</code> in <code>pytz.UTC</code> time zone as a string if <code>as_str</code>, else as a <code>datetime.datetime</code> object.</p> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def get_now(as_str: bool = False) -&gt; datetime.datetime | str:\n    \"\"\"\n    Return `datetime.now()` as either a string or `datetime` object.\n\n    Args:\n        as_str: Whether to return `now` `time` as a `str` or not, default: `False`\n\n    Returns:\n        `datetime.now()` in `pytz.UTC` time zone as a string if `as_str`, else\n            as a `datetime.datetime` object.\n    \"\"\"\n    now = datetime.datetime.now(tz=pytz.UTC)\n\n    if as_str:\n        return str(now)\n    else:\n        assert isinstance(now, datetime.datetime)\n        return now\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.get_path_from","title":"get_path_from","text":"<pre><code>get_path_from(p: str | Path) -&gt; Path\n</code></pre> <p>Converts an input value into a Path object if it's not already one.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>str | Path</code> <p>The input value, which can be a string or a Path object.</p> required <p>Returns:</p> Type Description <code>Path</code> <p>The input value as a Path object.</p> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def get_path_from(p: str | Path) -&gt; Path:\n    \"\"\"\n    Converts an input value into a Path object if it's not already one.\n\n    Args:\n        p: The input value, which can be a string or a Path object.\n\n    Returns:\n        The input value as a Path object.\n    \"\"\"\n    if isinstance(p, str):\n        p = Path(p)\n\n    if not isinstance(p, Path):\n        raise RuntimeError(f\"Unable to handle type: {type(p)}\")\n\n    return p\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.get_size_from_path","title":"get_size_from_path","text":"<pre><code>get_size_from_path(p: str | Path, raw: bool = False) -&gt; str | float\n</code></pre> <p>Returns a nice string for any given file size.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>str | Path</code> <p>Path to read the size from</p> required <code>raw</code> <code>bool</code> <p>Whether to return the file size as total number of bytes or a human-readable MB/GB amount</p> <code>False</code> <p>Returns:</p> Type Description <code>str | float</code> <p>Return <code>str</code> followed by <code>MB</code> or <code>GB</code> for size if not <code>raw</code> otherwise <code>float</code>.</p> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def get_size_from_path(p: str | Path, raw: bool = False) -&gt; str | float:\n    \"\"\"\n    Returns a nice string for any given file size.\n\n    Args:\n        p: Path to read the size from\n        raw: Whether to return the file size as total number of bytes or\n            a human-readable MB/GB amount\n\n    Returns:\n        Return `str` followed by `MB` or `GB` for size if not `raw` otherwise `float`.\n    \"\"\"\n\n    p = get_path_from(p)\n\n    bytes = p.stat().st_size\n\n    if raw:\n        return bytes\n\n    rel_size: float | int | str = round(bytes / 1000 / 1000 / 1000, 1)\n\n    assert not isinstance(rel_size, str)\n\n    if rel_size &lt; 0.5:\n        rel_size = round(bytes / 1000 / 1000, 1)\n        rel_size = f\"{rel_size}MB\"\n    else:\n        rel_size = f\"{rel_size}GB\"\n\n    return rel_size\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.glob_filter","title":"glob_filter","text":"<pre><code>glob_filter(p: str) -&gt; list\n</code></pre> <p>Return ordered glob, filtered out any pesky, unwanted .DS_Store from macOS.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>str</code> <p>Path to a directory to filter</p> required <p>Returns:</p> Type Description <code>list</code> <p>Sorted list of files contained in the provided path without the ones</p> <code>list</code> <p>whose names start with a <code>.</code></p> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def glob_filter(p: str) -&gt; list:\n    \"\"\"\n    Return ordered glob, filtered out any pesky, unwanted .DS_Store from macOS.\n\n    Args:\n        p: Path to a directory to filter\n\n    Returns:\n        Sorted list of files contained in the provided path without the ones\n        whose names start with a `.`\n    \"\"\"\n    return sorted([x for x in get_path_from(p).glob(\"*\") if not x.name.startswith(\".\")])\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.glob_path_rename_by_0_padding","title":"glob_path_rename_by_0_padding","text":"<pre><code>glob_path_rename_by_0_padding(\n    path: PathLike,\n    output_path: PathLike | None = None,\n    glob_regex_str: str = \"*\",\n    padding: int | None = 0,\n    match_int_regex: str = PADDING_0_REGEX_DEFAULT,\n    index: int = -1,\n) -&gt; dict[PathLike, PathLike]\n</code></pre> <p>Return an <code>OrderedDict</code> of replacement 0-padded file names from <code>path</code>.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>PathLike</code> <p><code>PathLike</code> to source files to rename.</p> required <code>output_path</code> <code>PathLike | None</code> <p><code>PathLike</code> to save renamed files to.</p> <code>None</code> <code>glob_regex_str</code> <code>str</code> <p><code>str</code> to match files to rename within <code>path</code>.</p> <code>'*'</code> <code>padding</code> <code>int | None</code> <p>How many digits (0s) to pad <code>match_int</code> with.</p> <code>0</code> <code>match_int_regex</code> <code>str</code> <p>Regular expression for matching numbers in <code>s</code> to pad. Only rename parts of <code>Path(file_path).name</code>; else replace across <code>Path(file_path).parents</code> as well.</p> <code>PADDING_0_REGEX_DEFAULT</code> <code>index</code> <code>int</code> <p>Which index of number in <code>s</code> to pad with 0s. Like numbering a <code>list</code>, 0 indicates the first match and -1 indicates the last match.</p> <code>-1</code> Example <pre><code>&gt;&gt;&gt; tmp_path: Path = getfixture('tmp_path')\n&gt;&gt;&gt; for i in range(4):\n...     (tmp_path / f'test_file-{i}.txt').touch(exist_ok=True)\n&gt;&gt;&gt; pprint(sorted(tmp_path.iterdir()))\n[...Path('...test_file-0.txt'),\n ...Path('...test_file-1.txt'),\n ...Path('...test_file-2.txt'),\n ...Path('...test_file-3.txt')]\n&gt;&gt;&gt; pprint(glob_path_rename_by_0_padding(tmp_path))\n{...Path('...test_file-0.txt'): ...Path('...test_file-00.txt'),\n ...Path('...test_file-1.txt'): ...Path('...test_file-01.txt'),\n ...Path('...test_file-2.txt'): ...Path('...test_file-02.txt'),\n ...Path('...test_file-3.txt'): ...Path('...test_file-03.txt')}\n</code></pre> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def glob_path_rename_by_0_padding(\n    path: PathLike,\n    output_path: PathLike | None = None,\n    glob_regex_str: str = \"*\",\n    padding: int | None = 0,\n    match_int_regex: str = PADDING_0_REGEX_DEFAULT,\n    index: int = -1,\n) -&gt; dict[PathLike, PathLike]:\n    \"\"\"Return an `OrderedDict` of replacement 0-padded file names from `path`.\n\n    Params:\n        path:\n            `PathLike` to source files to rename.\n\n        output_path:\n            `PathLike` to save renamed files to.\n\n        glob_regex_str:\n            `str` to match files to rename within `path`.\n\n        padding:\n            How many digits (0s) to pad `match_int` with.\n\n        match_int_regex:\n            Regular expression for matching numbers in `s` to pad.\n            Only rename parts of `Path(file_path).name`; else\n            replace across `Path(file_path).parents` as well.\n\n        index:\n            Which index of number in `s` to pad with 0s.\n            Like numbering a `list`, 0 indicates the first match\n            and -1 indicates the last match.\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; tmp_path: Path = getfixture('tmp_path')\n        &gt;&gt;&gt; for i in range(4):\n        ...     (tmp_path / f'test_file-{i}.txt').touch(exist_ok=True)\n        &gt;&gt;&gt; pprint(sorted(tmp_path.iterdir()))\n        [...Path('...test_file-0.txt'),\n         ...Path('...test_file-1.txt'),\n         ...Path('...test_file-2.txt'),\n         ...Path('...test_file-3.txt')]\n        &gt;&gt;&gt; pprint(glob_path_rename_by_0_padding(tmp_path))\n        {...Path('...test_file-0.txt'): ...Path('...test_file-00.txt'),\n         ...Path('...test_file-1.txt'): ...Path('...test_file-01.txt'),\n         ...Path('...test_file-2.txt'): ...Path('...test_file-02.txt'),\n         ...Path('...test_file-3.txt'): ...Path('...test_file-03.txt')}\n\n        ```\n\n    \"\"\"\n    try:\n        assert Path(path).exists()\n    except AssertionError:\n        raise ValueError(f'path does not exist: \"{Path(path)}\"')\n    paths_tuple: tuple[PathLike, ...] = path_globs_to_tuple(path, glob_regex_str)\n    try:\n        assert paths_tuple\n    except AssertionError:\n        raise FileNotFoundError(\n            f\"No files found matching 'glob_regex_str': \"\n            f\"'{glob_regex_str}' in: '{path}'\"\n        )\n    paths_to_index: tuple[tuple[str, int], ...] = tuple(\n        int_from_str(str(matched_path), index=index, regex=match_int_regex)\n        for matched_path in paths_tuple\n    )\n    max_index: int = max(index[1] for index in paths_to_index)\n    max_index_digits: int = len(str(max_index))\n    if not padding or padding &lt; max_index_digits:\n        padding = max_index_digits + 1\n    new_names_dict: dict[PathLike, PathLike] = {}\n    if output_path:\n        if not Path(output_path).is_absolute():\n            output_path = Path(path) / output_path\n        logger.debug(f\"Specified '{output_path}' for saving file copies\")\n    for i, old_path in enumerate(paths_tuple):\n        match_str, match_int = paths_to_index[i]\n        new_names_dict[old_path] = rename_by_0_padding(\n            old_path, match_str=str(match_str), match_int=match_int, padding=padding\n        )\n        if output_path:\n            new_names_dict[old_path] = (\n                Path(output_path) / Path(new_names_dict[old_path]).name\n            )\n    return new_names_dict\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.int_from_str","title":"int_from_str","text":"<pre><code>int_from_str(\n    s: str, index: int = -1, regex: str = PADDING_0_REGEX_DEFAULT\n) -&gt; tuple[str, int]\n</code></pre> <p>Return matched (or None) <code>regex</code> from <code>s</code> by index <code>index</code>.</p> <p>Parameters:</p> Name Type Description Default <code>s</code> <code>str</code> <p><code>str</code> to match and via <code>regex</code>.</p> required <code>index</code> <code>int</code> <p>Which index of number in <code>s</code> to pad with 0s. Like numbering a <code>list</code>, 0 indicates the first match and -1 indicates the last match.</p> <code>-1</code> <code>regex</code> <code>str</code> <p>Regular expression for matching numbers in <code>s</code> to pad.</p> <code>PADDING_0_REGEX_DEFAULT</code> Example <pre><code>&gt;&gt;&gt; int_from_str('a/path/to/fixture-03-05.txt')\n('05', 5)\n&gt;&gt;&gt; int_from_str('a/path/to/fixture-03-05.txt', index=0)\n('03', 3)\n</code></pre> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def int_from_str(\n    s: str,\n    index: int = -1,\n    regex: str = PADDING_0_REGEX_DEFAULT,\n) -&gt; tuple[str, int]:\n    \"\"\"Return matched (or None) `regex` from `s` by index `index`.\n\n    Params:\n        s:\n            `str` to match and via `regex`.\n\n        index:\n            Which index of number in `s` to pad with 0s.\n            Like numbering a `list`, 0 indicates the first match\n            and -1 indicates the last match.\n\n        regex:\n            Regular expression for matching numbers in `s` to pad.\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; int_from_str('a/path/to/fixture-03-05.txt')\n        ('05', 5)\n        &gt;&gt;&gt; int_from_str('a/path/to/fixture-03-05.txt', index=0)\n        ('03', 3)\n\n        ```\n    \"\"\"\n    matches: list[str] = [match for match in findall(regex, s) if match]\n    match_str: str = matches[index]\n    return match_str, int(match_str)\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.list_json_files","title":"list_json_files","text":"<pre><code>list_json_files(\n    p: str | Path,\n    drill: bool = False,\n    exclude_names: list = [],\n    include_names: list = [],\n) -&gt; Generator[Path, None, None] | list[Path]\n</code></pre> <p>List <code>json</code> files under the path specified in <code>p</code>.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>str | Path</code> <p>The path to search for <code>json</code> files</p> required <code>drill</code> <code>bool</code> <p>A flag indicating whether to drill down the subdirectories or not. Default is <code>False</code></p> <code>False</code> <code>exclude_names</code> <code>list</code> <p>A list of file names to exclude from the search result. Default is an empty list</p> <code>[]</code> <code>include_names</code> <code>list</code> <p>A list of file names to include in search result. If provided, the <code>exclude_names</code> argument will be ignored. Default is an empty list</p> <code>[]</code> <p>Returns:</p> Type Description <code>Generator[Path, None, None] | list[Path]</code> <p>A list of <code>Path</code> objects pointing to the found <code>json</code> files</p> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def list_json_files(\n    p: str | Path,\n    drill: bool = False,\n    exclude_names: list = [],\n    include_names: list = [],\n) -&gt; Generator[Path, None, None] | list[Path]:\n    \"\"\"\n    List `json` files under the path specified in ``p``.\n\n    Args:\n        p: The path to search for `json` files\n        drill: A flag indicating whether to drill down the subdirectories\n            or not. Default is ``False``\n        exclude_names: A list of file names to exclude from the search\n            result. Default is an empty list\n        include_names: A list of file names to include in search result.\n            If provided, the ``exclude_names`` argument will be ignored.\n            Default is an empty list\n\n    Returns:\n        A list of `Path` objects pointing to the found `json` files\n    \"\"\"\n\n    q: str = \"**/*.json\" if drill else \"*.json\"\n    files = get_path_from(p).glob(q)\n\n    if exclude_names:\n        files = list({x for x in files if x.name not in exclude_names})\n    elif include_names:\n        files = list({x for x in files if x.name in include_names})\n\n    return sorted(files)\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.load_json","title":"load_json","text":"<pre><code>load_json(p: str | Path, crash: bool = False) -&gt; dict | list\n</code></pre> <p>Easier access to reading <code>json</code> files.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>str | Path</code> <p>Path to read <code>json</code> from</p> required <code>crash</code> <code>bool</code> <p>Whether the program should crash if there is a <code>json</code> decode error, default: <code>False</code></p> <code>False</code> <p>Returns:</p> Type Description <code>dict | list</code> <p>The decoded <code>json</code> contents from the path, but an empty dictionary</p> <code>dict | list</code> <p>if the file cannot be decoded and <code>crash</code> is set to <code>False</code></p> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def load_json(p: str | Path, crash: bool = False) -&gt; dict | list:\n    \"\"\"\n    Easier access to reading `json` files.\n\n    Args:\n        p: Path to read `json` from\n        crash: Whether the program should crash if there is a `json` decode\n            error, default: ``False``\n\n    Returns:\n        The decoded `json` contents from the path, but an empty dictionary\n        if the file cannot be decoded and ``crash`` is set to ``False``\n    \"\"\"\n\n    p = get_path_from(p)\n\n    try:\n        return json.loads(p.read_text())\n    except json.JSONDecodeError:\n        msg = f\"Error: {p.read_text()}\"\n        error(msg, crash=crash)\n\n    return {}\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.load_multiple_json","title":"load_multiple_json","text":"<pre><code>load_multiple_json(\n    p: str | Path,\n    drill: bool = False,\n    filter_na: bool = True,\n    crash: bool = False,\n) -&gt; list\n</code></pre> <p>Load multiple <code>json</code> files and return a list of their content.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>str | Path</code> <p>The path to search for <code>json</code> files</p> required <code>drill</code> <code>bool</code> <p>A flag indicating whether to drill down the subdirectories or not. Default is <code>False</code></p> <code>False</code> <code>filter_na</code> <code>bool</code> <p>A flag indicating whether to filter out the content that is <code>None</code>. Default is <code>True</code>.</p> <code>True</code> <code>crash</code> <code>bool</code> <p>A flag indicating whether to raise an exception when an error occurs while loading a <code>json</code> file. Default is <code>False</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>list</code> <p>A <code>list</code> of the content of the loaded <code>json</code> files.</p> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def load_multiple_json(\n    p: str | Path,\n    drill: bool = False,\n    filter_na: bool = True,\n    crash: bool = False,\n) -&gt; list:\n    \"\"\"\n    Load multiple `json` files and return a list of their content.\n\n    Args:\n        p: The path to search for `json` files\n        drill: A flag indicating whether to drill down the subdirectories\n            or not. Default is `False`\n        filter_na: A flag indicating whether to filter out the content that\n            is `None`. Default is `True`.\n        crash: A flag indicating whether to raise an exception when an\n            error occurs while loading a `json` file. Default is `False`.\n\n    Returns:\n        A `list` of the content of the loaded `json` files.\n    \"\"\"\n\n    files = list_json_files(p, drill=drill)\n\n    content = [load_json(x, crash=crash) for x in files]\n\n    return [x for x in content if x] if filter_na else content\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.lock","title":"lock","text":"<pre><code>lock(lockfile: Path) -&gt; None\n</code></pre> <p>Writes a '.' to a lockfile, after making sure the parent directory exists.</p> <p>Parameters:</p> Name Type Description Default <code>lockfile</code> <code>Path</code> <p>The path to the lock file to be created</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def lock(lockfile: Path) -&gt; None:\n    \"\"\"\n    Writes a '.' to a lockfile, after making sure the parent directory exists.\n\n    Args:\n        lockfile: The path to the lock file to be created\n\n    Returns:\n        None\n    \"\"\"\n    lockfile.parent.mkdir(parents=True, exist_ok=True)\n\n    lockfile.write_text(\"\")\n\n    return\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.path_globs_to_tuple","title":"path_globs_to_tuple","text":"<pre><code>path_globs_to_tuple(\n    path: PathLike, glob_regex_str: str = \"*\"\n) -&gt; tuple[PathLike, ...]\n</code></pre> <p>Return a sorted <code>tuple</code> of <code>Path</code>s in <code>path</code> using <code>glob_regex_str</code>.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>PathLike</code> <p>Patch to search via <code>glob</code></p> required <code>glob_regex_str</code> <code>str</code> <p>Regular expression to use with <code>glob</code> at <code>path</code></p> <code>'*'</code> <p>Returns:</p> Type Description <code>tuple[PathLike, ...]</code> <p><code>tuple</code> of matching paths.</p> Example <pre><code>&gt;&gt;&gt; bl_lwm = getfixture(\"bl_lwm\")\n&gt;&gt;&gt; pprint(path_globs_to_tuple(bl_lwm, '*text.zip'))\n(...Path('...bl_lwm...0003079-test_plaintext.zip'),\n ...Path('...bl_lwm...0003548-test_plaintext.zip'))\n&gt;&gt;&gt; pprint(path_globs_to_tuple(bl_lwm, '*.txt'))\n(...Path('...bl_lwm...0003079_18980121_sect0001.txt'),\n ...Path('...bl_lwm...0003548_19040707_art0037.txt'))\n</code></pre> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def path_globs_to_tuple(\n    path: PathLike, glob_regex_str: str = \"*\"\n) -&gt; tuple[PathLike, ...]:\n    \"\"\"Return a sorted `tuple` of `Path`s in `path` using `glob_regex_str`.\n\n    Args:\n        path:\n            Patch to search via `glob`\n\n        glob_regex_str:\n            Regular expression to use with `glob` at `path`\n\n    Returns:\n        `tuple` of matching paths.\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; bl_lwm = getfixture(\"bl_lwm\")\n        &gt;&gt;&gt; pprint(path_globs_to_tuple(bl_lwm, '*text.zip'))\n        (...Path('...bl_lwm...0003079-test_plaintext.zip'),\n         ...Path('...bl_lwm...0003548-test_plaintext.zip'))\n        &gt;&gt;&gt; pprint(path_globs_to_tuple(bl_lwm, '*.txt'))\n        (...Path('...bl_lwm...0003079_18980121_sect0001.txt'),\n         ...Path('...bl_lwm...0003548_19040707_art0037.txt'))\n\n        ```\n\n    \"\"\"\n    return tuple(sorted(Path(path).glob(glob_regex_str)))\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.path_or_str_suffix","title":"path_or_str_suffix","text":"<pre><code>path_or_str_suffix(\n    str_or_path: str | PathLike,\n    max_extension_len: int = 10,\n    force: bool = False,\n    split_str: str = \".\",\n) -&gt; str\n</code></pre> <p>Return suffix of <code>str_or_path</code>, else <code>''</code>.</p> <p>Parameters:</p> Name Type Description Default <code>str_or_path</code> <code>str | PathLike</code> <p><code>str</code> or <code>PathLike</code> instance to extract <code>suffix</code> from.</p> required <code>max_extension_len</code> <code>int</code> <p>Maximum <code>extension</code> allowed for <code>suffix</code> to extract.</p> <code>10</code> <code>force</code> <code>bool</code> <p><code>bool</code> for overrised <code>max_extension_len</code> constraint.</p> <code>False</code> <code>split_str</code> <code>str</code> <p><code>str</code> to split <code>str_or_path</code> by, usually <code>.</code> for file path.</p> <code>'.'</code> <p>Returns:</p> Type Description <code>str</code> <p><code>str</code> extracted from the end of <code>str_or_path</code>.</p> Example <pre><code>&gt;&gt;&gt; path_or_str_suffix('https://lwmd.livingwithmachines.ac.uk/file.bz2')\n'bz2'\n&gt;&gt;&gt; path_or_str_suffix('https://lwmd.livingwithmachines.ac.uk/file')\n&lt;BLANKLINE&gt;\n...''...\n&gt;&gt;&gt; path_or_str_suffix(Path('cat') / 'dog' / 'fish.csv')\n'csv'\n&gt;&gt;&gt; path_or_str_suffix(Path('cat') / 'dog' / 'fish')\n''\n</code></pre> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def path_or_str_suffix(\n    str_or_path: str | PathLike,\n    max_extension_len: int = 10,\n    force: bool = False,\n    split_str: str = \".\",\n) -&gt; str:\n    \"\"\"Return suffix of `str_or_path`, else `''`.\n\n    Args:\n        str_or_path: `str` or `PathLike` instance to extract `suffix` from.\n        max_extension_len: Maximum `extension` allowed for `suffix` to extract.\n        force: `bool` for overrised `max_extension_len` constraint.\n        split_str: `str` to split `str_or_path` by, usually `.` for file path.\n\n    Returns:\n        `str` extracted from the end of `str_or_path`.\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; path_or_str_suffix('https://lwmd.livingwithmachines.ac.uk/file.bz2')\n        'bz2'\n        &gt;&gt;&gt; path_or_str_suffix('https://lwmd.livingwithmachines.ac.uk/file')\n        &lt;BLANKLINE&gt;\n        ...''...\n        &gt;&gt;&gt; path_or_str_suffix(Path('cat') / 'dog' / 'fish.csv')\n        'csv'\n        &gt;&gt;&gt; path_or_str_suffix(Path('cat') / 'dog' / 'fish')\n        ''\n\n        ```\n    \"\"\"\n    suffix: str = \"\"\n    if isinstance(str_or_path, Path):\n        if str_or_path.suffix:\n            suffix = str_or_path.suffix[1:]  # Skip the `.` for consistency\n        else:\n            \"\"\"\"\"\"\n    else:\n        split_str_or_path: list[str] = str(str_or_path).split(split_str)\n        if len(split_str_or_path) &gt; 1:\n            suffix = split_str_or_path[-1]\n            if \"/\" in suffix:\n                logger.debug(\n                    f\"Split via {split_str} of \"\n                    f\"{str_or_path} has a `/` `char`. \"\n                    \"Returning ''\",\n                )\n                return \"\"\n        else:\n            logger.debug(\n                f\"Can't split via {split_str} in \"\n                f\"{_short_text_trunc(str(str_or_path))}\",\n            )\n            return \"\"\n    if len(suffix) &gt; max_extension_len:\n        if force:\n            console.log(\n                f\"Force return of suffix {suffix}\",\n            )\n            return suffix\n        else:\n            console.log(\n                f\"suffix {_short_text_trunc(suffix)} too long \"\n                f\"(max={max_extension_len})\",\n            )\n            return \"\"\n    else:\n        return suffix\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.paths_with_newlines","title":"paths_with_newlines","text":"<pre><code>paths_with_newlines(\n    paths: Iterable[PathLike], truncate: bool = False, **kwargs\n) -&gt; str\n</code></pre> <p>Return a <code>str</code> of <code>paths</code> separated by a <code>\\n</code>.</p> Example <pre><code>&gt;&gt;&gt; plaintext_bl_lwm = getfixture('bl_lwm_plaintext')\n&gt;&gt;&gt; print(paths_with_newlines(plaintext_bl_lwm.compressed_files))\n'...bl_lwm...0003079-test_plaintext.zip'\n'...bl_lwm...0003548-test_plaintext.zip'\n&gt;&gt;&gt; print(\n...     paths_with_newlines(plaintext_bl_lwm.compressed_files,\n...                         truncate=True)\n... )\n'bl_lwm/0003079-test_plaintext.zip'\n'bl_lwm/0003548-test_plaintext.zip'\n</code></pre> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def paths_with_newlines(\n    paths: Iterable[PathLike], truncate: bool = False, **kwargs\n) -&gt; str:\n    \"\"\"Return a `str` of `paths` separated by a `\\\\n`.\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; plaintext_bl_lwm = getfixture('bl_lwm_plaintext')\n        &gt;&gt;&gt; print(paths_with_newlines(plaintext_bl_lwm.compressed_files))\n        '...bl_lwm...0003079-test_plaintext.zip'\n        '...bl_lwm...0003548-test_plaintext.zip'\n        &gt;&gt;&gt; print(\n        ...     paths_with_newlines(plaintext_bl_lwm.compressed_files,\n        ...                         truncate=True)\n        ... )\n        'bl_lwm/0003079-test_plaintext.zip'\n        'bl_lwm/0003548-test_plaintext.zip'\n\n        ```\n    \"\"\"\n    if truncate:\n        return \"\\n\".join(f\"'{truncate_path_str(f, **kwargs)}'\" for f in paths)\n    else:\n        return \"\\n\".join(f\"'{f}'\" for f in paths)\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.rename_by_0_padding","title":"rename_by_0_padding","text":"<pre><code>rename_by_0_padding(\n    file_path: PathLike,\n    match_str: str | None = None,\n    match_int: int | None = None,\n    padding: int = FILE_NAME_0_PADDING_DEFAULT,\n    replace_count: int = 1,\n    exclude_parents: bool = True,\n    reverse_int_match: bool = False,\n) -&gt; Path\n</code></pre> <p>Return <code>file_path</code> with <code>0</code> <code>padding</code> <code>Path</code> change.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>PathLike</code> <p><code>PathLike</code> to rename.</p> required <code>match_str</code> <code>str | None</code> <p><code>str</code> to match and replace with padded <code>match_int</code></p> <code>None</code> <code>match_int</code> <code>int | None</code> <p><code>int</code> to pad and replace <code>match_str</code></p> <code>None</code> <code>padding</code> <code>int</code> <p>How many digits (0s) to pad <code>match_int</code> with.</p> <code>FILE_NAME_0_PADDING_DEFAULT</code> <code>exclude_parents</code> <code>bool</code> <p>Only rename parts of <code>Path(file_path).name</code>; else replace across <code>Path(file_path).parents</code> as well.</p> <code>True</code> <code>reverse_int_match</code> <code>bool</code> <p>Whether to match from the end of the <code>file_path</code>.</p> <code>False</code> Example <pre><code>&gt;&gt;&gt; rename_by_0_padding('a/path/to/3/fixture-03-05.txt',\n...                     match_str='05', match_int=5)\n&lt;BLANKLINE&gt;\n...Path('a/path/to/3/fixture-03-000005.txt')...\n&gt;&gt;&gt; rename_by_0_padding('a/path/to/3/fixture-03-05.txt',\n...                     match_str='03')\n&lt;BLANKLINE&gt;\n...Path('a/path/to/3/fixture-000003-05.txt')...\n&gt;&gt;&gt; rename_by_0_padding('a/path/to/3/fixture-03-05.txt',\n...                     match_str='05', padding=0)\n&lt;BLANKLINE&gt;\n...Path('a/path/to/3/fixture-03-5.txt')...\n&gt;&gt;&gt; rename_by_0_padding('a/path/to/3/fixture-03-05.txt',\n...                     match_int=3)\n&lt;BLANKLINE&gt;\n...Path('a/path/to/3/fixture-0000003-05.txt')...\n&gt;&gt;&gt; rename_by_0_padding('a/path/to/3/f-03-05-0003.txt',\n...                     match_int=3, padding=2,\n...                     exclude_parents=False)\n&lt;BLANKLINE&gt;\n...Path('a/path/to/03/f-03-05-0003.txt')...\n&gt;&gt;&gt; rename_by_0_padding('a/path/to/3/f-03-05-0003.txt',\n...                     match_int=3, padding=2,\n...                     exclude_parents=False,\n...                     replace_count=3, )\n&lt;BLANKLINE&gt;\n...Path('a/path/to/03/f-003-05-00003.txt')...\n</code></pre> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def rename_by_0_padding(\n    file_path: PathLike,\n    match_str: str | None = None,\n    match_int: int | None = None,\n    padding: int = FILE_NAME_0_PADDING_DEFAULT,\n    replace_count: int = 1,\n    exclude_parents: bool = True,\n    reverse_int_match: bool = False,\n) -&gt; Path:\n    \"\"\"Return `file_path` with `0` `padding` `Path` change.\n\n    Params:\n        file_path:\n            `PathLike` to rename.\n\n        match_str:\n            `str` to match and replace with padded `match_int`\n\n        match_int:\n            `int` to pad and replace `match_str`\n\n        padding:\n            How many digits (0s) to pad `match_int` with.\n\n        exclude_parents:\n            Only rename parts of `Path(file_path).name`; else\n            replace across `Path(file_path).parents` as well.\n\n        reverse_int_match:\n            Whether to match from the end of the `file_path`.\n\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; rename_by_0_padding('a/path/to/3/fixture-03-05.txt',\n        ...                     match_str='05', match_int=5)\n        &lt;BLANKLINE&gt;\n        ...Path('a/path/to/3/fixture-03-000005.txt')...\n        &gt;&gt;&gt; rename_by_0_padding('a/path/to/3/fixture-03-05.txt',\n        ...                     match_str='03')\n        &lt;BLANKLINE&gt;\n        ...Path('a/path/to/3/fixture-000003-05.txt')...\n        &gt;&gt;&gt; rename_by_0_padding('a/path/to/3/fixture-03-05.txt',\n        ...                     match_str='05', padding=0)\n        &lt;BLANKLINE&gt;\n        ...Path('a/path/to/3/fixture-03-5.txt')...\n        &gt;&gt;&gt; rename_by_0_padding('a/path/to/3/fixture-03-05.txt',\n        ...                     match_int=3)\n        &lt;BLANKLINE&gt;\n        ...Path('a/path/to/3/fixture-0000003-05.txt')...\n        &gt;&gt;&gt; rename_by_0_padding('a/path/to/3/f-03-05-0003.txt',\n        ...                     match_int=3, padding=2,\n        ...                     exclude_parents=False)\n        &lt;BLANKLINE&gt;\n        ...Path('a/path/to/03/f-03-05-0003.txt')...\n        &gt;&gt;&gt; rename_by_0_padding('a/path/to/3/f-03-05-0003.txt',\n        ...                     match_int=3, padding=2,\n        ...                     exclude_parents=False,\n        ...                     replace_count=3, )\n        &lt;BLANKLINE&gt;\n        ...Path('a/path/to/03/f-003-05-00003.txt')...\n\n        ```\n    \"\"\"\n    if match_int is None and match_str in (None, \"\"):\n        raise ValueError(f\"At least `match_int` or `match_str` required; both None.\")\n    elif match_str and not match_int:\n        match_int = int(match_str)\n    elif match_int is not None and not match_str:\n        assert str(match_int) in str(file_path)\n        match_str = int_from_str(\n            str(file_path),\n            index=-1 if reverse_int_match else 0,\n        )[0]\n    assert match_int is not None and match_str is not None\n    if exclude_parents:\n        return Path(file_path).parent / Path(file_path).name.replace(\n            match_str, str(match_int).zfill(padding), replace_count\n        )\n    else:\n        return Path(\n            str(file_path).replace(\n                match_str, str(match_int).zfill(padding), replace_count\n            )\n        )\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.save_fixture","title":"save_fixture","text":"<pre><code>save_fixture(\n    generator: Sequence | Generator = [],\n    prefix: str = \"\",\n    output_path: PathLike | str = settings.OUTPUT,\n    max_elements_per_file: int = settings.MAX_ELEMENTS_PER_FILE,\n    add_created: bool = True,\n    add_fixture_name: bool = False,\n    fixture_name_field: str = \"\",\n    extra_dict_fields: dict[str, Any] = {},\n    json_indent: int = JSON_INDENT,\n    file_name_0_padding: int = FILE_NAME_0_PADDING_DEFAULT,\n) -&gt; None\n</code></pre> <p>Saves fixtures generated by a generator to separate JSON files.</p> <p>This function takes a generator and saves the generated fixtures to separate JSON files. The fixtures are saved in batches, where each batch is determined by the <code>max_elements_per_file</code> parameter.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>Sequence | Generator</code> <p>A generator that yields the fixtures to be saved.</p> <code>[]</code> <code>prefix</code> <code>str</code> <p>A string prefix to be added to the file names of the saved fixtures.</p> <code>''</code> <code>output_path</code> <code>PathLike | str</code> <p>Path to folder fixtures are saved to</p> <code>OUTPUT</code> <code>max_elements_per_file</code> <code>int</code> <p>Maximum <code>JSON</code> records saved in each file</p> <code>MAX_ELEMENTS_PER_FILE</code> <code>add_created</code> <code>bool</code> <p>Whether to add <code>created_at</code> and <code>updated_at</code> <code>timestamps</code></p> <code>True</code> <code>add_fixture_name</code> <code>bool</code> <p>If <code>fixture_name_field</code> is also set, add the fixture name as a field within <code>extra_dict_fields</code></p> <code>False</code> <code>fixture_name_field</code> <code>str</code> <p>If <code>add_fixture_name</code> is also set, the field name as a key to the fixture file name</p> <code>''</code> <code>json_indent</code> <code>int</code> <p>Number of indent spaces per line in saved <code>JSON</code></p> <code>JSON_INDENT</code> <code>file_name_0_padding</code> <code>int</code> <p>Zeros to prefix the number of each fixture file name.</p> <code>FILE_NAME_0_PADDING_DEFAULT</code> <p>Returns:</p> Type Description <code>None</code> <p>This function saves the fixtures to files but does not return</p> <code>None</code> <p>any value.</p> Example <pre><code>&gt;&gt;&gt; tmp_path: Path = getfixture('tmp_path')\n&gt;&gt;&gt; save_fixture(NEWSPAPER_COLLECTION_METADATA,\n...              prefix='test', output_path=tmp_path,\n...              add_fixture_name=True, fixture_name_field='fixture_path')\n&gt;&gt;&gt; imported_fixture = load_json(tmp_path / 'test-000001.json')\n&gt;&gt;&gt; imported_fixture[1]['pk']\n2\n&gt;&gt;&gt; imported_fixture[1]['fields'][DATA_PROVIDER_INDEX]\n'hmd'\n&gt;&gt;&gt; 'created_at' in imported_fixture[1]['fields']\nTrue\n&gt;&gt;&gt; imported_fixture[1]['fields']['fixture_path']\n'test-000001.json'\n</code></pre> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def save_fixture(\n    generator: Sequence | Generator = [],\n    prefix: str = \"\",\n    output_path: PathLike | str = settings.OUTPUT,\n    max_elements_per_file: int = settings.MAX_ELEMENTS_PER_FILE,\n    add_created: bool = True,\n    add_fixture_name: bool = False,\n    fixture_name_field: str = \"\",\n    extra_dict_fields: dict[str, Any] = {},\n    json_indent: int = JSON_INDENT,\n    file_name_0_padding: int = FILE_NAME_0_PADDING_DEFAULT,\n) -&gt; None:\n    \"\"\"Saves fixtures generated by a generator to separate JSON files.\n\n    This function takes a generator and saves the generated fixtures to\n    separate JSON files. The fixtures are saved in batches, where each batch\n    is determined by the ``max_elements_per_file`` parameter.\n\n    Args:\n        generator: A generator that yields the fixtures to be saved.\n        prefix: A string prefix to be added to the file names of the\n            saved fixtures.\n        output_path:\n            Path to folder fixtures are saved to\n        max_elements_per_file:\n            Maximum `JSON` records saved in each file\n        add_created:\n            Whether to add `created_at` and `updated_at` `timestamps`\n        add_fixture_name: If `fixture_name_field` is also set, add the\n            fixture name as a field within `extra_dict_fields`\n        fixture_name_field: If `add_fixture_name` is also set, the\n            field name as a key to the fixture file name\n        json_indent:\n            Number of indent spaces per line in saved `JSON`\n        file_name_0_padding:\n            Zeros to prefix the number of each fixture file name.\n\n    Returns:\n        This function saves the fixtures to files but does not return\n        any value.\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; tmp_path: Path = getfixture('tmp_path')\n        &gt;&gt;&gt; save_fixture(NEWSPAPER_COLLECTION_METADATA,\n        ...              prefix='test', output_path=tmp_path,\n        ...              add_fixture_name=True, fixture_name_field='fixture_path')\n        &gt;&gt;&gt; imported_fixture = load_json(tmp_path / 'test-000001.json')\n        &gt;&gt;&gt; imported_fixture[1]['pk']\n        2\n        &gt;&gt;&gt; imported_fixture[1]['fields'][DATA_PROVIDER_INDEX]\n        'hmd'\n        &gt;&gt;&gt; 'created_at' in imported_fixture[1]['fields']\n        True\n        &gt;&gt;&gt; imported_fixture[1]['fields']['fixture_path']\n        'test-000001.json'\n\n        ```\n\n    \"\"\"\n    internal_counter: int = 1\n    counter: int = 1\n    lst: list[PathLike] = []\n    file_name: str\n    Path(output_path).mkdir(parents=True, exist_ok=True)\n    for item in generator:\n        lst.append(item)\n        internal_counter += 1\n        if internal_counter &gt; max_elements_per_file:\n            file_name: str = f\"{prefix}-{str(counter).zfill(file_name_0_padding)}.json\"\n            if add_fixture_name and fixture_name_field:\n                extra_dict_fields[fixture_name_field] = file_name\n            write_json(\n                p=Path(f\"{output_path}/{file_name}\"),\n                o=lst,\n                add_created=add_created,\n                json_indent=json_indent,\n                extra_dict_fields=extra_dict_fields,\n            )\n\n            # Save up some memory\n            del lst\n            gc.collect()\n\n            # Re-instantiate\n            lst = []\n            internal_counter = 1\n            counter += 1\n    else:\n        file_name = f\"{prefix}-{str(counter).zfill(file_name_0_padding)}.json\"\n        if add_fixture_name and fixture_name_field:\n            extra_dict_fields[fixture_name_field] = file_name\n        write_json(\n            p=Path(f\"{output_path}/{file_name}\"),\n            o=lst,\n            add_created=add_created,\n            json_indent=json_indent,\n            extra_dict_fields=extra_dict_fields,\n        )\n\n    return\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.truncate_path_str","title":"truncate_path_str","text":"<pre><code>truncate_path_str(\n    path: PathLike,\n    max_length: int = MAX_TRUNCATE_PATH_STR_LEN,\n    folder_filler_str: str = INTERMEDIATE_PATH_TRUNCATION_STR,\n    head_parts: int = TRUNC_HEADS_PATH_DEFAULT,\n    tail_parts: int = TRUNC_TAILS_PATH_DEFAULT,\n    path_sep: str = sep,\n    _force_type: Type[Path] | Type[PureWindowsPath] = Path,\n) -&gt; str\n</code></pre> <p>If <code>len(text) &gt; max_length</code> return <code>text</code> followed by <code>trail_str</code>.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>PathLike</code> <p><code>PathLike</code> object to truncate</p> required <code>max_length</code> <code>int</code> <p>maximum length of <code>path</code> to allow, anything belond truncated</p> <code>MAX_TRUNCATE_PATH_STR_LEN</code> <code>folder_filler_str</code> <code>str</code> <p>what to fill intermediate path names with</p> <code>INTERMEDIATE_PATH_TRUNCATION_STR</code> <code>head_parts</code> <code>int</code> <p>how many parts of <code>path</code> from the root to keep. These must be <code>int</code> &gt;= 0</p> <code>TRUNC_HEADS_PATH_DEFAULT</code> <code>tail_parts</code> <code>int</code> <p>how many parts from the <code>path</code> tail the root to keep. These must be <code>int</code> &gt;= 0</p> <code>TRUNC_TAILS_PATH_DEFAULT</code> <code>path_sep</code> <code>str</code> <p>what <code>str</code> to replace <code>path</code> parts with if over <code>max_length</code></p> <code>sep</code> <p>Returns:</p> Type Description <code>str</code> <p><code>text</code> truncated to <code>max_length</code> (if longer than <code>max_length</code>), with with <code>folder_filler_str</code> for intermediate folder names</p> Note <p>For errors running on windows see: #56</p> Example <pre><code>&gt;&gt;&gt; logger.setLevel(WARNING)\n&gt;&gt;&gt; love_shadows: Path = (\n...     Path('Standing') / 'in' / 'the' / 'shadows'/ 'of' / 'love.')\n&gt;&gt;&gt; truncate_path_str(love_shadows)\n'Standing...love.'\n&gt;&gt;&gt; truncate_path_str(love_shadows, max_length=100)\n'Standing...in...the...shadows...of...love.'\n&gt;&gt;&gt; truncate_path_str(love_shadows, folder_filler_str=\"*\")\n'Standing...*...*...*...*...love.'\n&gt;&gt;&gt; root_love_shadows: Path = Path(sep) / love_shadows\n&gt;&gt;&gt; truncate_path_str(root_love_shadows, folder_filler_str=\"*\")\n'...Standing...*...*...*...*...love.'\n&gt;&gt;&gt; if is_platform_win:\n...     pytest.skip('fails on certain Windows root paths: issue #56')\n&gt;&gt;&gt; truncate_path_str(root_love_shadows,\n...                   folder_filler_str=\"*\", tail_parts=3)\n'...Standing...*...*...shadows...of...love.'\n</code></pre> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def truncate_path_str(\n    path: PathLike,\n    max_length: int = MAX_TRUNCATE_PATH_STR_LEN,\n    folder_filler_str: str = INTERMEDIATE_PATH_TRUNCATION_STR,\n    head_parts: int = TRUNC_HEADS_PATH_DEFAULT,\n    tail_parts: int = TRUNC_TAILS_PATH_DEFAULT,\n    path_sep: str = sep,\n    _force_type: Type[Path] | Type[PureWindowsPath] = Path,\n) -&gt; str:\n    \"\"\"If `len(text) &gt; max_length` return `text` followed by `trail_str`.\n\n    Args:\n        path:\n            `PathLike` object to truncate\n        max_length:\n            maximum length of `path` to allow, anything belond truncated\n        folder_filler_str:\n            what to fill intermediate path names with\n        head_parts:\n            how many parts of `path` from the root to keep.\n            These must be `int` &gt;= 0\n        tail_parts:\n            how many parts from the `path` tail the root to keep.\n            These must be `int` &gt;= 0\n        path_sep:\n            what `str` to replace `path` parts with if over `max_length`\n\n    Returns:\n        `text` truncated to `max_length` (if longer than `max_length`),\n            with with `folder_filler_str` for intermediate folder names\n\n    Note:\n        For errors running on windows see:\n        [#56](https://github.com/Living-with-machines/alto2txt2fixture/issues/56)\n\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; logger.setLevel(WARNING)\n        &gt;&gt;&gt; love_shadows: Path = (\n        ...     Path('Standing') / 'in' / 'the' / 'shadows'/ 'of' / 'love.')\n        &gt;&gt;&gt; truncate_path_str(love_shadows)\n        'Standing...love.'\n        &gt;&gt;&gt; truncate_path_str(love_shadows, max_length=100)\n        'Standing...in...the...shadows...of...love.'\n        &gt;&gt;&gt; truncate_path_str(love_shadows, folder_filler_str=\"*\")\n        'Standing...*...*...*...*...love.'\n        &gt;&gt;&gt; root_love_shadows: Path = Path(sep) / love_shadows\n        &gt;&gt;&gt; truncate_path_str(root_love_shadows, folder_filler_str=\"*\")\n        '...Standing...*...*...*...*...love.'\n        &gt;&gt;&gt; if is_platform_win:\n        ...     pytest.skip('fails on certain Windows root paths: issue #56')\n        &gt;&gt;&gt; truncate_path_str(root_love_shadows,\n        ...                   folder_filler_str=\"*\", tail_parts=3)\n        '...Standing...*...*...shadows...of...love.'\n\n        ```\n    \"\"\"\n    path = _force_type(normpath(path))\n    if len(str(path)) &gt; max_length:\n        try:\n            assert not (head_parts &lt; 0 or tail_parts &lt; 0)\n        except AssertionError:\n            logger.error(\n                f\"Both index params for `truncate_path_str` must be &gt;=0: \"\n                f\"(head_parts={head_parts}, tail_parts={tail_parts})\"\n            )\n            return str(path)\n        original_path_parts: tuple[str, ...] = path.parts\n        head_index_fix: int = 0\n        if path.is_absolute() or path.drive:\n            head_index_fix += 1\n            for part in original_path_parts[head_parts + head_index_fix :]:\n                if not part:\n                    head_index_fix += 1\n                else:\n                    break\n            logger.debug(\n                f\"Adding {head_index_fix} to `head_parts`: {head_parts} \"\n                f\"to truncate: '{path}'\"\n            )\n            head_parts += head_index_fix\n        try:\n            assert head_parts + tail_parts &lt; len(str(original_path_parts))\n        except AssertionError:\n            logger.error(\n                f\"Returning untruncated. Params \"\n                f\"(head_parts={head_parts}, tail_parts={tail_parts}) \"\n                f\"not valid to truncate: '{path}'\"\n            )\n            return str(path)\n        tail_index: int = len(original_path_parts) - tail_parts\n        replaced_path_parts: tuple[str, ...] = tuple(\n            part if (i &lt; head_parts or i &gt;= tail_index) else folder_filler_str\n            for i, part in enumerate(original_path_parts)\n        )\n        replaced_start_str: str = \"\".join(replaced_path_parts[:head_parts])\n        replaced_end_str: str = path_sep.join(\n            path for path in replaced_path_parts[head_parts:]\n        )\n        return path_sep.join((replaced_start_str, replaced_end_str))\n    else:\n        return str(path)\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.truncate_str","title":"truncate_str","text":"<pre><code>truncate_str(\n    text: str,\n    max_length: int = DEFAULT_MAX_LOG_STR_LENGTH,\n    trail_str: str = DEFAULT_TRUNCATION_CHARS,\n) -&gt; str\n</code></pre> <p>If <code>len(text) &gt; max_length</code> return <code>text</code> followed by <code>trail_str</code>.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p><code>str</code> to truncate</p> required <code>max_length</code> <code>int</code> <p>maximum length of <code>text</code> to allow, anything belond truncated</p> <code>DEFAULT_MAX_LOG_STR_LENGTH</code> <code>trail_str</code> <code>str</code> <p>what is appended to the end of <code>text</code> if truncated</p> <code>DEFAULT_TRUNCATION_CHARS</code> <p>Returns:</p> Type Description <code>str</code> <p><code>text</code> truncated to <code>max_length</code> (if longer than <code>max_length</code>),</p> <code>str</code> <p>appended with <code>tail_str</code></p> Example <pre><code>&gt;&gt;&gt; truncate_str('Standing in the shadows of love.', 15)\n'Standing in the...'\n</code></pre> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def truncate_str(\n    text: str,\n    max_length: int = DEFAULT_MAX_LOG_STR_LENGTH,\n    trail_str: str = DEFAULT_TRUNCATION_CHARS,\n) -&gt; str:\n    \"\"\"If `len(text) &gt; max_length` return `text` followed by `trail_str`.\n\n    Args:\n        text: `str` to truncate\n        max_length: maximum length of `text` to allow, anything belond truncated\n        trail_str: what is appended to the end of `text` if truncated\n\n    Returns:\n        `text` truncated to `max_length` (if longer than `max_length`),\n        appended with `tail_str`\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; truncate_str('Standing in the shadows of love.', 15)\n        'Standing in the...'\n\n        ```\n    \"\"\"\n    return text[:max_length] + trail_str if len(text) &gt; max_length else text\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.valid_compression_files","title":"valid_compression_files","text":"<pre><code>valid_compression_files(files: Sequence[PathLike]) -&gt; list[PathLike]\n</code></pre> <p>Return a <code>tuple</code> of valid compression paths in <code>files</code>.</p> <p>Parameters:</p> Name Type Description Default <code>files</code> <code>Sequence[PathLike]</code> <p><code>Sequence</code> of files to filter compression types from.</p> required <p>Returns:</p> Type Description <code>list[PathLike]</code> <p>A list of files that could be decompressed.</p> Example <pre><code>&gt;&gt;&gt; valid_compression_files([\n...     'cat.tar.bz2', 'dog.tar.bz3', 'fish.tgz', 'bird.zip',\n...     'giraffe.txt', 'frog'\n... ])\n['cat.tar.bz2', 'fish.tgz', 'bird.zip']\n</code></pre> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def valid_compression_files(files: Sequence[PathLike]) -&gt; list[PathLike]:\n    \"\"\"Return a `tuple` of valid compression paths in `files`.\n\n    Args:\n        files:\n            `Sequence` of files to filter compression types from.\n\n    Returns:\n        A list of files that could be decompressed.\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; valid_compression_files([\n        ...     'cat.tar.bz2', 'dog.tar.bz3', 'fish.tgz', 'bird.zip',\n        ...     'giraffe.txt', 'frog'\n        ... ])\n        ['cat.tar.bz2', 'fish.tgz', 'bird.zip']\n\n        ```\n    \"\"\"\n    return [\n        file\n        for file in files\n        if \"\".join(Path(file).suffixes) in VALID_COMPRESSION_FORMATS\n    ]\n</code></pre>"},{"location":"reference/alto2txt2fixture/utils.html#alto2txt2fixture.utils.write_json","title":"write_json","text":"<pre><code>write_json(\n    p: str | Path,\n    o: dict,\n    add_created: bool = True,\n    json_indent: int = JSON_INDENT,\n    extra_dict_fields: dict = {},\n) -&gt; None\n</code></pre> <p>Easier access to writing <code>json</code> files. Checks whether parent exists.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>str | Path</code> <p>Path to write <code>json</code> to</p> required <code>o</code> <code>dict</code> <p>Object to write to <code>json</code> file</p> required <code>add_created</code> <code>bool</code> <p>If set to True will add <code>created_at</code> and <code>updated_at</code> to the dictionary's fields. If <code>created_at</code> and <code>updated_at</code> already exist in the fields, they will be forcefully updated.</p> <code>True</code> <code>json_indent</code> <code>int</code> <p>What indetation format to write out <code>JSON</code> file in</p> <code>JSON_INDENT</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Example <pre><code>&gt;&gt;&gt; tmp_path: Path = getfixture('tmp_path')\n&gt;&gt;&gt; extra_fields: dict[str, str] = getfixture('text_fixture_path_dict')\n&gt;&gt;&gt; path: Path = tmp_path / 'test-write-json-example.json'\n&gt;&gt;&gt;\n&gt;&gt;&gt; write_json(p=path,\n...            o=NEWSPAPER_COLLECTION_METADATA,\n...            add_created=True, extra_dict_fields=extra_fields)\n&gt;&gt;&gt; imported_fixture = load_json(path)\n&gt;&gt;&gt; imported_fixture[1]['pk']\n2\n&gt;&gt;&gt; imported_fixture[1]['fields'][DATA_PROVIDER_INDEX]\n'hmd'\n&gt;&gt;&gt; imported_fixture[1]['fields']['text_fixture_path']\n'plaintext_fixture-000001.json'\n</code></pre> Source code in <code>alto2txt2fixture/utils.py</code> <pre><code>def write_json(\n    p: str | Path,\n    o: dict,\n    add_created: bool = True,\n    json_indent: int = JSON_INDENT,\n    extra_dict_fields: dict = {},\n) -&gt; None:\n    \"\"\"\n    Easier access to writing `json` files. Checks whether parent exists.\n\n    Args:\n        p: Path to write `json` to\n        o: Object to write to `json` file\n        add_created:\n            If set to True will add `created_at` and `updated_at`\n            to the dictionary's fields. If `created_at` and `updated_at`\n            already exist in the fields, they will be forcefully updated.\n        json_indent:\n            What indetation format to write out `JSON` file in\n\n    Returns:\n        None\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; tmp_path: Path = getfixture('tmp_path')\n        &gt;&gt;&gt; extra_fields: dict[str, str] = getfixture('text_fixture_path_dict')\n        &gt;&gt;&gt; path: Path = tmp_path / 'test-write-json-example.json'\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; write_json(p=path,\n        ...            o=NEWSPAPER_COLLECTION_METADATA,\n        ...            add_created=True, extra_dict_fields=extra_fields)\n        &gt;&gt;&gt; imported_fixture = load_json(path)\n        &gt;&gt;&gt; imported_fixture[1]['pk']\n        2\n        &gt;&gt;&gt; imported_fixture[1]['fields'][DATA_PROVIDER_INDEX]\n        'hmd'\n        &gt;&gt;&gt; imported_fixture[1]['fields']['text_fixture_path']\n        'plaintext_fixture-000001.json'\n\n        ```\n    \"\"\"\n\n    p = get_path_from(p)\n\n    if not (isinstance(o, dict) or isinstance(o, list)):\n        raise RuntimeError(f\"Unable to handle data of type: {type(o)}\")\n\n    def _append_created_fields(o: dict):\n        \"\"\"Add `created_at` and `updated_at` fields to a `dict` with `FixtureDict` values.\"\"\"\n        return dict(\n            **{k: v for k, v in o.items() if not k == \"fields\"},\n            fields=dict(\n                **{\n                    k: v\n                    for k, v in o[\"fields\"].items()\n                    if not k == \"created_at\" and not k == \"updated_at\"\n                },\n                **{\"created_at\": NOW_str, \"updated_at\": NOW_str},\n                **extra_dict_fields,\n            ),\n        )\n\n    try:\n        if add_created and isinstance(o, dict):\n            o = _append_created_fields(o)\n        elif add_created and isinstance(o, list):\n            o = [_append_created_fields(x) for x in o]\n    except KeyError:\n        error(\"An unknown error occurred (in write_json)\")\n\n    p.parent.mkdir(parents=True, exist_ok=True)\n\n    p.write_text(json.dumps(o, indent=json_indent))\n\n    return\n</code></pre>"},{"location":"tutorial/first-steps.html","title":"First Steps","text":""},{"location":"tutorial/first-steps.html#installing","title":"Installing","text":"<p>The installation process should be fairly easy to take care of, using <code>poetry</code>:</p> <pre><code>$ poetry install\n</code></pre> <p>However, this is only the first step in the process. As the script works through the <code>alto2txt</code> collections, you will either need to choose the slower option \u2014 mounting them to your computer (using <code>blobfuse</code>) \u2014\u00a0or the faster option \u2014 downloading the required zip files from the Azure storage to your local hard drive. In the two following sections, both of those options are described.</p>"},{"location":"tutorial/first-steps.html#connecting-alto2txt-to-the-program","title":"Connecting <code>alto2txt</code> to the program","text":""},{"location":"tutorial/first-steps.html#downloading-local-copies-of-alto2txt-on-your-computer","title":"Downloading local copies of <code>alto2txt</code> on your computer","text":"<p>This option will take up a lot of hard drive space</p> <p>As of the time of writing, downloading all of <code>alto2txt</code>\u2019s metadata takes up about 185GB on your local drive.</p> <p>You do not have to download all of the collections or all of the zip files for each collection, as long as you are aware that the resulting fixtures will be limited in scope.</p>"},{"location":"tutorial/first-steps.html#step-1-log-in-to-azure-using-microsoft-azure-storage-explorer","title":"Step 1: Log in to Azure using Microsoft Azure Storage Explorer","text":"<p>Microsoft Azure Storage Explorer (MASE) is a great and free tool for downloading content off Azure. Your first step is to download and install this product on your local computer.</p> <p>Once you have opened MASE, you will need to sign into the appropriate Azure account.</p>"},{"location":"tutorial/first-steps.html#step-2-download-the-alto2txt-blob-container-to-your-hard-drive","title":"Step 2: Download the <code>alto2txt</code> blob container to your hard drive","text":"<p>On your left-hand side, you should see a menu where you can navigate to the correct \u201cblob container\u201d: <code>Living with Machines</code> &gt; <code>Storage Accounts</code> &gt; <code>alto2txt</code> &gt; <code>Blob Containers</code>:</p> <p></p> <p>You will want to replicate the same structure as the Blob Container itself in a folder on your hard drive:</p> <p></p> <p>Once you have the structure set up, you are ready to download all of the files needed. For each of the blob containers, make sure that you download the <code>metadata</code> directory only onto your computer:</p> <p></p> <p>Select all of the files and press the download button:</p> <p></p> <p>Make sure you save all the zip files inside the correct local folder:</p> <p></p> <p>The \u201cActivities\u201d bar will now show you the progress and speed:</p> <p></p>"},{"location":"tutorial/first-steps.html#mounting-alto2txt-on-your-computer","title":"Mounting <code>alto2txt</code> on your computer","text":"<p>This option will only work on a Linux or UNIX computer</p> <p>If you have a mac, your only option is the one below.</p>"},{"location":"tutorial/first-steps.html#step-1-install-blobfuse","title":"Step 1: Install BlobFuse","text":"<p>Follow the instructions for installing BlobFuse and the instructions for how to prepare your drive for mounting.</p>"},{"location":"tutorial/first-steps.html#step-2-set-up-sas-tokens","title":"Step 2: Set up SAS tokens","text":"<p>Follow the instructions for setting up access to your Azure storage account.</p>"},{"location":"tutorial/first-steps.html#step-3-mount-your-blobs","title":"Step 3: Mount your blobs","text":"<p>TODO #3: Write this section.</p> <p>Note that you can also search on the internet for ideas on how to create local scripts to facilitate easier connection next time.</p>"}]}